{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3463cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Core Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, re, joblib\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- PyTorch for Neural Network ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# --- Energy imports ---\n",
    "from scipy.spatial.distance import cdist\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# --- Helper Functions (Copied from Training Notebook) ---\n",
    "USALIGN_PATH = \"/home/max/Documents/Protenix-KaggleRNA3D/af3-dev/USalign/USalign\"\n",
    "TEMP_DIR = \"./temp_pdb_inference/\"\n",
    "os.makedirs(TEMP_DIR, exist_ok=True)\n",
    "\n",
    "def get_coords(df, pred_idx):\n",
    "    return df[[f'x_{pred_idx}', f'y_{pred_idx}', f'z_{pred_idx}']].values\n",
    "\n",
    "def calculate_radius_of_gyration(coords):\n",
    "    center_of_mass = np.mean(coords, axis=0)\n",
    "    return np.sqrt(np.mean(np.sum((coords - center_of_mass)**2, axis=1)))\n",
    "\n",
    "def calculate_rmsd(coords1, coords2):\n",
    "    from scipy.spatial.transform import Rotation as R\n",
    "    if coords1.shape != coords2.shape: return np.nan\n",
    "    coords1_centered = coords1 - coords1.mean(axis=0)\n",
    "    coords2_centered = coords2 - coords2.mean(axis=0)\n",
    "    rotation, rmsd = R.align_vectors(coords1_centered, coords2_centered)\n",
    "    return rmsd\n",
    "\n",
    "# --- Final Evaluation Script (Provided by you) ---\n",
    "def parse_tmscore_output(output):\n",
    "    tm_score_match = re.findall(r'TM-score=\\s+([\\d.]+)', output)\n",
    "    if len(tm_score_match) > 1:\n",
    "        return float(tm_score_match[1])\n",
    "    return np.nan\n",
    "\n",
    "def write_target_line(atom_name, atom_serial, residue_name, chain_id, residue_num,\n",
    "                      x_coord, y_coord, z_coord, occupancy=1.0, b_factor=0.0, atom_type='C'):\n",
    "    atom_name_padded = f\" {atom_name.ljust(3)}\" if len(atom_name) < 4 else atom_name\n",
    "    return (\n",
    "        f\"ATOM  {atom_serial:5d} {atom_name_padded:<4s} {residue_name:<3s} {chain_id}\"\n",
    "        f\"{residue_num:4d}    {x_coord:8.3f}{y_coord:8.3f}{z_coord:8.3f}\"\n",
    "        f\"{occupancy:6.2f}{b_factor:6.2f}          {atom_type:>2s}  \\n\"\n",
    "    )\n",
    "\n",
    "def write2pdb(df: pd.DataFrame, xyz_id: int, target_path: str):\n",
    "    resolved_cnt = 0\n",
    "    written_resids = set()\n",
    "    with open(target_path, 'w') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            resid = int(row['resid'])\n",
    "            if resid in written_resids: continue\n",
    "            x, y, z = row.get(f'x_{xyz_id}'), row.get(f'y_{xyz_id}'), row.get(f'z_{xyz_id}')\n",
    "            if pd.notna(x) and x > -1e17:\n",
    "                resolved_cnt += 1\n",
    "                f.write(write_target_line( \"C1'\", resid, row['resname'], 'A', resid, x, y, z))\n",
    "                written_resids.add(resid)\n",
    "    return resolved_cnt\n",
    "\n",
    "\n",
    "def get_base_target_id(long_id):\n",
    "    \"\"\"Correctly extracts the base target ID (e.g., '9L5R_2') from a full ID ('9L5R_2_1').\"\"\"\n",
    "    return \"_\".join(str(long_id).split(\"_\")[:-1])\n",
    "\n",
    "def score_and_report(solution: pd.DataFrame, submission: pd.DataFrame):\n",
    "    solution['target_id'] = solution['ID'].apply(get_base_target_id)\n",
    "    submission['target_id'] = submission['ID'].apply(get_base_target_id)\n",
    "    \n",
    "    native_idxs = sorted(int(c.split('_')[1]) for c in solution.columns if c.startswith('x_'))\n",
    "    per_target, best_scores = {}, []\n",
    "\n",
    "    for tid, grp_nat in tqdm(solution.groupby('target_id'), desc=\"Scoring Targets\"):\n",
    "        grp_pred = submission[submission['target_id'] == tid]\n",
    "        if grp_pred.empty:\n",
    "            print(f\"Warning: No submission found for target {tid}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        best_of_five = []\n",
    "        for pred_cnt in range(1, 6):\n",
    "            best_for_this_pred = 0.0\n",
    "            for nat_cnt in native_idxs:\n",
    "                n_nat = write2pdb(grp_nat, nat_cnt, os.path.join(TEMP_DIR, 'native.pdb'))\n",
    "                n_pred = write2pdb(grp_pred, pred_cnt, os.path.join(TEMP_DIR, 'predicted.pdb'))\n",
    "                if n_nat > 0 and n_pred > 0:\n",
    "                    out = os.popen(f'{USALIGN_PATH} {os.path.join(TEMP_DIR, \"predicted.pdb\")} {os.path.join(TEMP_DIR, \"native.pdb\")} -atom \" C1\\'\"').read()\n",
    "                    score = parse_tmscore_output(out)\n",
    "                    if score is not None:\n",
    "                        best_for_this_pred = max(best_for_this_pred, score)\n",
    "            best_of_five.append(best_for_this_pred)\n",
    "        \n",
    "        per_target[tid] = best_of_five\n",
    "        best_scores.append(max(best_of_five))\n",
    "\n",
    "    overall = np.mean(best_scores)\n",
    "    print(f\"\\n>>> FINAL mean best-of-5 TM-score = {overall:.4f} (scored on {len(best_scores)} targets)\")\n",
    "    return per_target, overall\n",
    "\n",
    "def calculate_ground_truth_tm(pred_df, pred_idx, native_df):\n",
    "    \"\"\"Calculates the true TM-score for one prediction against ALL possible native structures.\"\"\"\n",
    "    best_tm_for_this_pred = 0.0\n",
    "    pred_path = os.path.join(TEMP_DIR, 'predicted_for_gt.pdb')\n",
    "    native_path = os.path.join(TEMP_DIR, 'native_for_gt.pdb')\n",
    "    \n",
    "    n_pred = write2pdb(pred_df, pred_idx, pred_path)\n",
    "    if n_pred == 0: return 0.0\n",
    "\n",
    "    native_indices = sorted(int(c.split('_')[1]) for c in native_df.columns if c.startswith('x_'))\n",
    "    for nat_idx in native_indices:\n",
    "        n_nat = write2pdb(native_df, nat_idx, native_path)\n",
    "        if n_nat > 0:\n",
    "            cmd = f'{USALIGN_PATH} {pred_path} {native_path} -atom \" C1\\'\"'\n",
    "            output = os.popen(cmd).read()\n",
    "            tm = parse_tmscore_output(output)\n",
    "            if tm is not None and tm > best_tm_for_this_pred:\n",
    "                best_tm_for_this_pred = tm\n",
    "    return best_tm_for_this_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d47d5399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration and model architecture defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "# Paths to the saved model and scaler from training\n",
    "MODEL_SAVE_PATH = 'meta_learner_model.pth'\n",
    "SCALER_SAVE_PATH = 'meta_learner_scaler.pkl'\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    'ProteinX': {\n",
    "        'predictions_path': '/home/max/Documents/Standford_3DRNA_PredictionData/Protenix_Baseline_Validation/submission.csv',\n",
    "        'confidences_path': '/home/max/Documents/Standford_3DRNA_PredictionData/Protenix_Baseline_Validation/confidence.csv',\n",
    "        'ranking_path': '/home/max/Documents/Standford_3DRNA_PredictionData/Protenix_Baseline_Validation/ranking_scores.csv'\n",
    "    },\n",
    "    'DrFo2': {\n",
    "        'predictions_path': '/home/max/Documents/Standford_3DRNA_PredictionData/DRfold2_Baseline_validation/submission.csv',\n",
    "        'confidences_path': '/home/max/Documents/Standford_3DRNA_PredictionData/DRfold2_Baseline_validation/confidence.csv',\n",
    "        'ranking_path': None\n",
    "    },\n",
    "    'Ribonanza': {\n",
    "        # Both predictions and confidences are in this one file\n",
    "        'predictions_path': '/home/max/Documents/Standford_3DRNA_PredictionData/Ribonanza_Baseline_Validation/ribonanzanet2_submission_with_confidence.csv',\n",
    "        'confidences_path': '/home/max/Documents/Standford_3DRNA_PredictionData/Ribonanza_Baseline_Validation/ribonanzanet2_submission_with_confidence.csv',\n",
    "        'ranking_path': None\n",
    "    }\n",
    "}\n",
    "\n",
    "SEQUENCES_PATH = '/home/max/Documents/Protenix-KaggleRNA3D/data/stanford-rna-3d-folding/validation_sequences_clean.csv'\n",
    "LABELS_PATH = '/home/max/Documents/Protenix-KaggleRNA3D/data/stanford-rna-3d-folding/validation_labels_clean.csv'\n",
    "\n",
    "# Constants\n",
    "NUM_PREDICTIONS_PER_MODEL = 5\n",
    "NUCLEOTIDES = ['A', 'C', 'G', 'U']\n",
    "\n",
    "# --- Define the NN Architecture (must match the trained model) ---\n",
    "class MetaLearnerNN(nn.Module):\n",
    "    def __init__(self, input_features):\n",
    "        super(MetaLearnerNN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            \n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x): return self.layers(x)\n",
    "\n",
    "print(\"✅ Configuration and model architecture defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "064c9a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from typing import Dict\n",
    "import numpy as np\n",
    "\n",
    "class RNAEnergyScorer:\n",
    "    def __init__(self, clash_penalty: float = 10.0):\n",
    "        self.CLASH_PENALTY = clash_penalty\n",
    "        self.VDW_RADIUS_C1 = 1.7\n",
    "        self.SOLVATION_CUTOFF = 6.0\n",
    "        self.BASE_PAIR_CUTOFF = 4.5\n",
    "        self.BASE_PAIR_ENERGIES = {\n",
    "            ('A', 'U'): -2.0, ('U', 'A'): -2.0,\n",
    "            ('G', 'C'): -3.0, ('C', 'G'): -3.0,\n",
    "            ('G', 'U'): -1.5, ('U', 'G'): -1.5,\n",
    "        }\n",
    "\n",
    "    def _calculate_vdw_energy(self, coords: np.ndarray) -> float:\n",
    "        if coords.shape[0] < 2:\n",
    "            return 0.0\n",
    "\n",
    "        distances = cdist(coords, coords)\n",
    "        sigma = self.VDW_RADIUS_C1 * 2\n",
    "        r = distances[np.triu_indices_from(distances, k=1)]\n",
    "        r = r[r > 0.1]\n",
    "\n",
    "        clashes = np.sum(r < 1.0) * self.CLASH_PENALTY\n",
    "\n",
    "        ratio = sigma / r\n",
    "        repulsive_term = np.sum(np.minimum(ratio**12, 1e6))\n",
    "        attractive_term = np.sum(ratio**6)\n",
    "\n",
    "        return (repulsive_term - attractive_term) + clashes\n",
    "\n",
    "    def _calculate_solvation_energy(self, coords: np.ndarray) -> float:\n",
    "        if coords.shape[0] < 2:\n",
    "            return 0.0\n",
    "\n",
    "        distances = cdist(coords, coords)\n",
    "        neighbor_counts = np.sum((distances > 0) & (distances < self.SOLVATION_CUTOFF), axis=1)\n",
    "        exposure_factors = 1.0 - np.minimum(neighbor_counts, 12) / 12.0\n",
    "        return -np.sum(exposure_factors)\n",
    "\n",
    "    def _calculate_base_pair_energy(self, sequence: str, coords: np.ndarray) -> float:\n",
    "        if len(sequence) != coords.shape[0]:\n",
    "            return 0.0\n",
    "\n",
    "        energy = 0.0\n",
    "        distances = cdist(coords, coords)\n",
    "\n",
    "        for i in range(len(sequence)):\n",
    "            potential_partners = np.where(\n",
    "                (distances[i] < self.BASE_PAIR_CUTOFF) & (np.abs(np.arange(len(sequence)) - i) > 2)\n",
    "            )[0]\n",
    "\n",
    "            for j in potential_partners:\n",
    "                if i >= j:\n",
    "                    continue\n",
    "                pair = (sequence[i], sequence[j])\n",
    "                if pair in self.BASE_PAIR_ENERGIES:\n",
    "                    weight = 1.0 - (distances[i, j] / self.BASE_PAIR_CUTOFF)\n",
    "                    energy += self.BASE_PAIR_ENERGIES[pair] * weight\n",
    "        return energy\n",
    "\n",
    "    def calculate_all_energies(self, sequence: str, coords: np.ndarray) -> Dict[str, float]:\n",
    "        if coords.shape[0] == 0:\n",
    "            return {'e_vdw': 0.0, 'e_solvation': 0.0, 'e_base_pair': 0.0}\n",
    "\n",
    "        return {\n",
    "            'e_vdw': self._calculate_vdw_energy(coords),\n",
    "            'e_solvation': self._calculate_solvation_energy(coords),\n",
    "            'e_base_pair': self._calculate_base_pair_energy(sequence, coords)\n",
    "        }\n",
    "\n",
    "def extract_energy_features(sequence: str, coords: np.ndarray, scorer: RNAEnergyScorer) -> Dict[str, float]:\n",
    "    if coords.shape[0] == 0 or len(sequence) == 0:\n",
    "        return {\n",
    "            'e_vdw': 0.0, 'e_solvation': 0.0, 'e_base_pair': 0.0,\n",
    "            'e_balance': 0.0, 'e_attractive_per_res': 0.0, 'e_repulsive_per_res': 0.0\n",
    "        }\n",
    "\n",
    "    energies = scorer.calculate_all_energies(sequence, coords)\n",
    "    e_attractive = energies['e_solvation'] + energies['e_base_pair']\n",
    "    e_repulsive = energies['e_vdw']\n",
    "\n",
    "    return {\n",
    "        'e_vdw': e_repulsive,\n",
    "        'e_solvation': energies['e_solvation'],\n",
    "        'e_base_pair': energies['e_base_pair'],\n",
    "        'e_balance': e_attractive / (e_repulsive + 1e-6),\n",
    "        'e_attractive_per_res': e_attractive / len(sequence),\n",
    "        'e_repulsive_per_res': e_repulsive / len(sequence)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db67743a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading and Pre-processing All Data ---\n",
      "All data files loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Load and Pre-process All Data ---\n",
    "print(\"--- Step 1: Loading and Pre-processing All Data ---\")\n",
    "try:\n",
    "    df_sequences = pd.read_csv(SEQUENCES_PATH)\n",
    "    df_labels = pd.read_csv(LABELS_PATH)\n",
    "    df_labels['target_id'] = df_labels['ID'].apply(get_base_target_id)\n",
    "    \n",
    "    data_dfs = {}\n",
    "    for model_name, config in MODEL_CONFIG.items():\n",
    "        if model_name == 'Ribonanza':\n",
    "            df_raw = pd.read_csv(config['predictions_path'])\n",
    "            pred_cols = ['ID', 'resname', 'resid'] + [col for col in df_raw.columns if col.startswith(('x_', 'y_', 'z_'))]\n",
    "            data_dfs[f'{model_name}_preds'] = df_raw[pred_cols].copy()\n",
    "            rename_dict = {f'confidence_{i}': f'plddt_{i}' for i in range(1, NUM_PREDICTIONS_PER_MODEL + 1)}\n",
    "            data_dfs[f'{model_name}_conf'] = df_raw.rename(columns=rename_dict)\n",
    "        else:\n",
    "            data_dfs[f'{model_name}_preds'] = pd.read_csv(config['predictions_path'])\n",
    "            data_dfs[f'{model_name}_conf'] = pd.read_csv(config['confidences_path'])\n",
    "        \n",
    "        if config.get('ranking_path'):\n",
    "            data_dfs[f'{model_name}_rank'] = pd.read_csv(config['ranking_path'])\n",
    "\n",
    "    print(\"All data files loaded.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"FATAL ERROR: Cannot load a data file: {e}.\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f52c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Final Feature Generation for Inference ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d570abf0d3454f318b373355ee8fc0d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Targets:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Feature Set Generation Complete ---\n",
      "Total features generated: 29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_id</th>\n",
       "      <th>model_source_str</th>\n",
       "      <th>prediction_index</th>\n",
       "      <th>sequence_length</th>\n",
       "      <th>percent_A</th>\n",
       "      <th>percent_C</th>\n",
       "      <th>percent_G</th>\n",
       "      <th>percent_U</th>\n",
       "      <th>std_plddt</th>\n",
       "      <th>ptm</th>\n",
       "      <th>...</th>\n",
       "      <th>std_plddt_x_Ribonanza</th>\n",
       "      <th>rog_norm_x_Ribonanza</th>\n",
       "      <th>low_conf_x_Ribonanza</th>\n",
       "      <th>e_vdw</th>\n",
       "      <th>e_solvation</th>\n",
       "      <th>e_base_pair</th>\n",
       "      <th>e_balance</th>\n",
       "      <th>e_attractive_per_res</th>\n",
       "      <th>e_repulsive_per_res</th>\n",
       "      <th>model_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9L5R_2</td>\n",
       "      <td>ProteinX</td>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "      <td>0.170984</td>\n",
       "      <td>0.26943</td>\n",
       "      <td>0.217617</td>\n",
       "      <td>0.341969</td>\n",
       "      <td>6.674131</td>\n",
       "      <td>0.500917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.105778</td>\n",
       "      <td>-164.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.588554</td>\n",
       "      <td>-0.852332</td>\n",
       "      <td>-0.062724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9L5R_2</td>\n",
       "      <td>ProteinX</td>\n",
       "      <td>2</td>\n",
       "      <td>193</td>\n",
       "      <td>0.170984</td>\n",
       "      <td>0.26943</td>\n",
       "      <td>0.217617</td>\n",
       "      <td>0.341969</td>\n",
       "      <td>6.291851</td>\n",
       "      <td>0.391554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.341462</td>\n",
       "      <td>-164.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.302044</td>\n",
       "      <td>-0.850604</td>\n",
       "      <td>-0.063945</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9L5R_2</td>\n",
       "      <td>ProteinX</td>\n",
       "      <td>3</td>\n",
       "      <td>193</td>\n",
       "      <td>0.170984</td>\n",
       "      <td>0.26943</td>\n",
       "      <td>0.217617</td>\n",
       "      <td>0.341969</td>\n",
       "      <td>6.346398</td>\n",
       "      <td>0.425882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.055151</td>\n",
       "      <td>-164.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.895019</td>\n",
       "      <td>-0.853195</td>\n",
       "      <td>-0.057281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9L5R_2</td>\n",
       "      <td>ProteinX</td>\n",
       "      <td>4</td>\n",
       "      <td>193</td>\n",
       "      <td>0.170984</td>\n",
       "      <td>0.26943</td>\n",
       "      <td>0.217617</td>\n",
       "      <td>0.341969</td>\n",
       "      <td>6.726162</td>\n",
       "      <td>0.492399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.341723</td>\n",
       "      <td>-163.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.261251</td>\n",
       "      <td>-0.848014</td>\n",
       "      <td>-0.063947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9L5R_2</td>\n",
       "      <td>ProteinX</td>\n",
       "      <td>5</td>\n",
       "      <td>193</td>\n",
       "      <td>0.170984</td>\n",
       "      <td>0.26943</td>\n",
       "      <td>0.217617</td>\n",
       "      <td>0.341969</td>\n",
       "      <td>6.356630</td>\n",
       "      <td>0.480664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.924505</td>\n",
       "      <td>-164.000000</td>\n",
       "      <td>-0.969639</td>\n",
       "      <td>-10.359483</td>\n",
       "      <td>-0.854765</td>\n",
       "      <td>0.082510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  target_id model_source_str  prediction_index  sequence_length  percent_A  \\\n",
       "0    9L5R_2         ProteinX                 1              193   0.170984   \n",
       "1    9L5R_2         ProteinX                 2              193   0.170984   \n",
       "2    9L5R_2         ProteinX                 3              193   0.170984   \n",
       "3    9L5R_2         ProteinX                 4              193   0.170984   \n",
       "4    9L5R_2         ProteinX                 5              193   0.170984   \n",
       "\n",
       "   percent_C  percent_G  percent_U  std_plddt       ptm  ...  \\\n",
       "0    0.26943   0.217617   0.341969   6.674131  0.500917  ...   \n",
       "1    0.26943   0.217617   0.341969   6.291851  0.391554  ...   \n",
       "2    0.26943   0.217617   0.341969   6.346398  0.425882  ...   \n",
       "3    0.26943   0.217617   0.341969   6.726162  0.492399  ...   \n",
       "4    0.26943   0.217617   0.341969   6.356630  0.480664  ...   \n",
       "\n",
       "   std_plddt_x_Ribonanza  rog_norm_x_Ribonanza  low_conf_x_Ribonanza  \\\n",
       "0                    0.0                   0.0                   0.0   \n",
       "1                    0.0                   0.0                   0.0   \n",
       "2                    0.0                   0.0                   0.0   \n",
       "3                    0.0                   0.0                   0.0   \n",
       "4                    0.0                   0.0                   0.0   \n",
       "\n",
       "       e_vdw  e_solvation  e_base_pair  e_balance  e_attractive_per_res  \\\n",
       "0 -12.105778  -164.500000     0.000000  13.588554             -0.852332   \n",
       "1 -12.341462  -164.166667     0.000000  13.302044             -0.850604   \n",
       "2 -11.055151  -164.666667     0.000000  14.895019             -0.853195   \n",
       "3 -12.341723  -163.666667     0.000000  13.261251             -0.848014   \n",
       "4  15.924505  -164.000000    -0.969639 -10.359483             -0.854765   \n",
       "\n",
       "   e_repulsive_per_res  model_source  \n",
       "0            -0.062724             0  \n",
       "1            -0.063945             0  \n",
       "2            -0.057281             0  \n",
       "3            -0.063947             0  \n",
       "4             0.082510             0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FINAL INFERENCE PIPELINE\n",
    "# =============================================================================\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Helper function to compute the RMSD matrix for clustering\n",
    "def calculate_pairwise_rmsd_matrix(coords_dict: Dict) -> (np.ndarray, list):\n",
    "    candidate_keys = list(coords_dict.keys())\n",
    "    coords_list = [coords_dict[key] for key in candidate_keys]\n",
    "    n = len(candidate_keys)\n",
    "    rmsd_matrix = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            if coords_list[i].shape[0] > 0 and coords_list[i].shape == coords_list[j].shape:\n",
    "                rmsd = calculate_rmsd(coords_list[i], coords_list[j])\n",
    "                rmsd_matrix[i, j] = rmsd\n",
    "                rmsd_matrix[j, i] = rmsd\n",
    "            else:\n",
    "                rmsd_matrix[i, j] = 999.0\n",
    "                rmsd_matrix[j, i] = 999.0\n",
    "                \n",
    "    return rmsd_matrix, candidate_keys\n",
    "\n",
    "# --- Step 1: Feature Generation ---\n",
    "print(\"--- Starting Final Feature Generation for Inference ---\")\n",
    "# Initialize the custom energy scorer\n",
    "energy_scorer = RNAEnergyScorer()\n",
    "meta_data_rows = []\n",
    "all_target_ids_in_sequence_file = df_sequences['target_id'].unique()\n",
    "\n",
    "for target_id in tqdm(all_target_ids_in_sequence_file, desc=\"Processing Targets\"):\n",
    "    sequence_row = df_sequences[df_sequences['target_id'] == target_id]\n",
    "    if sequence_row.empty: continue\n",
    "    sequence = sequence_row.iloc[0]['sequence']\n",
    "    \n",
    "    all_candidate_coords = {}\n",
    "    for model_name in MODEL_CONFIG:\n",
    "        target_preds = data_dfs[f'{model_name}_preds'][data_dfs[f'{model_name}_preds']['ID'].str.startswith(target_id)]\n",
    "        if target_preds.empty: continue\n",
    "        for i in range(1, NUM_PREDICTIONS_PER_MODEL + 1):\n",
    "            all_candidate_coords[f'{model_name}_{i}'] = get_coords(target_preds, i)\n",
    "\n",
    "    cluster_info = {}\n",
    "    if len(all_candidate_coords) > 1:\n",
    "        rmsd_matrix, candidate_keys = calculate_pairwise_rmsd_matrix(all_candidate_coords)\n",
    "        dbscan = DBSCAN(eps=7.5, min_samples=2, metric='precomputed', n_jobs=-1)\n",
    "        cluster_labels = dbscan.fit_predict(rmsd_matrix)\n",
    "        num_clusters_found = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)\n",
    "        labels_series = pd.Series(cluster_labels)\n",
    "        cluster_sizes = labels_series.value_counts().to_dict()\n",
    "        for k_idx, key in enumerate(candidate_keys):\n",
    "            label = cluster_labels[k_idx]\n",
    "            cluster_info[key] = {\n",
    "                'cluster_label': label,\n",
    "                'is_outlier': 1 if label == -1 else 0,\n",
    "                'cluster_size': cluster_sizes.get(label, 0),\n",
    "                'num_clusters_total': num_clusters_found\n",
    "            }\n",
    "\n",
    "    for model_name in MODEL_CONFIG:\n",
    "        df_conf = data_dfs[f'{model_name}_conf']\n",
    "        target_confs = df_conf[df_conf['ID'].str.startswith(target_id)]\n",
    "        if target_confs.empty: continue\n",
    "        df_rank = data_dfs.get(f'{model_name}_rank')\n",
    "        target_rank = df_rank[df_rank['target_id'] == target_id] if df_rank is not None else None\n",
    "\n",
    "        for i in range(1, NUM_PREDICTIONS_PER_MODEL + 1):\n",
    "            candidate_key = f'{model_name}_{i}'\n",
    "            if f'plddt_{i}' not in target_confs.columns or candidate_key not in all_candidate_coords:\n",
    "                continue\n",
    "            \n",
    "            features = {'target_id': target_id, 'model_source_str': model_name, 'prediction_index': i}\n",
    "            \n",
    "            # Base Features\n",
    "            features['sequence_length'] = len(sequence)\n",
    "            for nuc in NUCLEOTIDES: features[f'percent_{nuc}'] = sequence.count(nuc) / len(sequence)\n",
    "            plddt_scores = target_confs[f'plddt_{i}'].values\n",
    "            features['std_plddt'] = np.std(plddt_scores)\n",
    "            if target_rank is not None and not target_rank.empty:\n",
    "                features.update({'ptm': target_rank.iloc[0].get(f'ptm_{i}', 0), 'ranking_score': target_rank.iloc[0].get(f'ranking_score_{i}', 0)})\n",
    "            else:\n",
    "                features.update({'ptm': 0, 'ranking_score': 0})\n",
    "\n",
    "            # Structural, Ensemble, and Engineered Features\n",
    "            candidate_coords = all_candidate_coords[candidate_key]\n",
    "            if candidate_coords is None or candidate_coords.shape[0] == 0: continue\n",
    "            \n",
    "            rmsd_to_others = [calculate_rmsd(candidate_coords, other_coords) for key, other_coords in all_candidate_coords.items() if key != candidate_key]\n",
    "            features['avg_rmsd_to_others'] = np.nanmean(rmsd_to_others)\n",
    "            info = cluster_info.get(candidate_key, {})\n",
    "            features['is_outlier'] = info.get('is_outlier', 1)\n",
    "            features['cluster_size'] = info.get('cluster_size', 0)\n",
    "            features['num_clusters_total'] = info.get('num_clusters_total', 0)\n",
    "            if features['sequence_length'] > 0:\n",
    "                features['rog_normalized'] = calculate_radius_of_gyration(candidate_coords) / np.sqrt(features['sequence_length'])\n",
    "            else:\n",
    "                features['rog_normalized'] = 0.0\n",
    "\n",
    "            # Model-Specific Interaction Features\n",
    "            base_plddt_std = features['std_plddt']\n",
    "            base_rog_norm = features['rog_normalized']\n",
    "            base_percent_low_conf = np.mean(plddt_scores < 70)\n",
    "            for source in MODEL_CONFIG.keys():\n",
    "                features[f'std_plddt_x_{source}'] = 0.0\n",
    "                features[f'rog_norm_x_{source}'] = 0.0\n",
    "                features[f'low_conf_x_{source}'] = 0.0\n",
    "            features[f'std_plddt_x_{model_name}'] = base_plddt_std\n",
    "            features[f'rog_norm_x_{model_name}'] = base_rog_norm\n",
    "            features[f'low_conf_x_{model_name}'] = base_percent_low_conf\n",
    "\n",
    "            # Final Energy Features\n",
    "            try:\n",
    "                energy_features = extract_energy_features(sequence, candidate_coords, energy_scorer)\n",
    "                features.update(energy_features)\n",
    "            except Exception as e:\n",
    "                null_energy = {'e_vdw': 0.0, 'e_solvation': 0.0, 'e_base_pair': 0.0,\n",
    "                               'e_balance': 0.0, 'e_attractive_per_res': 0.0, 'e_repulsive_per_res': 0.0}\n",
    "                features.update(null_energy)\n",
    "            \n",
    "            meta_data_rows.append(features)\n",
    "\n",
    "# --- Step 2: Finalize DataFrame ---\n",
    "if not meta_data_rows:\n",
    "    raise ValueError(\"FATAL ERROR: No feature rows were generated.\")\n",
    "\n",
    "# This is the full dataframe with all generated columns, used for submission assembly and analysis\n",
    "df_inference = pd.DataFrame(meta_data_rows)\n",
    "model_mapping = {name: i for i, name in enumerate(MODEL_CONFIG.keys())}\n",
    "df_inference['model_source'] = df_inference['model_source_str'].map(model_mapping)\n",
    "df_inference.fillna(df_inference.median(numeric_only=True), inplace=True)\n",
    "\n",
    "print(\"\\n--- Final Feature Set Generation Complete ---\")\n",
    "print(f\"Total features generated: {len(df_inference.columns) - 3}\")\n",
    "display(df_inference.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38ffa1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading models and making predictions... ---\n",
      "✅ Top 5 candidates selected for each target.\n",
      "Total selected structures: 470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_401009/1446237388.py:33: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_top5 = df_inference.groupby('target_id').apply(lambda x: x.nlargest(5, 'predicted_tm')).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_id</th>\n",
       "      <th>model_source_str</th>\n",
       "      <th>prediction_index</th>\n",
       "      <th>predicted_tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8K85_A</td>\n",
       "      <td>Ribonanza</td>\n",
       "      <td>4</td>\n",
       "      <td>0.880325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8K85_A</td>\n",
       "      <td>Ribonanza</td>\n",
       "      <td>3</td>\n",
       "      <td>0.880277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8K85_A</td>\n",
       "      <td>Ribonanza</td>\n",
       "      <td>5</td>\n",
       "      <td>0.879872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8K85_A</td>\n",
       "      <td>Ribonanza</td>\n",
       "      <td>2</td>\n",
       "      <td>0.879004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8K85_A</td>\n",
       "      <td>Ribonanza</td>\n",
       "      <td>1</td>\n",
       "      <td>0.878701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8KEB_A</td>\n",
       "      <td>Ribonanza</td>\n",
       "      <td>4</td>\n",
       "      <td>0.826261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8KEB_A</td>\n",
       "      <td>Ribonanza</td>\n",
       "      <td>5</td>\n",
       "      <td>0.825076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8KEB_A</td>\n",
       "      <td>ProteinX</td>\n",
       "      <td>5</td>\n",
       "      <td>0.597488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8KEB_A</td>\n",
       "      <td>ProteinX</td>\n",
       "      <td>1</td>\n",
       "      <td>0.596196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8KEB_A</td>\n",
       "      <td>ProteinX</td>\n",
       "      <td>2</td>\n",
       "      <td>0.583674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target_id model_source_str  prediction_index  predicted_tm\n",
       "0    8K85_A        Ribonanza                 4      0.880325\n",
       "1    8K85_A        Ribonanza                 3      0.880277\n",
       "2    8K85_A        Ribonanza                 5      0.879872\n",
       "3    8K85_A        Ribonanza                 2      0.879004\n",
       "4    8K85_A        Ribonanza                 1      0.878701\n",
       "5    8KEB_A        Ribonanza                 4      0.826261\n",
       "6    8KEB_A        Ribonanza                 5      0.825076\n",
       "7    8KEB_A         ProteinX                 5      0.597488\n",
       "8    8KEB_A         ProteinX                 1      0.596196\n",
       "9    8KEB_A         ProteinX                 2      0.583674"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Step 2: Predict with Model and Select Top 5 (CORRECTED) ---\n",
    "print(\"--- Loading models and making predictions... ---\")\n",
    "\n",
    "# Load the fitted scaler and model\n",
    "scaler = joblib.load(SCALER_SAVE_PATH)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MetaLearnerNN(input_features=scaler.n_features_in_).to(device)\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "model.eval()\n",
    "\n",
    "try:\n",
    "    X_inference = df_inference[scaler.feature_names_in_]\n",
    "except KeyError as e:\n",
    "    print(f\"ERROR: A feature is missing from the inference data that was present in training: {e}\")\n",
    "    # This is a fallback to help debug if the columns still don't match\n",
    "    print(\"\\nFeatures in inference data:\", df_inference.columns.tolist())\n",
    "    print(\"Features expected by scaler:\", scaler.feature_names_in_)\n",
    "    raise e\n",
    "\n",
    "# Scale the inference data\n",
    "X_inference_scaled = scaler.transform(X_inference)\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(X_inference_scaled, dtype=torch.float32).to(device)\n",
    "    predicted_scores = model(X_tensor).cpu().numpy().flatten()\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "df_inference['predicted_tm'] = predicted_scores\n",
    "\n",
    "# --- Core Selection Logic ---\n",
    "# For each target_id, find the 5 candidates with the highest predicted score\n",
    "df_top5 = df_inference.groupby('target_id').apply(lambda x: x.nlargest(5, 'predicted_tm')).reset_index(drop=True)\n",
    "\n",
    "print(\"✅ Top 5 candidates selected for each target.\")\n",
    "print(f\"Total selected structures: {len(df_top5)}\")\n",
    "display(df_top5[['target_id', 'model_source_str', 'prediction_index', 'predicted_tm']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c192d0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Assembling final submission file with robust merging... ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7cfcf4c3c54ea29f597311daf8c7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Assembling Submission:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembled submission file 'ensembled_submission.csv' created successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resid</th>\n",
       "      <th>ID</th>\n",
       "      <th>resname</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>z_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>y_3</th>\n",
       "      <th>z_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>y_4</th>\n",
       "      <th>z_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>y_5</th>\n",
       "      <th>z_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8K85_A_1</td>\n",
       "      <td>G</td>\n",
       "      <td>-10.031795</td>\n",
       "      <td>21.430502</td>\n",
       "      <td>24.104576</td>\n",
       "      <td>11.359874</td>\n",
       "      <td>19.273932</td>\n",
       "      <td>-24.725073</td>\n",
       "      <td>1.739657</td>\n",
       "      <td>25.807976</td>\n",
       "      <td>-21.325783</td>\n",
       "      <td>-25.030249</td>\n",
       "      <td>-3.009271</td>\n",
       "      <td>22.493553</td>\n",
       "      <td>-11.122301</td>\n",
       "      <td>25.338013</td>\n",
       "      <td>20.354237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8K85_A_2</td>\n",
       "      <td>G</td>\n",
       "      <td>-12.683558</td>\n",
       "      <td>19.124477</td>\n",
       "      <td>19.230865</td>\n",
       "      <td>11.292404</td>\n",
       "      <td>13.435502</td>\n",
       "      <td>-24.485357</td>\n",
       "      <td>2.243749</td>\n",
       "      <td>20.615433</td>\n",
       "      <td>-21.924036</td>\n",
       "      <td>-22.164127</td>\n",
       "      <td>-6.809379</td>\n",
       "      <td>19.551247</td>\n",
       "      <td>-6.083194</td>\n",
       "      <td>22.807205</td>\n",
       "      <td>19.369934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8K85_A_3</td>\n",
       "      <td>A</td>\n",
       "      <td>-13.850716</td>\n",
       "      <td>18.713408</td>\n",
       "      <td>14.441497</td>\n",
       "      <td>12.951257</td>\n",
       "      <td>9.367302</td>\n",
       "      <td>-22.206780</td>\n",
       "      <td>4.780207</td>\n",
       "      <td>16.301336</td>\n",
       "      <td>-21.403898</td>\n",
       "      <td>-21.007872</td>\n",
       "      <td>-9.346490</td>\n",
       "      <td>15.168128</td>\n",
       "      <td>-2.446923</td>\n",
       "      <td>19.225378</td>\n",
       "      <td>19.853275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8K85_A_4</td>\n",
       "      <td>G</td>\n",
       "      <td>-12.531183</td>\n",
       "      <td>18.946608</td>\n",
       "      <td>9.559502</td>\n",
       "      <td>15.312449</td>\n",
       "      <td>6.391326</td>\n",
       "      <td>-18.453760</td>\n",
       "      <td>8.139541</td>\n",
       "      <td>12.631317</td>\n",
       "      <td>-19.601051</td>\n",
       "      <td>-20.436550</td>\n",
       "      <td>-9.683000</td>\n",
       "      <td>9.947579</td>\n",
       "      <td>-0.673806</td>\n",
       "      <td>14.225980</td>\n",
       "      <td>20.273897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8K85_A_5</td>\n",
       "      <td>A</td>\n",
       "      <td>-10.470436</td>\n",
       "      <td>19.030570</td>\n",
       "      <td>4.495241</td>\n",
       "      <td>17.220327</td>\n",
       "      <td>4.177942</td>\n",
       "      <td>-13.849748</td>\n",
       "      <td>11.442865</td>\n",
       "      <td>9.733561</td>\n",
       "      <td>-16.639530</td>\n",
       "      <td>-20.069801</td>\n",
       "      <td>-9.160627</td>\n",
       "      <td>4.501581</td>\n",
       "      <td>0.640619</td>\n",
       "      <td>8.873339</td>\n",
       "      <td>20.482450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   resid        ID resname        x_1        y_1        z_1        x_2  \\\n",
       "0      1  8K85_A_1       G -10.031795  21.430502  24.104576  11.359874   \n",
       "1      2  8K85_A_2       G -12.683558  19.124477  19.230865  11.292404   \n",
       "2      3  8K85_A_3       A -13.850716  18.713408  14.441497  12.951257   \n",
       "3      4  8K85_A_4       G -12.531183  18.946608   9.559502  15.312449   \n",
       "4      5  8K85_A_5       A -10.470436  19.030570   4.495241  17.220327   \n",
       "\n",
       "         y_2        z_2        x_3        y_3        z_3        x_4       y_4  \\\n",
       "0  19.273932 -24.725073   1.739657  25.807976 -21.325783 -25.030249 -3.009271   \n",
       "1  13.435502 -24.485357   2.243749  20.615433 -21.924036 -22.164127 -6.809379   \n",
       "2   9.367302 -22.206780   4.780207  16.301336 -21.403898 -21.007872 -9.346490   \n",
       "3   6.391326 -18.453760   8.139541  12.631317 -19.601051 -20.436550 -9.683000   \n",
       "4   4.177942 -13.849748  11.442865   9.733561 -16.639530 -20.069801 -9.160627   \n",
       "\n",
       "         z_4        x_5        y_5        z_5  \n",
       "0  22.493553 -11.122301  25.338013  20.354237  \n",
       "1  19.551247  -6.083194  22.807205  19.369934  \n",
       "2  15.168128  -2.446923  19.225378  19.853275  \n",
       "3   9.947579  -0.673806  14.225980  20.273897  \n",
       "4   4.501581   0.640619   8.873339  20.482450  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Step 3: Assemble the Ensembled Submission File (CORRECTED) ---\n",
    "print(\"--- Assembling final submission file with robust merging... ---\")\n",
    "\n",
    "final_submission_rows = []\n",
    "# Group by target_id to process one RNA at a time\n",
    "for target_id, group in tqdm(df_top5.groupby('target_id'), desc=\"Assembling Submission\"):\n",
    "    \n",
    "    # Get the base information (ID, resname, resid) from any of the original prediction files.\n",
    "    # Set 'resid' as the index to prepare for clean assignment.\n",
    "    base_info = data_dfs['ProteinX_preds'][data_dfs['ProteinX_preds']['ID'].str.startswith(f\"{target_id}_\")]\n",
    "    if base_info.empty:\n",
    "        base_info = data_dfs['DrFo2_preds'][data_dfs['DrFo2_preds']['ID'].str.startswith(f\"{target_id}_\")]\n",
    "        \n",
    "    target_submission_df = base_info[['ID', 'resname', 'resid']].copy().set_index('resid')\n",
    "    \n",
    "    # Iterate from k=1 to 5 to create the new columns x_1, y_1, z_1 ... x_5, y_5, z_5\n",
    "    for k, (_, selection_row) in enumerate(group.iterrows(), 1):\n",
    "        \n",
    "        source_model = selection_row['model_source_str']\n",
    "        original_pred_idx = selection_row['prediction_index']\n",
    "        \n",
    "        # Get the original coordinate data for this selection\n",
    "        original_coords_df = data_dfs[f'{source_model}_preds'][data_dfs[f'{source_model}_preds']['ID'].str.startswith(f\"{target_id}_\")]\n",
    "        \n",
    "        # Prepare the coordinates to add, with 'resid' as the index\n",
    "        coords_to_add = original_coords_df[['resid', f'x_{original_pred_idx}', f'y_{original_pred_idx}', f'z_{original_pred_idx}']].copy()\n",
    "        coords_to_add = coords_to_add.set_index('resid')\n",
    "        \n",
    "        # Assign the new columns. This is safer than merging.\n",
    "        target_submission_df[f'x_{k}'] = coords_to_add[f'x_{original_pred_idx}']\n",
    "        target_submission_df[f'y_{k}'] = coords_to_add[f'y_{original_pred_idx}']\n",
    "        target_submission_df[f'z_{k}'] = coords_to_add[f'z_{original_pred_idx}']\n",
    "        \n",
    "    # Reset the index to make 'resid' a column again, matching the submission format\n",
    "    final_submission_rows.append(target_submission_df.reset_index())\n",
    "\n",
    "# Concatenate all targets into the final submission dataframe\n",
    "if final_submission_rows:\n",
    "    ensembled_submission_df = pd.concat(final_submission_rows)\n",
    "    ensembled_submission_df.to_csv('ensembled_submission.csv', index=False)\n",
    "    print(\"Ensembled submission file 'ensembled_submission.csv' created successfully.\")\n",
    "    display(ensembled_submission_df.head())\n",
    "else:\n",
    "    print(\"ERROR: No data was assembled for the final submission.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55f38b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating the performance of the meta-learner ensemble... ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0c8bf7172945b08b8bcbca6812297f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring Targets:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> FINAL mean best-of-5 TM-score = 0.4725 (scored on 94 targets)\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Evaluate the Final Result ---\n",
    "print(\"--- Evaluating the performance of the meta-learner ensemble... ---\")\n",
    "\n",
    "# Load the ground truth labels\n",
    "solution_df = pd.read_csv(LABELS_PATH)\n",
    "\n",
    "# The submission dataframe is the one we just created\n",
    "submission_df = pd.read_csv('ensembled_submission.csv')\n",
    "\n",
    "# Run the scoring\n",
    "_, final_score = score_and_report(solution_df, submission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd0db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- In-Depth Ensemble Performance Analysis ---\n",
      "Calculating ground truth TM-scores for analysis (efficiently)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae915f1cc4c4af99c29f3dae1d6a29f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating True TM-scores:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Analysis data prepared successfully.\n",
      "\n",
      "✅ True TM-scores calculated and merged successfully.\n",
      "1. Oracle Score (Theoretical Max): 0.5021\n",
      "2. Your Model's Achieved Score:     0.4725\n",
      "   (Your model achieved 94.11% of the theoretical maximum performance)\n",
      "\n",
      "3. Recall@5 (Found the single best candidate): 54.26% (51/94 targets)\n",
      "\n",
      "4. Distribution of Models in Your Final Top 5 Selection:\n",
      "model_source_str\n",
      "Ribonanza    0.538298\n",
      "ProteinX     0.259574\n",
      "DrFo2        0.202128\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "5. Model Performance Analysis (Avg Predicted vs. True TM-score):\n",
      "                  avg_predicted_tm  avg_true_tm  count\n",
      "model_source_str                                      \n",
      "ProteinX                  0.396947     0.403984    470\n",
      "DrFo2                     0.386938     0.353896    470\n",
      "Ribonanza                 0.426319     0.319214    470\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ANALYSIS CELL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n--- In-Depth Ensemble Performance Analysis ---\")\n",
    "\n",
    "# Step 1: Calculate the true TM-score for every candidate in df_inference.\n",
    "print(\"Calculating ground truth TM-scores for analysis (efficiently)...\")\n",
    "\n",
    "# This list will store small dataframes, each with results for one target\n",
    "all_target_results = []\n",
    "\n",
    "# Get the list of unique targets from the inference results\n",
    "unique_targets_to_analyze = df_inference['target_id'].unique()\n",
    "\n",
    "for target_id in tqdm(unique_targets_to_analyze, desc=\"Calculating True TM-scores\"):\n",
    "    # Get the slice of predictions for this one target\n",
    "    inference_slice = df_inference[df_inference['target_id'] == target_id].copy()\n",
    "    \n",
    "    # Get the corresponding labels once for this target\n",
    "    native_df_for_target = df_labels[df_labels['ID'].apply(get_base_target_id) == target_id]\n",
    "    \n",
    "    # This list will hold the calculated true TM-scores for this target\n",
    "    true_scores = []\n",
    "    \n",
    "    # Iterate through the rows of the slice (15 rows per target)\n",
    "    for _, row in inference_slice.iterrows():\n",
    "        model_name = row['model_source_str']\n",
    "        pred_idx = row['prediction_index']\n",
    "        \n",
    "        # Get the prediction data for the specific model\n",
    "        pred_df_for_target = data_dfs[f'{model_name}_preds'][data_dfs[f'{model_name}_preds']['ID'].apply(get_base_target_id) == target_id]\n",
    "\n",
    "        if native_df_for_target.empty or pred_df_for_target.empty:\n",
    "            tm_score = np.nan\n",
    "        else:\n",
    "            tm_score = calculate_ground_truth_tm(pred_df_for_target, pred_idx, native_df_for_target)\n",
    "            \n",
    "        true_scores.append(tm_score)\n",
    "        \n",
    "    # Add the list of scores as a new column to the slice\n",
    "    inference_slice['true_tm_score'] = true_scores\n",
    "    all_target_results.append(inference_slice)\n",
    "\n",
    "# Concatenate all the small dataframes back into one\n",
    "df_analysis = pd.concat(all_target_results)\n",
    "\n",
    "print(\"✅ Analysis data prepared successfully.\")\n",
    "\n",
    "# --- DEBUGGING CHECK ---\n",
    "if df_analysis['true_tm_score'].isnull().all():\n",
    "    print(\"\\n❌ CRITICAL ERROR: Could not calculate any true TM-scores.\")\n",
    "else:\n",
    "    print(\"\\n✅ True TM-scores calculated and merged successfully.\")\n",
    "    \n",
    "    # --- Metric 1: \"Oracle Score\" ---\n",
    "    oracle_best_scores = df_analysis.groupby('target_id')['true_tm_score'].max()\n",
    "    oracle_score = oracle_best_scores.mean()\n",
    "    print(f\"1. Oracle Score (Theoretical Max): {oracle_score:.4f}\")\n",
    "\n",
    "    # --- Metric 2: Your Model's Achieved Score ---\n",
    "    print(f\"2. Your Model's Achieved Score:     {final_score:.4f}\")\n",
    "    if oracle_score > 0:\n",
    "        print(f\"   (Your model achieved {final_score/oracle_score:.2%} of the theoretical maximum performance)\")\n",
    "\n",
    "    # --- Metric 3: Recall@5 ---\n",
    "    recall_hits = 0\n",
    "    total_targets = df_analysis['target_id'].nunique()\n",
    "    for target_id, group in df_analysis.groupby('target_id'):\n",
    "        if group['true_tm_score'].notna().any():\n",
    "            best_candidate_true_idx = group['true_tm_score'].idxmax()\n",
    "            top_5_predicted_indices = group.nlargest(5, 'predicted_tm').index\n",
    "            if best_candidate_true_idx in top_5_predicted_indices:\n",
    "                recall_hits += 1\n",
    "\n",
    "    if total_targets > 0:\n",
    "        recall_at_5 = recall_hits / total_targets\n",
    "        print(f\"\\n3. Recall@5 (Found the single best candidate): {recall_at_5:.2%} ({recall_hits}/{total_targets} targets)\")\n",
    "\n",
    "    # --- Metric 4: Distribution of selected models ---\n",
    "    print(\"\\n4. Distribution of Models in Your Final Top 5 Selection:\")\n",
    "    model_distribution = df_top5['model_source_str'].value_counts(normalize=True)\n",
    "    print(model_distribution)\n",
    "\n",
    "    # --- Metric 5: Average Predicted vs. True TM-score for each model ---\n",
    "    print(\"\\n5. Model Performance Analysis (Avg Predicted vs. True TM-score):\")\n",
    "    analysis_summary = df_analysis.groupby('model_source_str').agg(\n",
    "        avg_predicted_tm=('predicted_tm', 'mean'),\n",
    "        avg_true_tm=('true_tm_score', 'mean'),\n",
    "        count=('target_id', 'size')\n",
    "    ).sort_values(by='avg_true_tm', ascending=False)\n",
    "    print(analysis_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNA3D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
