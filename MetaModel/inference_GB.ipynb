{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3463cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Core Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys, re, joblib\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import lightgbm as lgb \n",
    "\n",
    "# --- Energy imports ---\n",
    "from scipy.spatial.distance import cdist\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "# --- Helper Functions (Copied from Training Notebook) ---\n",
    "USALIGN_PATH = \"/home/max/Documents/Protenix-KaggleRNA3D/af3-dev/USalign/USalign\"\n",
    "TEMP_DIR = \"./temp_pdb_inference/\"\n",
    "os.makedirs(TEMP_DIR, exist_ok=True)\n",
    "\n",
    "def get_coords(df, pred_idx):\n",
    "    return df[[f'x_{pred_idx}', f'y_{pred_idx}', f'z_{pred_idx}']].values\n",
    "\n",
    "def calculate_radius_of_gyration(coords):\n",
    "    center_of_mass = np.mean(coords, axis=0)\n",
    "    return np.sqrt(np.mean(np.sum((coords - center_of_mass)**2, axis=1)))\n",
    "\n",
    "def calculate_rmsd(coords1, coords2):\n",
    "    from scipy.spatial.transform import Rotation as R\n",
    "    if coords1.shape != coords2.shape: return np.nan\n",
    "    coords1_centered = coords1 - coords1.mean(axis=0)\n",
    "    coords2_centered = coords2 - coords2.mean(axis=0)\n",
    "    rotation, rmsd = R.align_vectors(coords1_centered, coords2_centered)\n",
    "    return rmsd\n",
    "\n",
    "# --- Final Evaluation Script (Provided by you) ---\n",
    "def parse_tmscore_output(output):\n",
    "    tm_score_match = re.findall(r'TM-score=\\s+([\\d.]+)', output)\n",
    "    if len(tm_score_match) > 1:\n",
    "        return float(tm_score_match[1])\n",
    "    return np.nan\n",
    "\n",
    "def write_target_line(atom_name, atom_serial, residue_name, chain_id, residue_num,\n",
    "                      x_coord, y_coord, z_coord, occupancy=1.0, b_factor=0.0, atom_type='C'):\n",
    "    atom_name_padded = f\" {atom_name.ljust(3)}\" if len(atom_name) < 4 else atom_name\n",
    "    return (\n",
    "        f\"ATOM  {atom_serial:5d} {atom_name_padded:<4s} {residue_name:<3s} {chain_id}\"\n",
    "        f\"{residue_num:4d}    {x_coord:8.3f}{y_coord:8.3f}{z_coord:8.3f}\"\n",
    "        f\"{occupancy:6.2f}{b_factor:6.2f}          {atom_type:>2s}  \\n\"\n",
    "    )\n",
    "\n",
    "def write2pdb(df: pd.DataFrame, xyz_id: int, target_path: str):\n",
    "    resolved_cnt = 0\n",
    "    written_resids = set()\n",
    "    with open(target_path, 'w') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            resid = int(row['resid'])\n",
    "            if resid in written_resids: continue\n",
    "            x, y, z = row.get(f'x_{xyz_id}'), row.get(f'y_{xyz_id}'), row.get(f'z_{xyz_id}')\n",
    "            if pd.notna(x) and x > -1e17:\n",
    "                resolved_cnt += 1\n",
    "                f.write(write_target_line( \"C1'\", resid, row['resname'], 'A', resid, x, y, z))\n",
    "                written_resids.add(resid)\n",
    "    return resolved_cnt\n",
    "\n",
    "\n",
    "def get_base_target_id(long_id):\n",
    "    \"\"\"Correctly extracts the base target ID (e.g., '9L5R_2') from a full ID ('9L5R_2_1').\"\"\"\n",
    "    return \"_\".join(str(long_id).split(\"_\")[:-1])\n",
    "\n",
    "def score_and_report(solution: pd.DataFrame, submission: pd.DataFrame):\n",
    "    solution['target_id'] = solution['ID'].apply(get_base_target_id)\n",
    "    submission['target_id'] = submission['ID'].apply(get_base_target_id)\n",
    "    \n",
    "    native_idxs = sorted(int(c.split('_')[1]) for c in solution.columns if c.startswith('x_'))\n",
    "    per_target, best_scores = {}, []\n",
    "\n",
    "    for tid, grp_nat in tqdm(solution.groupby('target_id'), desc=\"Scoring Targets\"):\n",
    "        grp_pred = submission[submission['target_id'] == tid]\n",
    "        if grp_pred.empty:\n",
    "            print(f\"Warning: No submission found for target {tid}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        best_of_five = []\n",
    "        for pred_cnt in range(1, 6):\n",
    "            best_for_this_pred = 0.0\n",
    "            for nat_cnt in native_idxs:\n",
    "                n_nat = write2pdb(grp_nat, nat_cnt, os.path.join(TEMP_DIR, 'native.pdb'))\n",
    "                n_pred = write2pdb(grp_pred, pred_cnt, os.path.join(TEMP_DIR, 'predicted.pdb'))\n",
    "                if n_nat > 0 and n_pred > 0:\n",
    "                    out = os.popen(f'{USALIGN_PATH} {os.path.join(TEMP_DIR, \"predicted.pdb\")} {os.path.join(TEMP_DIR, \"native.pdb\")} -atom \" C1\\'\"').read()\n",
    "                    score = parse_tmscore_output(out)\n",
    "                    if score is not None:\n",
    "                        best_for_this_pred = max(best_for_this_pred, score)\n",
    "            best_of_five.append(best_for_this_pred)\n",
    "        \n",
    "        per_target[tid] = best_of_five\n",
    "        best_scores.append(max(best_of_five))\n",
    "\n",
    "    overall = np.mean(best_scores)\n",
    "    print(f\"\\n>>> FINAL mean best-of-5 TM-score = {overall:.4f} (scored on {len(best_scores)} targets)\")\n",
    "    return per_target, overall\n",
    "\n",
    "def calculate_ground_truth_tm(pred_df, pred_idx, native_df):\n",
    "    \"\"\"Calculates the true TM-score for one prediction against ALL possible native structures.\"\"\"\n",
    "    best_tm_for_this_pred = 0.0\n",
    "    pred_path = os.path.join(TEMP_DIR, 'predicted_for_gt.pdb')\n",
    "    native_path = os.path.join(TEMP_DIR, 'native_for_gt.pdb')\n",
    "    \n",
    "    n_pred = write2pdb(pred_df, pred_idx, pred_path)\n",
    "    if n_pred == 0: return 0.0\n",
    "\n",
    "    native_indices = sorted(int(c.split('_')[1]) for c in native_df.columns if c.startswith('x_'))\n",
    "    for nat_idx in native_indices:\n",
    "        n_nat = write2pdb(native_df, nat_idx, native_path)\n",
    "        if n_nat > 0:\n",
    "            cmd = f'{USALIGN_PATH} {pred_path} {native_path} -atom \" C1\\'\"'\n",
    "            output = os.popen(cmd).read()\n",
    "            tm = parse_tmscore_output(output)\n",
    "            if tm is not None and tm > best_tm_for_this_pred:\n",
    "                best_tm_for_this_pred = tm\n",
    "    return best_tm_for_this_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d47d5399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Configuration and model architecture defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "# Paths to the saved model and scaler from training\n",
    "MODEL_SAVE_PATH = 'meta_learner_lgbm.pkl' \n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    'ProteinX': {\n",
    "        'predictions_path': '/home/max/Documents/Standford_3DRNA_PredictionData/Protenix_Baseline_Validation/submission.csv',\n",
    "        'confidences_path': '/home/max/Documents/Standford_3DRNA_PredictionData/Protenix_Baseline_Validation/confidence.csv',\n",
    "        'ranking_path': '/home/max/Documents/Standford_3DRNA_PredictionData/Protenix_Baseline_Validation/ranking_scores.csv'\n",
    "    },\n",
    "    'DrFo2': {\n",
    "        'predictions_path': '/home/max/Documents/Standford_3DRNA_PredictionData/DRfold2_Baseline_validation/submission.csv',\n",
    "        'confidences_path': '/home/max/Documents/Standford_3DRNA_PredictionData/DRfold2_Baseline_validation/confidence.csv',\n",
    "        'ranking_path': None\n",
    "    },\n",
    "    'Ribonanza': {\n",
    "        # Both predictions and confidences are in this one file\n",
    "        'predictions_path': '/home/max/Documents/Standford_3DRNA_PredictionData/Ribonanza_Baseline_Validation/ribonanzanet2_submission_with_confidence.csv',\n",
    "        'confidences_path': '/home/max/Documents/Standford_3DRNA_PredictionData/Ribonanza_Baseline_Validation/ribonanzanet2_submission_with_confidence.csv',\n",
    "        'ranking_path': None\n",
    "    }\n",
    "}\n",
    "\n",
    "SEQUENCES_PATH = '/home/max/Documents/Protenix-KaggleRNA3D/data/stanford-rna-3d-folding/validation_sequences_clean.csv'\n",
    "LABELS_PATH = '/home/max/Documents/Protenix-KaggleRNA3D/data/stanford-rna-3d-folding/validation_labels_clean.csv'\n",
    "\n",
    "# Constants\n",
    "NUM_PREDICTIONS_PER_MODEL = 5\n",
    "NUCLEOTIDES = ['A', 'C', 'G', 'U']\n",
    "\n",
    "print(\"✅ Configuration and model architecture defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "064c9a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNAEnergyScorer:\n",
    "    def __init__(self):\n",
    "        # Base pairing energies (kcal/mol) at 37°C\n",
    "        self.base_pair_energies = {\n",
    "            ('A', 'U'): -2.0, ('U', 'A'): -2.0,  # Watson-Crick AU\n",
    "            ('G', 'C'): -3.0, ('C', 'G'): -3.0,  # Watson-Crick GC\n",
    "            ('G', 'U'): -1.5, ('U', 'G'): -1.5,  # Wobble GU\n",
    "        }\n",
    "        \n",
    "        # Stacking energies for consecutive base pairs (kcal/mol)\n",
    "        # Format: ((base1, base2), (base3, base4)) where 1-2 and 3-4 are pairs\n",
    "        self.stacking_energies = {\n",
    "            (('A', 'U'), ('A', 'U')): -0.9,\n",
    "            (('A', 'U'), ('G', 'C')): -2.1,\n",
    "            (('G', 'C'), ('G', 'C')): -3.4,\n",
    "            (('G', 'C'), ('A', 'U')): -2.3,\n",
    "            (('G', 'U'), ('G', 'U')): -1.3,\n",
    "            (('G', 'U'), ('G', 'C')): -2.5,\n",
    "            (('G', 'U'), ('A', 'U')): -1.4,\n",
    "        }\n",
    "        \n",
    "        # VdW radii for RNA atoms (Angstroms)\n",
    "        self.vdw_radii = {\n",
    "            'C': 1.7,   # Carbon\n",
    "            'N': 1.55,  # Nitrogen\n",
    "            'O': 1.52,  # Oxygen\n",
    "            'P': 1.8,   # Phosphorus\n",
    "        }\n",
    "        \n",
    "        # Ideal distances for hydrogen bonds (Angstroms)\n",
    "        self.hbond_ideal_distance = 2.8\n",
    "        self.hbond_max_distance = 3.5\n",
    "        \n",
    "    def calculate_base_pair_energy(self, sequence: str, coords: np.ndarray, cutoff_distance: float = 4.0) -> float:\n",
    "        if len(sequence) != len(coords):\n",
    "            return 0.0\n",
    "            \n",
    "        energy = 0.0\n",
    "        distances = cdist(coords, coords)\n",
    "        \n",
    "        for i in range(len(sequence)):\n",
    "            for j in range(i + 3, len(sequence)):  # Skip neighbors\n",
    "                if distances[i, j] < cutoff_distance:\n",
    "                    pair = (sequence[i], sequence[j])\n",
    "                    if pair in self.base_pair_energies:\n",
    "                        # Weight by distance (closer = stronger)\n",
    "                        weight = 1.0 - (distances[i, j] / cutoff_distance)\n",
    "                        energy += self.base_pair_energies[pair] * weight\n",
    "                        \n",
    "        return energy\n",
    "    \n",
    "    def calculate_stacking_energy(self, sequence: str, coords: np.ndarray) -> float:\n",
    "        if len(sequence) < 2 or len(coords) < 2:\n",
    "            return 0.0\n",
    "            \n",
    "        energy = 0.0\n",
    "        \n",
    "        # Calculate stacking between consecutive bases\n",
    "        for i in range(len(sequence) - 1):\n",
    "            # Distance between consecutive bases\n",
    "            dist = np.linalg.norm(coords[i] - coords[i + 1])\n",
    "            \n",
    "            # Ideal stacking distance is around 3.4 Angstroms\n",
    "            if 3.0 < dist < 4.0:\n",
    "                # Simple stacking energy based on base types\n",
    "                base1, base2 = sequence[i], sequence[i + 1]\n",
    "                \n",
    "                # Purine-purine stacking is stronger\n",
    "                if base1 in ['A', 'G'] and base2 in ['A', 'G']:\n",
    "                    energy += -1.5\n",
    "                # Purine-pyrimidine\n",
    "                elif (base1 in ['A', 'G'] and base2 in ['C', 'U']) or \\\n",
    "                     (base1 in ['C', 'U'] and base2 in ['A', 'G']):\n",
    "                    energy += -1.0\n",
    "                # Pyrimidine-pyrimidine is weakest\n",
    "                else:\n",
    "                    energy += -0.5\n",
    "                    \n",
    "        return energy\n",
    "    \n",
    "    def calculate_vdw_energy(self, coords: np.ndarray, epsilon: float = 0.1, clash_penalty: float = 10.0) -> float:\n",
    "        if len(coords) < 2:\n",
    "            return 0.0\n",
    "            \n",
    "        energy = 0.0\n",
    "        distances = cdist(coords, coords)\n",
    "        \n",
    "        # Assume all atoms are carbon for simplicity (can be extended)\n",
    "        sigma = 2 * self.vdw_radii['C']\n",
    "        \n",
    "        for i in range(len(coords)):\n",
    "            for j in range(i + 1, len(coords)):\n",
    "                r = distances[i, j]\n",
    "                \n",
    "                if r < 0.1:  # Avoid division by zero\n",
    "                    energy += clash_penalty\n",
    "                elif r < sigma * 2.5:  # Only calculate for nearby atoms\n",
    "                    # Lennard-Jones potential\n",
    "                    ratio = sigma / r\n",
    "                    energy += 4 * epsilon * (ratio**12 - ratio**6)\n",
    "                    \n",
    "        return energy\n",
    "    \n",
    "    def calculate_electrostatic_energy(self, sequence: str, coords: np.ndarray, dielectric: float = 80.0) -> float:\n",
    "        if len(coords) < 2:\n",
    "            return 0.0\n",
    "            \n",
    "        # Phosphate groups have -1 charge\n",
    "        charge = -1.0\n",
    "        k_e = 332.0  # Coulomb's constant in kcal*Å/(mol*e²)\n",
    "        \n",
    "        energy = 0.0\n",
    "        distances = cdist(coords, coords)\n",
    "        \n",
    "        for i in range(len(coords)):\n",
    "            for j in range(i + 2, len(coords)):  # Skip neighbors\n",
    "                r = distances[i, j]\n",
    "                if r > 0.1:  # Avoid division by zero\n",
    "                    # Coulomb's law with distance-dependent dielectric\n",
    "                    effective_dielectric = dielectric * (1 + 0.1 * r)\n",
    "                    energy += k_e * charge * charge / (effective_dielectric * r)\n",
    "                    \n",
    "        return energy\n",
    "    \n",
    "    def calculate_hydrogen_bond_energy(self, sequence: str, coords: np.ndarray) -> float:\n",
    "        if len(sequence) != len(coords): return 0.0\n",
    "            \n",
    "        energy = 0.0\n",
    "        distances = cdist(coords, coords)\n",
    "        \n",
    "        # Number of H-bonds per base pair type\n",
    "        hbond_counts = {\n",
    "            ('A', 'U'): 2, ('U', 'A'): 2,\n",
    "            ('G', 'C'): 3, ('C', 'G'): 3,\n",
    "            ('G', 'U'): 2, ('U', 'G'): 2,\n",
    "        }\n",
    "        \n",
    "        for i in range(len(sequence)):\n",
    "            for j in range(i + 3, len(sequence)):\n",
    "                dist = distances[i, j]\n",
    "                \n",
    "                if dist < self.hbond_max_distance:\n",
    "                    pair = (sequence[i], sequence[j])\n",
    "                    if pair in hbond_counts:\n",
    "                        # Energy per H-bond with distance dependence\n",
    "                        if dist <= self.hbond_ideal_distance:\n",
    "                            bond_energy = -1.0  # kcal/mol per H-bond\n",
    "                        else:\n",
    "                            # Linear decrease from ideal to max distance\n",
    "                            factor = 1 - (dist - self.hbond_ideal_distance) / \\\n",
    "                                    (self.hbond_max_distance - self.hbond_ideal_distance)\n",
    "                            bond_energy = -1.0 * factor\n",
    "                            \n",
    "                        energy += bond_energy * hbond_counts[pair]\n",
    "                        \n",
    "        return energy\n",
    "    \n",
    "    def calculate_solvation_energy(self, coords: np.ndarray, \n",
    "                                  probe_radius: float = 1.4) -> float:\n",
    "        if len(coords) == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        # Simplified SASA calculation\n",
    "        # Count neighbors within cutoff as buried\n",
    "        cutoff = 5.0  # Angstroms\n",
    "        distances = cdist(coords, coords)\n",
    "        \n",
    "        energy = 0.0\n",
    "        for i in range(len(coords)):\n",
    "            # Count neighbors\n",
    "            neighbors = np.sum((distances[i] > 0) & (distances[i] < cutoff))\n",
    "            \n",
    "            # More neighbors = more buried = less solvation penalty\n",
    "            # Assume -0.5 kcal/mol per exposed nucleotide\n",
    "            exposure = max(0, 1 - neighbors / 6.0)  # 6 is roughly fully buried\n",
    "            energy += -0.5 * exposure\n",
    "            \n",
    "        return energy\n",
    "    \n",
    "    def calculate_torsion_energy(self, coords: np.ndarray) -> float:\n",
    "        if len(coords) < 4:\n",
    "            return 0.0\n",
    "            \n",
    "        energy = 0.0\n",
    "        \n",
    "        # Calculate pseudo-torsion angles for consecutive 4 nucleotides\n",
    "        for i in range(len(coords) - 3):\n",
    "            # Get 4 consecutive points\n",
    "            p1, p2, p3, p4 = coords[i:i+4]\n",
    "            \n",
    "            # Calculate vectors\n",
    "            v1 = p2 - p1\n",
    "            v2 = p3 - p2\n",
    "            v3 = p4 - p3\n",
    "            \n",
    "            # Calculate normal vectors to planes\n",
    "            n1 = np.cross(v1, v2)\n",
    "            n2 = np.cross(v2, v3)\n",
    "            \n",
    "            # Avoid division by zero\n",
    "            if np.linalg.norm(n1) > 0 and np.linalg.norm(n2) > 0:\n",
    "                n1 = n1 / np.linalg.norm(n1)\n",
    "                n2 = n2 / np.linalg.norm(n2)\n",
    "                \n",
    "                # Calculate dihedral angle\n",
    "                cos_angle = np.clip(np.dot(n1, n2), -1, 1)\n",
    "                angle = np.arccos(cos_angle)\n",
    "                \n",
    "                # Simple torsion potential (favors certain angles)\n",
    "                # Minima at 0, π/3, 2π/3, π, 4π/3, 5π/3\n",
    "                energy += 0.5 * (1 + np.cos(3 * angle))\n",
    "                \n",
    "        return energy\n",
    "    \n",
    "    def calculate_total_energy(self, sequence: str, coords: np.ndarray,\n",
    "                             weights: Optional[Dict[str, float]] = None) -> Dict[str, float]:\n",
    "        if weights is None:\n",
    "            weights = {\n",
    "                'base_pair': 1.0,\n",
    "                'stacking': 0.5,\n",
    "                'vdw': 0.3,\n",
    "                'electrostatic': 0.2,\n",
    "                'hbond': 0.8,\n",
    "                'solvation': 0.4,\n",
    "                'torsion': 0.3\n",
    "            }\n",
    "        \n",
    "        energies = {\n",
    "            'base_pair': self.calculate_base_pair_energy(sequence, coords),\n",
    "            'stacking': self.calculate_stacking_energy(sequence, coords),\n",
    "            'vdw': self.calculate_vdw_energy(coords),\n",
    "            'electrostatic': self.calculate_electrostatic_energy(sequence, coords),\n",
    "            'hbond': self.calculate_hydrogen_bond_energy(sequence, coords),\n",
    "            'solvation': self.calculate_solvation_energy(coords),\n",
    "            'torsion': self.calculate_torsion_energy(coords)\n",
    "        }\n",
    "        \n",
    "        # Calculate weighted total\n",
    "        total = sum(weights.get(key, 1.0) * value for key, value in energies.items())\n",
    "        energies['total'] = total\n",
    "        \n",
    "        return energies\n",
    "\n",
    "\n",
    "def extract_energy_features(sequence: str, coords: np.ndarray, scorer: Optional[RNAEnergyScorer] = None) -> Dict[str, float]:\n",
    "    if scorer is None: scorer = RNAEnergyScorer()\n",
    "    \n",
    "    energies = scorer.calculate_total_energy(sequence, coords)\n",
    "    features = energies.copy()\n",
    "    \n",
    "    # Energy per nucleotide\n",
    "    n_nucleotides = len(sequence)\n",
    "    if n_nucleotides > 0:\n",
    "        features['energy_per_nucleotide'] = energies['total'] / n_nucleotides\n",
    "        features['base_pair_per_nucleotide'] = energies['base_pair'] / n_nucleotides\n",
    "    \n",
    "    # Ratio features\n",
    "    if energies['total'] != 0:\n",
    "        features['base_pair_ratio'] = energies['base_pair'] / abs(energies['total'])\n",
    "        features['hbond_ratio'] = energies['hbond'] / abs(energies['total'])\n",
    "    \n",
    "    # Stability score (lower energy = more stable)\n",
    "    features['stability_score'] = -energies['total']\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db67743a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Loading and Pre-processing All Data ---\n",
      "All data files loaded.\n",
      "\n",
      "--- Step 2: Generating Features for Inference ---\n",
      "Found 94 unique targets in the primary sequence file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ea020a884346118d0847d233a55847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Targets:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Feature generation complete for 94 targets.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_id</th>\n",
       "      <th>model_source_str</th>\n",
       "      <th>prediction_index</th>\n",
       "      <th>sequence_length</th>\n",
       "      <th>percent_A</th>\n",
       "      <th>percent_C</th>\n",
       "      <th>percent_G</th>\n",
       "      <th>percent_U</th>\n",
       "      <th>mean_plddt</th>\n",
       "      <th>std_plddt</th>\n",
       "      <th>...</th>\n",
       "      <th>energy_stability_score</th>\n",
       "      <th>energy_base_pair_ratio</th>\n",
       "      <th>energy_hbond_ratio</th>\n",
       "      <th>energy_attractive</th>\n",
       "      <th>energy_repulsive</th>\n",
       "      <th>energy_balance</th>\n",
       "      <th>energy_density</th>\n",
       "      <th>energy_variance</th>\n",
       "      <th>energy_std</th>\n",
       "      <th>model_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9L5R_2</td>\n",
       "      <td>ProteinX</td>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "      <td>0.170984</td>\n",
       "      <td>0.26943</td>\n",
       "      <td>0.217617</td>\n",
       "      <td>0.341969</td>\n",
       "      <td>50.865285</td>\n",
       "      <td>6.674131</td>\n",
       "      <td>...</td>\n",
       "      <td>-111.026941</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>558.202298</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575269</td>\n",
       "      <td>41774.617491</td>\n",
       "      <td>204.388399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9L5R_2</td>\n",
       "      <td>ProteinX</td>\n",
       "      <td>2</td>\n",
       "      <td>193</td>\n",
       "      <td>0.170984</td>\n",
       "      <td>0.26943</td>\n",
       "      <td>0.217617</td>\n",
       "      <td>0.341969</td>\n",
       "      <td>50.863990</td>\n",
       "      <td>6.291851</td>\n",
       "      <td>...</td>\n",
       "      <td>-104.898808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>534.964876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.543517</td>\n",
       "      <td>38639.473721</td>\n",
       "      <td>196.569259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9L5R_2</td>\n",
       "      <td>ProteinX</td>\n",
       "      <td>3</td>\n",
       "      <td>193</td>\n",
       "      <td>0.170984</td>\n",
       "      <td>0.26943</td>\n",
       "      <td>0.217617</td>\n",
       "      <td>0.341969</td>\n",
       "      <td>50.045337</td>\n",
       "      <td>6.346398</td>\n",
       "      <td>...</td>\n",
       "      <td>-111.859021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>560.106704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.579580</td>\n",
       "      <td>41984.046444</td>\n",
       "      <td>204.900089</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9L5R_2</td>\n",
       "      <td>ProteinX</td>\n",
       "      <td>4</td>\n",
       "      <td>193</td>\n",
       "      <td>0.170984</td>\n",
       "      <td>0.26943</td>\n",
       "      <td>0.217617</td>\n",
       "      <td>0.341969</td>\n",
       "      <td>51.018135</td>\n",
       "      <td>6.726162</td>\n",
       "      <td>...</td>\n",
       "      <td>-109.998523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>559.019174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.569941</td>\n",
       "      <td>41867.415541</td>\n",
       "      <td>204.615287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9L5R_2</td>\n",
       "      <td>ProteinX</td>\n",
       "      <td>5</td>\n",
       "      <td>193</td>\n",
       "      <td>0.170984</td>\n",
       "      <td>0.26943</td>\n",
       "      <td>0.217617</td>\n",
       "      <td>0.341969</td>\n",
       "      <td>50.661917</td>\n",
       "      <td>6.356630</td>\n",
       "      <td>...</td>\n",
       "      <td>-117.409530</td>\n",
       "      <td>-0.006255</td>\n",
       "      <td>-0.017034</td>\n",
       "      <td>-2.734425</td>\n",
       "      <td>593.812545</td>\n",
       "      <td>-0.004605</td>\n",
       "      <td>0.608340</td>\n",
       "      <td>44944.874678</td>\n",
       "      <td>212.002063</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  target_id model_source_str  prediction_index  sequence_length  percent_A  \\\n",
       "0    9L5R_2         ProteinX                 1              193   0.170984   \n",
       "1    9L5R_2         ProteinX                 2              193   0.170984   \n",
       "2    9L5R_2         ProteinX                 3              193   0.170984   \n",
       "3    9L5R_2         ProteinX                 4              193   0.170984   \n",
       "4    9L5R_2         ProteinX                 5              193   0.170984   \n",
       "\n",
       "   percent_C  percent_G  percent_U  mean_plddt  std_plddt  ...  \\\n",
       "0    0.26943   0.217617   0.341969   50.865285   6.674131  ...   \n",
       "1    0.26943   0.217617   0.341969   50.863990   6.291851  ...   \n",
       "2    0.26943   0.217617   0.341969   50.045337   6.346398  ...   \n",
       "3    0.26943   0.217617   0.341969   51.018135   6.726162  ...   \n",
       "4    0.26943   0.217617   0.341969   50.661917   6.356630  ...   \n",
       "\n",
       "   energy_stability_score  energy_base_pair_ratio  energy_hbond_ratio  \\\n",
       "0             -111.026941                0.000000            0.000000   \n",
       "1             -104.898808                0.000000            0.000000   \n",
       "2             -111.859021                0.000000            0.000000   \n",
       "3             -109.998523                0.000000            0.000000   \n",
       "4             -117.409530               -0.006255           -0.017034   \n",
       "\n",
       "   energy_attractive  energy_repulsive  energy_balance  energy_density  \\\n",
       "0           0.000000        558.202298        0.000000        0.575269   \n",
       "1           0.000000        534.964876        0.000000        0.543517   \n",
       "2           0.000000        560.106704        0.000000        0.579580   \n",
       "3           0.000000        559.019174        0.000000        0.569941   \n",
       "4          -2.734425        593.812545       -0.004605        0.608340   \n",
       "\n",
       "   energy_variance  energy_std  model_source  \n",
       "0     41774.617491  204.388399             0  \n",
       "1     38639.473721  196.569259             0  \n",
       "2     41984.046444  204.900089             0  \n",
       "3     41867.415541  204.615287             0  \n",
       "4     44944.874678  212.002063             0  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique targets in SEQUENCES file after filtering: 94\n",
      "Unique targets in LABELS file after filtering: 94\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Load and Pre-process All Data ---\n",
    "print(\"--- Step 1: Loading and Pre-processing All Data ---\")\n",
    "try:\n",
    "    df_sequences = pd.read_csv(SEQUENCES_PATH)\n",
    "    df_labels = pd.read_csv(LABELS_PATH)\n",
    "    df_labels['target_id'] = df_labels['ID'].apply(get_base_target_id)\n",
    "    \n",
    "    data_dfs = {}\n",
    "    for model_name, config in MODEL_CONFIG.items():\n",
    "        if model_name == 'Ribonanza':\n",
    "            df_raw = pd.read_csv(config['predictions_path'])\n",
    "            pred_cols = ['ID', 'resname', 'resid'] + [col for col in df_raw.columns if col.startswith(('x_', 'y_', 'z_'))]\n",
    "            data_dfs[f'{model_name}_preds'] = df_raw[pred_cols].copy()\n",
    "            rename_dict = {f'confidence_{i}': f'plddt_{i}' for i in range(1, NUM_PREDICTIONS_PER_MODEL + 1)}\n",
    "            data_dfs[f'{model_name}_conf'] = df_raw.rename(columns=rename_dict)\n",
    "        else:\n",
    "            data_dfs[f'{model_name}_preds'] = pd.read_csv(config['predictions_path'])\n",
    "            data_dfs[f'{model_name}_conf'] = pd.read_csv(config['confidences_path'])\n",
    "        \n",
    "        if config.get('ranking_path'):\n",
    "            data_dfs[f'{model_name}_rank'] = pd.read_csv(config['ranking_path'])\n",
    "\n",
    "    print(\"All data files loaded.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"FATAL ERROR: Cannot load a data file: {e}.\")\n",
    "    raise e\n",
    "\n",
    "# --- Step 2: Main Feature Generation Loop with Integrated Checks ---\n",
    "print(\"\\n--- Step 2: Generating Features for Inference ---\")\n",
    "energy_scorer = RNAEnergyScorer()\n",
    "meta_data_rows = []\n",
    "all_target_ids_in_sequence_file = df_sequences['target_id'].unique()\n",
    "print(f\"Found {len(all_target_ids_in_sequence_file)} unique targets in the primary sequence file.\")\n",
    "\n",
    "for target_id in tqdm(all_target_ids_in_sequence_file, desc=\"Processing Targets\"):\n",
    "    \n",
    "    # --- Robustness Check: Ensure this target exists where needed ---\n",
    "    sequence_row = df_sequences[df_sequences['target_id'] == target_id]\n",
    "    if sequence_row.empty: continue # Should not happen, but safe\n",
    "    \n",
    "    # Check if this target_id has predictions from ALL models\n",
    "    is_present_in_all = True\n",
    "    for model_name in MODEL_CONFIG.keys():\n",
    "        if data_dfs[f'{model_name}_preds'][data_dfs[f'{model_name}_preds']['ID'].str.startswith(target_id)].empty:\n",
    "            is_present_in_all = False\n",
    "            # print(f\"Warning: Skipping {target_id}, missing predictions from {model_name}\")\n",
    "            break\n",
    "    if not is_present_in_all: continue\n",
    "\n",
    "    # --- If checks pass, proceed with feature generation ---\n",
    "    sequence = sequence_row.iloc[0]['sequence']\n",
    "    \n",
    "    # Pre-calculate all candidate coordinates for this target\n",
    "    all_candidate_coords = {}\n",
    "    for model_name in MODEL_CONFIG:\n",
    "        target_preds = data_dfs[f'{model_name}_preds'][data_dfs[f'{model_name}_preds']['ID'].str.startswith(target_id)]\n",
    "        for i in range(1, NUM_PREDICTIONS_PER_MODEL + 1):\n",
    "            all_candidate_coords[f'{model_name}_{i}'] = get_coords(target_preds, i)\n",
    "\n",
    "    # Loop through each model to create feature rows\n",
    "    for model_name in MODEL_CONFIG:\n",
    "        df_conf = data_dfs[f'{model_name}_conf']\n",
    "        target_confs = df_conf[df_conf['ID'].str.startswith(target_id)]\n",
    "        \n",
    "        df_rank = data_dfs.get(f'{model_name}_rank')\n",
    "        target_rank = df_rank[df_rank['target_id'] == target_id] if df_rank is not None else None\n",
    "\n",
    "        for i in range(1, NUM_PREDICTIONS_PER_MODEL + 1):\n",
    "            if f'plddt_{i}' not in target_confs.columns: continue\n",
    "            \n",
    "            features = {\n",
    "                'target_id': target_id, \n",
    "                'model_source_str': model_name,\n",
    "                'prediction_index': i\n",
    "            }\n",
    "            \n",
    "            features['sequence_length'] = len(sequence)\n",
    "            for nuc in NUCLEOTIDES: features[f'percent_{nuc}'] = sequence.count(nuc) / len(sequence)\n",
    "            \n",
    "            plddt_scores = target_confs[f'plddt_{i}'].values\n",
    "            features.update({'mean_plddt': np.mean(plddt_scores), 'std_plddt': np.std(plddt_scores), 'min_plddt': np.min(plddt_scores), 'percent_low_conf': np.mean(plddt_scores < 70), 'percent_high_conf': np.mean(plddt_scores > 90)})\n",
    "            \n",
    "            if target_rank is not None and not target_rank.empty:\n",
    "                features.update({'ptm': target_rank.iloc[0].get(f'ptm_{i}', 0), 'ranking_score': target_rank.iloc[0].get(f'ranking_score_{i}', 0)})\n",
    "            else:\n",
    "                features.update({'ptm': 0, 'ranking_score': 0})\n",
    "\n",
    "            candidate_coords = all_candidate_coords.get(f'{model_name}_{i}')\n",
    "            if candidate_coords is None or candidate_coords.shape[0] == 0: continue\n",
    "            features['radius_of_gyration'] = calculate_radius_of_gyration(candidate_coords)\n",
    "            rmsd_to_others = [calculate_rmsd(candidate_coords, other_coords) for key, other_coords in all_candidate_coords.items() if key != f'{model_name}_{i}']\n",
    "            features['avg_rmsd_to_others'] = np.nanmean(rmsd_to_others)\n",
    "            \n",
    "            base_mean_plddt = features['mean_plddt']\n",
    "            base_std_plddt = features['std_plddt']\n",
    "            base_radius_of_gyration = features['radius_of_gyration']\n",
    "            for source in MODEL_CONFIG.keys():\n",
    "                features[f'plddt_x_{source}'] = 0.0\n",
    "                features[f'std_plddt_x_{source}'] = 0.0\n",
    "                features[f'rog_x_{source}'] = 0.0\n",
    "            features[f'plddt_x_{model_name}'] = base_mean_plddt\n",
    "            features[f'std_plddt_x_{model_name}'] = base_std_plddt\n",
    "            features[f'rog_x_{model_name}'] = base_radius_of_gyration\n",
    "            \n",
    "            try:\n",
    "                energy_features = extract_energy_features(sequence, candidate_coords, energy_scorer)\n",
    "                features.update({\n",
    "                    'energy_total': energy_features['total'],\n",
    "                    'energy_base_pair': energy_features['base_pair'],\n",
    "                    'energy_stacking': energy_features['stacking'],\n",
    "                    'energy_vdw': energy_features['vdw'],\n",
    "                    'energy_electrostatic': energy_features['electrostatic'],\n",
    "                    'energy_hbond': energy_features['hbond'],\n",
    "                    'energy_solvation': energy_features['solvation'],\n",
    "                    'energy_torsion': energy_features['torsion'],\n",
    "                    'energy_per_nucleotide': energy_features.get('energy_per_nucleotide', 0),\n",
    "                    'energy_stability_score': energy_features.get('stability_score', 0),\n",
    "                    'energy_base_pair_ratio': energy_features.get('base_pair_ratio', 0),\n",
    "                    'energy_hbond_ratio': energy_features.get('hbond_ratio', 0)\n",
    "                })\n",
    "                attractive_energy = energy_features['base_pair'] + energy_features['stacking'] + energy_features['hbond']\n",
    "                repulsive_energy = energy_features['vdw'] + energy_features['electrostatic']\n",
    "                features['energy_attractive'] = attractive_energy\n",
    "                features['energy_repulsive'] = repulsive_energy\n",
    "                features['energy_balance'] = attractive_energy / (abs(repulsive_energy) + 1e-6)\n",
    "                features['energy_density'] = energy_features['total'] / (len(sequence) + 1e-6)\n",
    "                energy_components = [energy_features[k] for k in ['base_pair', 'stacking', 'vdw', 'electrostatic', 'hbond', 'solvation', 'torsion']]\n",
    "                features['energy_variance'] = np.var(energy_components)\n",
    "                features['energy_std'] = np.std(energy_components)\n",
    "            except Exception as e:\n",
    "                # print(f\"Warning: Error calculating energy for {target_id}_{model_name}_{i}: {e}\")\n",
    "                energy_feature_names = [\n",
    "                    'energy_total', 'energy_base_pair', 'energy_stacking', 'energy_vdw',\n",
    "                    'energy_electrostatic', 'energy_hbond', 'energy_solvation', 'energy_torsion',\n",
    "                    'energy_per_nucleotide', 'energy_stability_score', 'energy_base_pair_ratio',\n",
    "                    'energy_hbond_ratio', 'energy_attractive', 'energy_repulsive', 'energy_balance',\n",
    "                    'energy_density', 'energy_variance', 'energy_std'\n",
    "                ]\n",
    "                for feat_name in energy_feature_names:\n",
    "                    features[feat_name] = 0.0\n",
    "                    \n",
    "            meta_data_rows.append(features)\n",
    "\n",
    "# --- Step 3: Finalize DataFrame ---\n",
    "if not meta_data_rows:\n",
    "    raise ValueError(\"FATAL ERROR: No feature rows were generated. Check for data mismatches or empty files.\")\n",
    "\n",
    "df_inference = pd.DataFrame(meta_data_rows)\n",
    "\n",
    "# Create the numeric 'model_source' column that the model was trained on\n",
    "model_mapping = {name: i for i, name in enumerate(MODEL_CONFIG.keys())}\n",
    "df_inference['model_source'] = df_inference['model_source_str'].map(model_mapping)\n",
    "\n",
    "df_inference.fillna(df_inference.median(numeric_only=True), inplace=True)\n",
    "\n",
    "print(f\"\\n✅ Feature generation complete for {df_inference['target_id'].nunique()} targets.\")\n",
    "display(df_inference.head())\n",
    "\n",
    "print(f\"Unique targets in SEQUENCES file after filtering: {df_sequences['target_id'].nunique()}\")\n",
    "print(f\"Unique targets in LABELS file after filtering: {df_labels['target_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38ffa1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading LightGBM model and making predictions... ---\n",
      "✅ Top 5 candidates selected for each target.\n",
      "Total selected structures: 470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_183721/3663936403.py:35: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_top5 = df_inference.groupby('target_id').apply(lambda x: x.nlargest(5, 'predicted_tm')).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_id</th>\n",
       "      <th>model_source_str</th>\n",
       "      <th>prediction_index</th>\n",
       "      <th>predicted_tm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8K85_A</td>\n",
       "      <td>Ribonanza</td>\n",
       "      <td>3</td>\n",
       "      <td>0.585564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8K85_A</td>\n",
       "      <td>Ribonanza</td>\n",
       "      <td>4</td>\n",
       "      <td>0.577453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8K85_A</td>\n",
       "      <td>Ribonanza</td>\n",
       "      <td>5</td>\n",
       "      <td>0.575787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8K85_A</td>\n",
       "      <td>Ribonanza</td>\n",
       "      <td>2</td>\n",
       "      <td>0.570707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8K85_A</td>\n",
       "      <td>Ribonanza</td>\n",
       "      <td>1</td>\n",
       "      <td>0.569004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8KEB_A</td>\n",
       "      <td>Ribonanza</td>\n",
       "      <td>4</td>\n",
       "      <td>0.882930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8KEB_A</td>\n",
       "      <td>Ribonanza</td>\n",
       "      <td>5</td>\n",
       "      <td>0.878771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8KEB_A</td>\n",
       "      <td>ProteinX</td>\n",
       "      <td>5</td>\n",
       "      <td>0.669664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8KEB_A</td>\n",
       "      <td>ProteinX</td>\n",
       "      <td>2</td>\n",
       "      <td>0.659660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8KEB_A</td>\n",
       "      <td>ProteinX</td>\n",
       "      <td>4</td>\n",
       "      <td>0.658660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target_id model_source_str  prediction_index  predicted_tm\n",
       "0    8K85_A        Ribonanza                 3      0.585564\n",
       "1    8K85_A        Ribonanza                 4      0.577453\n",
       "2    8K85_A        Ribonanza                 5      0.575787\n",
       "3    8K85_A        Ribonanza                 2      0.570707\n",
       "4    8K85_A        Ribonanza                 1      0.569004\n",
       "5    8KEB_A        Ribonanza                 4      0.882930\n",
       "6    8KEB_A        Ribonanza                 5      0.878771\n",
       "7    8KEB_A         ProteinX                 5      0.669664\n",
       "8    8KEB_A         ProteinX                 2      0.659660\n",
       "9    8KEB_A         ProteinX                 4      0.658660"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\n--- Loading LightGBM model and making predictions... ---\")\n",
    "\n",
    "# Load the trained LightGBM model\n",
    "try:\n",
    "    model = joblib.load(MODEL_SAVE_PATH)\n",
    "except FileNotFoundError:\n",
    "    print(f\"FATAL ERROR: Model file not found at {MODEL_SAVE_PATH}. Please run the training notebook first.\")\n",
    "    raise\n",
    "\n",
    "# Define the feature columns (must match the training script)\n",
    "feature_cols = [col for col in df_inference.columns if col not in ['target_id', 'model_source_str', 'tm_score']] # tm_score might not exist\n",
    "X_inference = df_inference[feature_cols].copy()\n",
    "\n",
    "# Clean column names to be compatible with LightGBM (must be identical to training)\n",
    "X_inference.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_inference.columns]\n",
    "\n",
    "# --- Sanity Check: Ensure feature order is the same as in the trained model ---\n",
    "try:\n",
    "    X_inference = X_inference[model.feature_name_]\n",
    "except Exception as e:\n",
    "    print(f\"FATAL ERROR: Feature mismatch between inference data and trained model. Error: {e}\")\n",
    "    print(\"\\nFeatures in inference data:\", X_inference.columns.tolist())\n",
    "    print(\"Features expected by model:\", model.feature_name_)\n",
    "    raise\n",
    "\n",
    "# Make predictions\n",
    "# No scaling or tensor conversion needed!\n",
    "predicted_scores = model.predict(X_inference)\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "df_inference['predicted_tm'] = predicted_scores\n",
    "\n",
    "# --- Core Selection Logic ---\n",
    "# For each target_id, find the 5 candidates with the highest predicted score\n",
    "df_top5 = df_inference.groupby('target_id').apply(lambda x: x.nlargest(5, 'predicted_tm')).reset_index(drop=True)\n",
    "\n",
    "print(\"✅ Top 5 candidates selected for each target.\")\n",
    "print(f\"Total selected structures: {len(df_top5)}\")\n",
    "display(df_top5[['target_id', 'model_source_str', 'prediction_index', 'predicted_tm']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c192d0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Assembling final submission file... ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a009c0f931e640b7969764f55a0db886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Assembling Submission:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensembled submission file 'ensembled_submission.csv' created successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resid</th>\n",
       "      <th>ID</th>\n",
       "      <th>resname</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>z_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>y_3</th>\n",
       "      <th>z_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>y_4</th>\n",
       "      <th>z_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>y_5</th>\n",
       "      <th>z_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8K85_A_1</td>\n",
       "      <td>G</td>\n",
       "      <td>11.359874</td>\n",
       "      <td>19.273932</td>\n",
       "      <td>-24.725073</td>\n",
       "      <td>-10.031795</td>\n",
       "      <td>21.430502</td>\n",
       "      <td>24.104576</td>\n",
       "      <td>1.739657</td>\n",
       "      <td>25.807976</td>\n",
       "      <td>-21.325783</td>\n",
       "      <td>-25.030249</td>\n",
       "      <td>-3.009271</td>\n",
       "      <td>22.493553</td>\n",
       "      <td>-11.122301</td>\n",
       "      <td>25.338013</td>\n",
       "      <td>20.354237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8K85_A_2</td>\n",
       "      <td>G</td>\n",
       "      <td>11.292404</td>\n",
       "      <td>13.435502</td>\n",
       "      <td>-24.485357</td>\n",
       "      <td>-12.683558</td>\n",
       "      <td>19.124477</td>\n",
       "      <td>19.230865</td>\n",
       "      <td>2.243749</td>\n",
       "      <td>20.615433</td>\n",
       "      <td>-21.924036</td>\n",
       "      <td>-22.164127</td>\n",
       "      <td>-6.809379</td>\n",
       "      <td>19.551247</td>\n",
       "      <td>-6.083194</td>\n",
       "      <td>22.807205</td>\n",
       "      <td>19.369934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8K85_A_3</td>\n",
       "      <td>A</td>\n",
       "      <td>12.951257</td>\n",
       "      <td>9.367302</td>\n",
       "      <td>-22.206780</td>\n",
       "      <td>-13.850716</td>\n",
       "      <td>18.713408</td>\n",
       "      <td>14.441497</td>\n",
       "      <td>4.780207</td>\n",
       "      <td>16.301336</td>\n",
       "      <td>-21.403898</td>\n",
       "      <td>-21.007872</td>\n",
       "      <td>-9.346490</td>\n",
       "      <td>15.168128</td>\n",
       "      <td>-2.446923</td>\n",
       "      <td>19.225378</td>\n",
       "      <td>19.853275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8K85_A_4</td>\n",
       "      <td>G</td>\n",
       "      <td>15.312449</td>\n",
       "      <td>6.391326</td>\n",
       "      <td>-18.453760</td>\n",
       "      <td>-12.531183</td>\n",
       "      <td>18.946608</td>\n",
       "      <td>9.559502</td>\n",
       "      <td>8.139541</td>\n",
       "      <td>12.631317</td>\n",
       "      <td>-19.601051</td>\n",
       "      <td>-20.436550</td>\n",
       "      <td>-9.683000</td>\n",
       "      <td>9.947579</td>\n",
       "      <td>-0.673806</td>\n",
       "      <td>14.225980</td>\n",
       "      <td>20.273897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8K85_A_5</td>\n",
       "      <td>A</td>\n",
       "      <td>17.220327</td>\n",
       "      <td>4.177942</td>\n",
       "      <td>-13.849748</td>\n",
       "      <td>-10.470436</td>\n",
       "      <td>19.030570</td>\n",
       "      <td>4.495241</td>\n",
       "      <td>11.442865</td>\n",
       "      <td>9.733561</td>\n",
       "      <td>-16.639530</td>\n",
       "      <td>-20.069801</td>\n",
       "      <td>-9.160627</td>\n",
       "      <td>4.501581</td>\n",
       "      <td>0.640619</td>\n",
       "      <td>8.873339</td>\n",
       "      <td>20.482450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   resid        ID resname        x_1        y_1        z_1        x_2  \\\n",
       "0      1  8K85_A_1       G  11.359874  19.273932 -24.725073 -10.031795   \n",
       "1      2  8K85_A_2       G  11.292404  13.435502 -24.485357 -12.683558   \n",
       "2      3  8K85_A_3       A  12.951257   9.367302 -22.206780 -13.850716   \n",
       "3      4  8K85_A_4       G  15.312449   6.391326 -18.453760 -12.531183   \n",
       "4      5  8K85_A_5       A  17.220327   4.177942 -13.849748 -10.470436   \n",
       "\n",
       "         y_2        z_2        x_3        y_3        z_3        x_4       y_4  \\\n",
       "0  21.430502  24.104576   1.739657  25.807976 -21.325783 -25.030249 -3.009271   \n",
       "1  19.124477  19.230865   2.243749  20.615433 -21.924036 -22.164127 -6.809379   \n",
       "2  18.713408  14.441497   4.780207  16.301336 -21.403898 -21.007872 -9.346490   \n",
       "3  18.946608   9.559502   8.139541  12.631317 -19.601051 -20.436550 -9.683000   \n",
       "4  19.030570   4.495241  11.442865   9.733561 -16.639530 -20.069801 -9.160627   \n",
       "\n",
       "         z_4        x_5        y_5        z_5  \n",
       "0  22.493553 -11.122301  25.338013  20.354237  \n",
       "1  19.551247  -6.083194  22.807205  19.369934  \n",
       "2  15.168128  -2.446923  19.225378  19.853275  \n",
       "3   9.947579  -0.673806  14.225980  20.273897  \n",
       "4   4.501581   0.640619   8.873339  20.482450  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Step 3: Assemble the Ensembled Submission File (CORRECTED) ---\n",
    "print(\"\\n--- Assembling final submission file... ---\")\n",
    "\n",
    "final_submission_rows = []\n",
    "# Group by target_id to process one RNA at a time\n",
    "for target_id, group in tqdm(df_top5.groupby('target_id'), desc=\"Assembling Submission\"):\n",
    "    \n",
    "    # Get the base information (ID, resname, resid) from any of the original prediction files.\n",
    "    base_info_df = None\n",
    "    for model_name in MODEL_CONFIG.keys():\n",
    "        base_info = data_dfs[f'{model_name}_preds'][data_dfs[f'{model_name}_preds']['ID'].str.startswith(f\"{target_id}_\")]\n",
    "        if not base_info.empty:\n",
    "            base_info_df = base_info[['ID', 'resname', 'resid']].copy()\n",
    "            break\n",
    "            \n",
    "    if base_info_df is None:\n",
    "        print(f\"Warning: Could not find base info for target {target_id}. Skipping.\")\n",
    "        continue\n",
    "    \n",
    "    target_submission_df = base_info_df.set_index('resid')\n",
    "    \n",
    "    # Iterate from k=1 to 5 to create the new columns x_1, y_1, z_1 ... x_5, y_5, z_5\n",
    "    for k, (_, selection_row) in enumerate(group.iterrows(), 1):\n",
    "        \n",
    "        source_model = selection_row['model_source_str']\n",
    "        original_pred_idx = selection_row['prediction_index']\n",
    "        \n",
    "        # Get the original coordinate data for this selection\n",
    "        original_coords_df = data_dfs[f'{source_model}_preds'][data_dfs[f'{source_model}_preds']['ID'].str.startswith(f\"{target_id}_\")]\n",
    "        \n",
    "        # Prepare the coordinates to add, with 'resid' as the index\n",
    "        coords_to_add = original_coords_df[['resid', f'x_{original_pred_idx}', f'y_{original_pred_idx}', f'z_{original_pred_idx}']].copy()\n",
    "        coords_to_add = coords_to_add.set_index('resid')\n",
    "        \n",
    "        # Assign the new columns. This is safer than merging.\n",
    "        target_submission_df[f'x_{k}'] = coords_to_add[f'x_{original_pred_idx}']\n",
    "        target_submission_df[f'y_{k}'] = coords_to_add[f'y_{original_pred_idx}']\n",
    "        target_submission_df[f'z_{k}'] = coords_to_add[f'z_{original_pred_idx}']\n",
    "        \n",
    "    # Reset the index to make 'resid' a column again, matching the submission format\n",
    "    final_submission_rows.append(target_submission_df.reset_index())\n",
    "\n",
    "# Concatenate all targets into the final submission dataframe\n",
    "if final_submission_rows:\n",
    "    ensembled_submission_df = pd.concat(final_submission_rows)\n",
    "    ensembled_submission_df.to_csv('ensembled_submission.csv', index=False)\n",
    "    print(\"Ensembled submission file 'ensembled_submission.csv' created successfully.\")\n",
    "    display(ensembled_submission_df.head())\n",
    "else:\n",
    "    print(\"ERROR: No data was assembled for the final submission.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55f38b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluating the performance of the meta-learner ensemble... ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951c98f6b2014813830bba2bdb31f8b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Scoring Targets:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> FINAL mean best-of-5 TM-score = 0.4750 (scored on 94 targets)\n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Evaluate the Final Result ---\n",
    "print(\"--- Evaluating the performance of the meta-learner ensemble... ---\")\n",
    "\n",
    "# Load the ground truth labels\n",
    "solution_df = pd.read_csv(LABELS_PATH)\n",
    "\n",
    "# The submission dataframe is the one we just created\n",
    "submission_df = pd.read_csv('ensembled_submission.csv')\n",
    "\n",
    "# Run the scoring\n",
    "_, final_score = score_and_report(solution_df, submission_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddd0db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- In-Depth Ensemble Performance Analysis ---\n",
      "Calculating ground truth TM-scores for analysis (efficiently)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac5ce6364fb2410a8b92b5a07790241e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating True TM-scores:   0%|          | 0/94 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Analysis data prepared successfully.\n",
      "\n",
      "✅ True TM-scores calculated and merged successfully.\n",
      "1. Oracle Score (Theoretical Max): 0.5021\n",
      "2. Your Model's Achieved Score:     0.4750\n",
      "   (Your model achieved 94.62% of the theoretical maximum performance)\n",
      "\n",
      "3. Recall@5 (Found the single best candidate): 53.19% (50/94 targets)\n",
      "\n",
      "4. Distribution of Models in Your Final Top 5 Selection:\n",
      "model_source_str\n",
      "Ribonanza    0.534043\n",
      "ProteinX     0.300000\n",
      "DrFo2        0.165957\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "5. Model Performance Analysis (Avg Predicted vs. True TM-score):\n",
      "                  avg_predicted_tm  avg_true_tm  count\n",
      "model_source_str                                      \n",
      "ProteinX                  0.406427     0.403984    470\n",
      "DrFo2                     0.360612     0.353896    470\n",
      "Ribonanza                 0.433002     0.319214    470\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- In-Depth Ensemble Performance Analysis ---\")\n",
    "\n",
    "# Step 1: Calculate the true TM-score for every candidate in df_inference.\n",
    "print(\"Calculating ground truth TM-scores for analysis (efficiently)...\")\n",
    "\n",
    "# This list will store small dataframes, each with results for one target\n",
    "all_target_results = []\n",
    "\n",
    "# Get the list of unique targets from the inference results\n",
    "unique_targets_to_analyze = df_inference['target_id'].unique()\n",
    "\n",
    "for target_id in tqdm(unique_targets_to_analyze, desc=\"Calculating True TM-scores\"):\n",
    "    # Get the slice of predictions for this one target\n",
    "    inference_slice = df_inference[df_inference['target_id'] == target_id].copy()\n",
    "    \n",
    "    # Get the corresponding labels once for this target\n",
    "    native_df_for_target = df_labels[df_labels['ID'].apply(get_base_target_id) == target_id]\n",
    "    \n",
    "    # This list will hold the calculated true TM-scores for this target\n",
    "    true_scores = []\n",
    "    \n",
    "    # Iterate through the rows of the slice (15 rows per target)\n",
    "    for _, row in inference_slice.iterrows():\n",
    "        model_name = row['model_source_str']\n",
    "        pred_idx = row['prediction_index']\n",
    "        \n",
    "        # Get the prediction data for the specific model\n",
    "        pred_df_for_target = data_dfs[f'{model_name}_preds'][data_dfs[f'{model_name}_preds']['ID'].apply(get_base_target_id) == target_id]\n",
    "\n",
    "        if native_df_for_target.empty or pred_df_for_target.empty:\n",
    "            tm_score = np.nan\n",
    "        else:\n",
    "            tm_score = calculate_ground_truth_tm(pred_df_for_target, pred_idx, native_df_for_target)\n",
    "            \n",
    "        true_scores.append(tm_score)\n",
    "        \n",
    "    # Add the list of scores as a new column to the slice\n",
    "    inference_slice['true_tm_score'] = true_scores\n",
    "    all_target_results.append(inference_slice)\n",
    "\n",
    "# Concatenate all the small dataframes back into one\n",
    "df_analysis = pd.concat(all_target_results)\n",
    "\n",
    "print(\"✅ Analysis data prepared successfully.\")\n",
    "\n",
    "# --- DEBUGGING CHECK ---\n",
    "if df_analysis['true_tm_score'].isnull().all():\n",
    "    print(\"\\n❌ CRITICAL ERROR: Could not calculate any true TM-scores.\")\n",
    "else:\n",
    "    print(\"\\n✅ True TM-scores calculated and merged successfully.\")\n",
    "    \n",
    "    # --- Metric 1: \"Oracle Score\" ---\n",
    "    oracle_best_scores = df_analysis.groupby('target_id')['true_tm_score'].max()\n",
    "    oracle_score = oracle_best_scores.mean()\n",
    "    print(f\"1. Oracle Score (Theoretical Max): {oracle_score:.4f}\")\n",
    "\n",
    "    # --- Metric 2: Your Model's Achieved Score ---\n",
    "    # Assumes 'final_score' was correctly calculated in the cell above.\n",
    "    print(f\"2. Your Model's Achieved Score:     {final_score:.4f}\")\n",
    "    if oracle_score > 0:\n",
    "        print(f\"   (Your model achieved {final_score/oracle_score:.2%} of the theoretical maximum performance)\")\n",
    "\n",
    "    # --- Metric 3: Recall@5 ---\n",
    "    recall_hits = 0\n",
    "    total_targets = df_analysis['target_id'].nunique()\n",
    "    for target_id, group in df_analysis.groupby('target_id'):\n",
    "        if group['true_tm_score'].notna().any():\n",
    "            best_candidate_true_idx = group['true_tm_score'].idxmax()\n",
    "            top_5_predicted_indices = group.nlargest(5, 'predicted_tm').index\n",
    "            if best_candidate_true_idx in top_5_predicted_indices:\n",
    "                recall_hits += 1\n",
    "\n",
    "    if total_targets > 0:\n",
    "        recall_at_5 = recall_hits / total_targets\n",
    "        print(f\"\\n3. Recall@5 (Found the single best candidate): {recall_at_5:.2%} ({recall_hits}/{total_targets} targets)\")\n",
    "\n",
    "    # --- Metric 4: Distribution of selected models ---\n",
    "    print(\"\\n4. Distribution of Models in Your Final Top 5 Selection:\")\n",
    "    model_distribution = df_top5['model_source_str'].value_counts(normalize=True)\n",
    "    print(model_distribution)\n",
    "\n",
    "    # --- Metric 5: Average Predicted vs. True TM-score for each model ---\n",
    "    print(\"\\n5. Model Performance Analysis (Avg Predicted vs. True TM-score):\")\n",
    "    analysis_summary = df_analysis.groupby('model_source_str').agg(\n",
    "        avg_predicted_tm=('predicted_tm', 'mean'),\n",
    "        avg_true_tm=('true_tm_score', 'mean'),\n",
    "        count=('target_id', 'size')\n",
    "    ).sort_values(by='avg_true_tm', ascending=False)\n",
    "    print(analysis_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNA3D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
