{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c86973",
   "metadata": {},
   "source": [
    "## Install requirements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d44b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, tempfile, pathlib, subprocess, re, time\n",
    "from   timeit import default_timer as timer\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from   tqdm   import tqdm\n",
    "\n",
    "# ── user flags ──────────────────────────────────────────────────────────\n",
    "MODE        = \"local\"            #  <<<  \"local\"  or  \"submit\"\n",
    "RUN_LOCAL   = True\n",
    "RUN_KAGGLE  = not RUN_LOCAL\n",
    "\n",
    "NUM_CONF=5\n",
    "MAX_LENGTH=1000\n",
    "\n",
    "# assert torch.cuda.is_available(), \"Need an NVIDIA GPU.\"\n",
    "# print(\"torch\", torch.__version__, \"| cuda:\", torch.version.cuda,\n",
    "#       \"| gpu:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# ── pip installs (done once) ────────────────────────────────────────────\n",
    "!pip install --no-deps protenix biopython ml-collections \\\n",
    "                      biotite==1.0.1 rdkit\n",
    "\n",
    "# ── Protenix resource directory ────────────────────────────────────────\n",
    "os.environ[\"USE_DEEPSPEED_EVO_ATTENTION\"] = \"True\"\n",
    "\n",
    "if RUN_LOCAL:\n",
    "    ROOT_DIR = \"/home/max/Documents/Protenix-KaggleRNA3D/af3-dev\"\n",
    "else:\n",
    "    ROOT_DIR = \"/kaggle/input/protenix/af3-dev\"\n",
    "        \n",
    "os.environ[\"PROTENIX_DATA_ROOT_DIR\"] = ROOT_DIR\n",
    "print(\"PROTENIX_DATA_ROOT_DIR →\", ROOT_DIR)\n",
    "\n",
    "print(\"Setting random seeds for deterministic prediction...\")\n",
    "np.random.seed(0)\n",
    "torch.random.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7d154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_CSV = (\"/home/max/Documents/Protenix-KaggleRNA3D/data/stanford-rna-3d-folding/\"\n",
    "           f'{\"validation\" if MODE==\"local\" else \"test\"}_sequences.csv')\n",
    "# SEQ_CSV = (\"/kaggle/input/stanford-rna-3d-folding/\"\n",
    "#            f'{\"validation\" if MODE==\"local\" else \"test\"}_sequences.csv')\n",
    "df      = pd.read_csv(SEQ_CSV)\n",
    "\n",
    "if MODE == \"local\":\n",
    "    LABEL_CSV  = \"/kaggle/input/stanford-rna-3d-folding/validation_labels.csv\"\n",
    "    label_df   = pd.read_csv(LABEL_CSV)\n",
    "    label_df[\"target_id\"] = label_df.ID.str.rsplit(pat=\"_\", n=1).str[0]\n",
    "\n",
    "if MODE == \"local\":\n",
    "    LABEL_CSV  = \"/home/max/Documents/Protenix-KaggleRNA3D/data/stanford-rna-3d-folding/validation_labels_clean.csv\"\n",
    "    label_df   = pd.read_csv(LABEL_CSV)\n",
    "    label_df[\"target_id\"] = label_df.ID.str.rsplit(pat=\"_\", n=1).str[0]\n",
    "\n",
    "# build input JSON --------------------------------------------------------\n",
    "samples = [{\"name\":tid,\n",
    "            \"sequences\":[{\"rnaSequence\":{\"sequence\":seq,\"count\":1}}]}\n",
    "           for seq,tid in zip(df.sequence, df.target_id)]\n",
    "json_path = tempfile.mktemp(prefix=\"protenix_inputs_\", suffix=\".json\")\n",
    "json.dump(samples, open(json_path,\"w\"))\n",
    "print(\"json →\", json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8629c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from configs.configs_base       import configs as cfg_base\n",
    "from configs.configs_data       import data_configs\n",
    "from configs.configs_inference  import inference_configs\n",
    "from protenix.config.config     import parse_configs\n",
    "from runner.inference           import InferenceRunner, update_inference_configs\n",
    "\n",
    "ckpt_path = f\"/home/max/Documents/ProtenixFinetuningFinalResults/9999_NoMSA.pt\"\n",
    "\n",
    "os.environ[\"CUTLASS_PATH\"] = \"/home/max/Documents/Protenix-KaggleRNA3D/Cutlass/cutlass\"\n",
    "\n",
    "cfg_base[\"use_deepspeed_evo_attention\"]     = True\n",
    "cfg_base[\"model\"][\"N_cycle\"]                = 10\n",
    "cfg_base[\"sample_diffusion\"][\"N_step\"]      = 200\n",
    "cfg_base[\"sample_diffusion\"][\"N_sample\"]    = 5\n",
    "inference_configs[\"load_checkpoint_path\"]   = ckpt_path\n",
    "inference_configs[\"dtype\"]                  = \"bf16\"\n",
    "inference_configs[\"template\"] = {\n",
    "    \"use_templates\": False,\n",
    "    \"template_mmcif_dir\": \"\"\n",
    "}\n",
    "\n",
    "cfg = { **cfg_base,\n",
    "        **{\"data\": data_configs},\n",
    "        **inference_configs,\n",
    "        \"input_json_path\": json_path,\n",
    "        \"dump_dir\": tempfile.mkdtemp(prefix=\"pred_out_\") }\n",
    "\n",
    "cfg = parse_configs(cfg, fill_required_with_null=True)\n",
    "runner = InferenceRunner(cfg) \n",
    "print(\"model is\", type(runner.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332b49d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from protenix.data.infer_data_pipeline import InferenceDataset\n",
    "\n",
    "# --- Prediction Loop ---\n",
    "ds = InferenceDataset(json_path, dump_dir=\".\", use_msa=False)\n",
    "submission_rows = []\n",
    "confidence_rows = []\n",
    "ranking_data = []\n",
    "\n",
    "MAX_SEQ_LENGTH_THRESHOLD = 800\n",
    "\n",
    "for idx in tqdm(range(len(ds)), desc=\"Featurize → Predict\"):\n",
    "    data, atom_array, err = ds[idx]\n",
    "    tid = data[\"sample_name\"]\n",
    "    seq = df.loc[df.target_id == tid, \"sequence\"].values[0]\n",
    "\n",
    "    # Skip long sequences\n",
    "    if len(seq) > MAX_SEQ_LENGTH_THRESHOLD:\n",
    "        print(f\"  - ID: {tid}, Length: {len(seq)} > {MAX_SEQ_LENGTH_THRESHOLD}. SKIPPING.\")\n",
    "        for i, res in enumerate(seq, 1):\n",
    "            submission_rows.append([f\"{tid}_{i}\", res, i] + [0.0] * (NUM_CONF * 3))\n",
    "            confidence_rows.append([f\"{tid}_{i}\", res, i] + [0.0] * NUM_CONF)\n",
    "        ranking_entry = {'target_id': tid}\n",
    "        for k in range(NUM_CONF):\n",
    "            ranking_entry[f'ptm_{k+1}'] = 0.0\n",
    "            ranking_entry[f'ranking_score_{k+1}'] = 0.0\n",
    "        ranking_data.append(ranking_entry)\n",
    "        continue\n",
    "\n",
    "    # Handle featurization errors\n",
    "    if err:\n",
    "        print(f\"  - ID: {tid}, Featurization ERROR: {err}\")\n",
    "        for i, res in enumerate(seq, 1):\n",
    "            submission_rows.append([f\"{tid}_{i}\", res, i] + [0.0] * (NUM_CONF * 3))\n",
    "            confidence_rows.append([f\"{tid}_{i}\", res, i] + [0.0] * NUM_CONF)\n",
    "        ranking_entry = {'target_id': tid}\n",
    "        for k in range(NUM_CONF):\n",
    "            ranking_entry[f'ptm_{k+1}'] = 0.0\n",
    "            ranking_entry[f'ranking_score_{k+1}'] = 0.0\n",
    "        ranking_data.append(ranking_entry)\n",
    "        continue\n",
    "\n",
    "    # Run prediction\n",
    "    runner.update_model_configs(update_inference_configs(cfg, int(data[\"N_token\"])))\n",
    "    with torch.no_grad():\n",
    "        prediction_output = runner.predict(data)\n",
    "    \n",
    "    # Extract coordinates, pLDDT, and ranking scores\n",
    "    coord = prediction_output[\"coordinate\"]\n",
    "    atom_plddts = [d['atom_plddt'] * 100 for d in prediction_output['full_data']]\n",
    "    plddt_per_atom = torch.stack(atom_plddts, dim=0)\n",
    "    ptm_scores = [d['ptm'].item() for d in prediction_output['summary_confidence']]\n",
    "    ranking_scores = [d['ranking_score'].item() for d in prediction_output['summary_confidence']]\n",
    "    \n",
    "    ranking_entry = {'target_id': tid}\n",
    "    for k in range(NUM_CONF):\n",
    "        ranking_entry[f'ptm_{k+1}'] = ptm_scores[k] if k < len(ptm_scores) else 0.0\n",
    "        ranking_entry[f'ranking_score_{k+1}'] = ranking_scores[k] if k < len(ranking_scores) else 0.0\n",
    "    ranking_data.append(ranking_entry)\n",
    "    print(f\"  - ID: {tid}, Length: {len(seq)}, pTMs: {np.round(ptm_scores, 3)}\")\n",
    "\n",
    "    # Filter for C1' atoms\n",
    "    c1_mask = data[\"input_feature_dict\"][\"atom_to_tokatom_idx\"] == 12\n",
    "    coord_c1 = coord[:, c1_mask, :]\n",
    "    plddt_c1 = plddt_per_atom[:, c1_mask]\n",
    "\n",
    "    # Pad if necessary\n",
    "    while coord_c1.shape[0] < NUM_CONF:\n",
    "        coord_c1 = torch.cat([coord_c1, coord_c1[-1:]], dim=0)\n",
    "        plddt_c1 = torch.cat([plddt_c1, plddt_c1[-1:]], dim=0)\n",
    "\n",
    "    # Populate data for CSV files\n",
    "    for i, res in enumerate(seq, 1):\n",
    "        coord_triplets = coord_c1[:, i - 1, :].to(torch.float32).cpu().numpy().reshape(-1)\n",
    "        submission_rows.append([f\"{tid}_{i}\", res, i] + coord_triplets.tolist())\n",
    "\n",
    "        plddt_scores_per_res = plddt_c1[:, i - 1].to(torch.float32).cpu().numpy()\n",
    "        confidence_rows.append([f\"{tid}_{i}\", res, i] + plddt_scores_per_res.tolist())\n",
    "\n",
    "\n",
    "# --- Save Output Files ---\n",
    "print(\"\\nCreating output files...\")\n",
    "\n",
    "cols_sub = ([\"ID\", \"resname\", \"resid\"] + [f\"{ax}_{k}\" for k in range(1, NUM_CONF + 1) for ax in (\"x\", \"y\", \"z\")])\n",
    "sub_df = pd.DataFrame(submission_rows, columns=cols_sub)\n",
    "sub_df.to_csv(\"submission.csv\", index=False)\n",
    "print(f\"submission.csv written — shape: {sub_df.shape}\")\n",
    "\n",
    "cols_conf = ([\"ID\", \"resname\", \"resid\"] + [f\"plddt_{k}\" for k in range(1, NUM_CONF + 1)])\n",
    "conf_df = pd.DataFrame(confidence_rows, columns=cols_conf)\n",
    "conf_df.to_csv(\"confidence.csv\", index=False)\n",
    "print(f\"confidence.csv written — shape: {conf_df.shape}\")\n",
    "\n",
    "ranking_df = pd.DataFrame(ranking_data)\n",
    "ranking_df.to_csv(\"ranking_scores.csv\", index=False)\n",
    "print(f\"ranking_scores.csv written — shape: {ranking_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457d050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def parse_tmscore_output(output):\n",
    "    tm_score_match = re.findall(r'TM-score=\\s+([\\d.]+)', output)[1]\n",
    "    return float(tm_score_match)\n",
    "\n",
    "def write_target_line(\n",
    "    atom_name, atom_serial, residue_name, chain_id, residue_num,\n",
    "    x_coord, y_coord, z_coord, occupancy=1.0, b_factor=0.0, atom_type='P'\n",
    ") -> str:\n",
    "    return (\n",
    "        f'ATOM  {atom_serial:>5d}  {atom_name:<5s} {residue_name:<3s} '\n",
    "        f'{residue_num:>3d}    {x_coord:>8.3f}{y_coord:>8.3f}'\n",
    "        f'{z_coord:>8.3f}{occupancy:>6.2f}{b_factor:>6.2f}           {atom_type}\\n'\n",
    "    )\n",
    "\n",
    "def write2pdb(df: pd.DataFrame, xyz_id: int, target_path: str) -> int:\n",
    "    resolved_cnt = 0\n",
    "    with open(target_path, 'w') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            x = row[f'x_{xyz_id}']; y = row[f'y_{xyz_id}']; z = row[f'z_{xyz_id}']\n",
    "            if x > -1e17 and y > -1e17 and z > -1e17:\n",
    "                resolved_cnt += 1\n",
    "                f.write(write_target_line(\n",
    "                    atom_name=\"C1'\", atom_serial=int(row['resid']),\n",
    "                    residue_name=row['resname'], chain_id='0',\n",
    "                    residue_num=int(row['resid']),\n",
    "                    x_coord=x, y_coord=y, z_coord=z, atom_type='C'\n",
    "                ))\n",
    "    return resolved_cnt\n",
    "\n",
    "def get_base_target_id(long_id):\n",
    "    return \"_\".join(str(long_id).split(\"_\")[:-1])\n",
    "\n",
    "def score_and_report(solution: pd.DataFrame, submission: pd.DataFrame):\n",
    "    solution['target_id'] = solution['ID'].apply(get_base_target_id)\n",
    "    submission['target_id'] = submission['ID'].apply(get_base_target_id)\n",
    "\n",
    "    native_idxs = sorted(int(c.split('_')[1])\n",
    "                         for c in solution.columns if c.startswith('x_'))\n",
    "\n",
    "    usalign = \"/home/max/Documents/Protenix-KaggleRNA3D/af3-dev/USalign/USalign\"\n",
    "    per_target = {}\n",
    "    \n",
    "    # Find common targets to iterate over\n",
    "    common_targets = sorted(list(set(solution['target_id'].unique()) & set(submission['target_id'].unique())))\n",
    "    \n",
    "    print(f\"Scoring {len(common_targets)} common targets...\")\n",
    "\n",
    "    for tid in common_targets:\n",
    "        grp_nat = solution[solution['target_id'] == tid]\n",
    "        grp_pred = submission[submission['target_id'] == tid]\n",
    "        best_of_five = []\n",
    "\n",
    "        for pred_cnt in range(1, 6):\n",
    "            best_for_this_pred = 0.0\n",
    "            for nat_cnt in native_idxs:\n",
    "                n_nat  = write2pdb(grp_nat,   nat_cnt,   'native.pdb')\n",
    "                n_pred = write2pdb(grp_pred,  pred_cnt, 'predicted.pdb')\n",
    "                if n_nat > 0 and n_pred > 0:\n",
    "                    out = os.popen(\n",
    "                        f'{usalign} predicted.pdb native.pdb -atom \" C1\\'\"'\n",
    "                    ).read()\n",
    "                    best_for_this_pred = max(best_for_this_pred,\n",
    "                                             parse_tmscore_output(out))\n",
    "            best_of_five.append(best_for_this_pred)\n",
    "\n",
    "        per_target[tid] = best_of_five\n",
    "        print(f\"{tid}: TM-scores per model = {best_of_five}, \"\n",
    "              f\"best = {max(best_of_five):.4f}\")\n",
    "\n",
    "solution   = pd.read_csv(\n",
    "    \"/home/max/Documents/Protenix-KaggleRNA3D/data/stanford-rna-3d-folding/validation_labels_clean.csv\"\n",
    ")\n",
    "submission = pd.read_csv(\"submission.csv\")\n",
    "\n",
    "per_target_scores, mean_tm = score_and_report(solution, submission)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNA3D",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
