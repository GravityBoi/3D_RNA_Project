{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c0e40d6",
   "metadata": {
    "papermill": {
     "duration": 0.002549,
     "end_time": "2025-05-13T22:01:01.666109",
     "exception": false,
     "start_time": "2025-05-13T22:01:01.663560",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install requirements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1deb1cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T22:01:01.670952Z",
     "iopub.status.busy": "2025-05-13T22:01:01.670742Z",
     "iopub.status.idle": "2025-05-13T22:01:01.693026Z",
     "shell.execute_reply": "2025-05-13T22:01:01.692411Z"
    },
    "papermill": {
     "duration": 0.025952,
     "end_time": "2025-05-13T22:01:01.694244",
     "exception": false,
     "start_time": "2025-05-13T22:01:01.668292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created symlink for CCD file\n",
      "Created symlink for RDKIT file\n"
     ]
    }
   ],
   "source": [
    "    import os\n",
    "    os.makedirs(\"/usr/local/lib/python3.11/dist-packages/release_data/ccd_cache\", exist_ok=True)\n",
    "    \n",
    "    source_ccd_file = \"/kaggle/input/protenix/af3-dev/release_data/ccd_cache/components.cif\"\n",
    "    target_ccd_file = \"/usr/local/lib/python3.11/dist-packages/release_data/ccd_cache/components.cif\"\n",
    "    \n",
    "    source_rdkit_file = \"/kaggle/input/protenix/af3-dev/release_data/ccd_cache/components.cif.rdkit_mol.pkl\"\n",
    "    target_rdkit_file = \"/usr/local/lib/python3.11/dist-packages/release_data/ccd_cache/components.cif.rdkit_mol.pkl\"\n",
    "    \n",
    "    # Create the symlinks if the source files exist\n",
    "    if os.path.exists(source_ccd_file) and not os.path.exists(target_ccd_file):\n",
    "        try:\n",
    "            os.symlink(source_ccd_file, target_ccd_file)\n",
    "            print(f\"Created symlink for CCD file\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating symlink for CCD file: {e}\")\n",
    "    \n",
    "    if os.path.exists(source_rdkit_file) and not os.path.exists(target_rdkit_file):\n",
    "        try:\n",
    "            os.symlink(source_rdkit_file, target_rdkit_file)\n",
    "            print(f\"Created symlink for RDKIT file\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating symlink for RDKIT file: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68fdc164",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T22:01:01.699007Z",
     "iopub.status.busy": "2025-05-13T22:01:01.698818Z",
     "iopub.status.idle": "2025-05-13T22:01:14.331682Z",
     "shell.execute_reply": "2025-05-13T22:01:14.330642Z"
    },
    "papermill": {
     "duration": 12.637287,
     "end_time": "2025-05-13T22:01:14.333562",
     "exception": false,
     "start_time": "2025-05-13T22:01:01.696275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 2.5.1+cu124 | cuda: 12.4 | gpu: Tesla P100-PCIE-16GB\n",
      "Looking in links: /kaggle/input/protenix-wheel-bundle/wheels\r\n",
      "Processing /kaggle/input/protenix-wheel-bundle/wheels/protenix-0.4.6-py3-none-any.whl\r\n",
      "Processing /kaggle/input/protenix-wheel-bundle/wheels/biopython-1.83-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Processing /kaggle/input/protenix-wheel-bundle/wheels/ml_collections-1.1.0-py3-none-any.whl\r\n",
      "Processing /kaggle/input/protenix-wheel-bundle/wheels/biotite-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Processing /kaggle/input/protenix-wheel-bundle/wheels/rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl\r\n",
      "Installing collected packages: rdkit, protenix, ml-collections, biotite, biopython\r\n",
      "Successfully installed biopython-1.83 biotite-1.0.1 ml-collections-1.1.0 protenix-0.4.6 rdkit-2024.9.6\r\n",
      "PROTENIX_DATA_ROOT_DIR → /kaggle/input/protenix/af3-dev\n"
     ]
    }
   ],
   "source": [
    "import os, sys, json, tempfile, pathlib, subprocess, re, time\n",
    "from   timeit import default_timer as timer\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from   tqdm   import tqdm\n",
    "\n",
    "# ── user flags ──────────────────────────────────────────────────────────\n",
    "MODE        = \"submit\"            #  <<<  \"local\"  or  \"submit\"\n",
    "RUN_LOCAL   = False\n",
    "RUN_KAGGLE  = not RUN_LOCAL\n",
    "\n",
    "NUM_CONF=5\n",
    "MAX_LENGTH=20000\n",
    "\n",
    "assert torch.cuda.is_available(), \"Need an NVIDIA GPU.\"\n",
    "print(\"torch\", torch.__version__, \"| cuda:\", torch.version.cuda,\n",
    "      \"| gpu:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# ── pip installs (done once) ────────────────────────────────────────────\n",
    "# !pip install --no-deps protenix biopython ml-collections \\\n",
    "#                       biotite==1.0.1 rdkit\n",
    "\n",
    "!pip install --no-index --no-deps --find-links=/kaggle/input/protenix-wheel-bundle/wheels protenix biopython ml-collections biotite==1.0.1 rdkit\n",
    "\n",
    "# ── Protenix resource directory ────────────────────────────────────────\n",
    "os.environ[\"USE_DEEPSPEED_EVO_ATTENTION\"] = \"false\"\n",
    "\n",
    "if RUN_LOCAL:\n",
    "    ROOT_DIR = \"/home/max/Documents/Protenix-KaggleRNA3D/af3-dev\"\n",
    "else:\n",
    "    ROOT_DIR = \"/kaggle/input/protenix/af3-dev\"\n",
    "        \n",
    "os.environ[\"PROTENIX_DATA_ROOT_DIR\"] = ROOT_DIR\n",
    "print(\"PROTENIX_DATA_ROOT_DIR →\", ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00a62a04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T22:01:14.341480Z",
     "iopub.status.busy": "2025-05-13T22:01:14.340522Z",
     "iopub.status.idle": "2025-05-13T22:01:14.368591Z",
     "shell.execute_reply": "2025-05-13T22:01:14.367735Z"
    },
    "papermill": {
     "duration": 0.032627,
     "end_time": "2025-05-13T22:01:14.369733",
     "exception": false,
     "start_time": "2025-05-13T22:01:14.337106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json → /tmp/protenix_inputs_9euvm72_.json\n"
     ]
    }
   ],
   "source": [
    "# SEQ_CSV = (\"/home/max/Documents/Protenix-KaggleRNA3D/data/stanford-rna-3d-folding/\"\n",
    "#            f'{\"validation\" if MODE==\"local\" else \"test\"}_sequences.csv')\n",
    "SEQ_CSV = (\"/kaggle/input/stanford-rna-3d-folding/\"\n",
    "           f'{\"validation\" if MODE==\"local\" else \"test\"}_sequences.csv')\n",
    "df      = pd.read_csv(SEQ_CSV)\n",
    "\n",
    "if MODE == \"local\":\n",
    "    # LABEL_CSV  = \"/home/max/Documents/Protenix-KaggleRNA3D/data/stanford-rna-3d-folding/validation_labels.csv\"\n",
    "    LABEL_CSV  = \"/kaggle/input/stanford-rna-3d-folding/validation_labels.csv\"\n",
    "    label_df   = pd.read_csv(LABEL_CSV)\n",
    "    label_df[\"target_id\"] = label_df.ID.str.rsplit(pat=\"_\", n=1).str[0]\n",
    "\n",
    "# build input JSON --------------------------------------------------------\n",
    "samples = [{\"name\":tid,\n",
    "            \"sequences\":[{\"rnaSequence\":{\"sequence\":seq,\"count\":1}}]}\n",
    "           for seq,tid in zip(df.sequence, df.target_id)]\n",
    "json_path = tempfile.mktemp(prefix=\"protenix_inputs_\", suffix=\".json\")\n",
    "json.dump(samples, open(json_path,\"w\"))\n",
    "print(\"json →\", json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ba93641",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T22:01:14.375300Z",
     "iopub.status.busy": "2025-05-13T22:01:14.375066Z",
     "iopub.status.idle": "2025-05-13T22:01:14.378016Z",
     "shell.execute_reply": "2025-05-13T22:01:14.377513Z"
    },
    "papermill": {
     "duration": 0.006823,
     "end_time": "2025-05-13T22:01:14.379024",
     "exception": false,
     "start_time": "2025-05-13T22:01:14.372201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !cat /tmp/protenix_inputs_7x1cqjsu.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8114b746",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T22:01:14.384583Z",
     "iopub.status.busy": "2025-05-13T22:01:14.384410Z",
     "iopub.status.idle": "2025-05-13T22:01:14.387212Z",
     "shell.execute_reply": "2025-05-13T22:01:14.386612Z"
    },
    "papermill": {
     "duration": 0.006832,
     "end_time": "2025-05-13T22:01:14.388339",
     "exception": false,
     "start_time": "2025-05-13T22:01:14.381507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! ln -s /kaggle/input/protenix/af3-dev/release_data /release_data\n",
    "# ! ls /release_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c73c44e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T22:01:14.395080Z",
     "iopub.status.busy": "2025-05-13T22:01:14.394708Z",
     "iopub.status.idle": "2025-05-13T22:01:53.265855Z",
     "shell.execute_reply": "2025-05-13T22:01:53.264925Z"
    },
    "papermill": {
     "duration": 38.878857,
     "end_time": "2025-05-13T22:01:53.269590",
     "exception": false,
     "start_time": "2025-05-13T22:01:14.390733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try to find the ccd cache data in the code directory for inference.\n",
      "train scheduler 16.0\n",
      "inference scheduler 16.0\n",
      "Diffusion Module has 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/runner/inference.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is <class 'protenix.model.protenix.Protenix'>\n"
     ]
    }
   ],
   "source": [
    "from configs.configs_base       import configs as cfg_base\n",
    "from configs.configs_data       import data_configs\n",
    "from configs.configs_inference  import inference_configs\n",
    "from protenix.config.config     import parse_configs\n",
    "from runner.inference           import InferenceRunner, update_inference_configs\n",
    "\n",
    "ckpt_path = \"/kaggle/input/7ksteps-protenix-nomsa-75cropping/6999_ema_0.999.pt\"\n",
    "\n",
    "cfg_base[\"use_deepspeed_evo_attention\"]     = False\n",
    "cfg_base[\"model\"][\"N_cycle\"]                = 10\n",
    "cfg_base[\"sample_diffusion\"][\"N_step\"]      = 200\n",
    "cfg_base[\"sample_diffusion\"][\"N_sample\"]    = 5          # 1 if VRAM is tight\n",
    "inference_configs[\"load_checkpoint_path\"]   = ckpt_path\n",
    "inference_configs[\"dtype\"]                  = \"bf16\"     # GPU friendly\n",
    "\n",
    "cfg = { **cfg_base,\n",
    "        **{\"data\": data_configs},\n",
    "        **inference_configs,\n",
    "        \"input_json_path\": json_path,\n",
    "        \"dump_dir\": tempfile.mkdtemp(prefix=\"pred_out_\") }\n",
    "\n",
    "cfg = parse_configs(cfg, fill_required_with_null=True)\n",
    "runner = InferenceRunner(cfg) \n",
    "print(\"model is\", type(runner.model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a153d18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T22:01:53.277979Z",
     "iopub.status.busy": "2025-05-13T22:01:53.277531Z",
     "iopub.status.idle": "2025-05-13T22:36:58.473002Z",
     "shell.execute_reply": "2025-05-13T22:36:58.472156Z"
    },
    "papermill": {
     "duration": 2105.201996,
     "end_time": "2025-05-13T22:36:58.474557",
     "exception": false,
     "start_time": "2025-05-13T22:01:53.272561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurize → Predict:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Dataset load time: 11.90s\n",
      "[0] Config update time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/protenix/openfold_local/model/primitives.py:238: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/usr/local/lib/python3.11/dist-packages/protenix/openfold_local/model/primitives.py:215: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "/usr/local/lib/python3.11/dist-packages/protenix/openfold_local/model/primitives.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "Featurize → Predict:   8%|▊         | 1/12 [01:05<11:56, 65.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Prediction time: 53.22s\n",
      "[1] Dataset load time: 0.19s\n",
      "[1] Config update time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurize → Predict:  17%|█▋        | 2/12 [01:57<09:35, 57.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Prediction time: 52.05s\n",
      "[2] Dataset load time: 0.53s\n",
      "[2] Config update time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurize → Predict:  25%|██▌       | 3/12 [03:26<10:45, 71.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] Prediction time: 88.12s\n",
      "[3] Dataset load time: 0.08s\n",
      "[3] Config update time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurize → Predict:  33%|███▎      | 4/12 [04:15<08:22, 62.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3] Prediction time: 48.97s\n",
      "[4] Dataset load time: 1.77s\n",
      "[4] Config update time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurize → Predict:  42%|████▏     | 5/12 [08:46<16:05, 137.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] Prediction time: 269.20s\n",
      "[5] Dataset load time: 0.92s\n",
      "[5] Config update time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurize → Predict:  50%|█████     | 6/12 [11:13<14:06, 141.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] Prediction time: 146.57s\n",
      "[6] Dataset load time: 1.88s\n",
      "[6] Config update time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurize → Predict:  58%|█████▊    | 7/12 [15:55<15:36, 187.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6] Prediction time: 280.17s\n",
      "[7] Dataset load time: 5.56s\n",
      "[7] Config update time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurize → Predict:  67%|██████▋   | 8/12 [30:26<26:59, 404.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7] Prediction time: 864.93s\n",
      "[8] Dataset load time: 0.38s\n",
      "[8] Config update time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurize → Predict:  75%|███████▌  | 9/12 [31:35<14:59, 299.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8] Prediction time: 68.47s\n",
      "[9] Dataset load time: 0.42s\n",
      "[9] Config update time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurize → Predict:  83%|████████▎ | 10/12 [32:52<07:42, 231.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9] Prediction time: 77.10s\n",
      "[10] Dataset load time: 0.36s\n",
      "[10] Config update time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurize → Predict:  92%|█████████▏| 11/12 [33:58<03:00, 180.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] Prediction time: 65.86s\n",
      "[11] Dataset load time: 0.37s\n",
      "[11] Config update time: 0.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Featurize → Predict: 100%|██████████| 12/12 [35:05<00:00, 175.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11] Prediction time: 65.91s\n",
      "submission.csv written — shape: (2515, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from protenix.data.infer_data_pipeline import InferenceDataset\n",
    "import time\n",
    "\n",
    "ds = InferenceDataset(json_path, dump_dir=\".\", use_msa=False)\n",
    "rows = []\n",
    "\n",
    "for idx in tqdm(range(len(ds)), desc=\"Featurize → Predict\"):\n",
    "    start = time.time()\n",
    "    data, atom_array, err = ds[idx]\n",
    "    print(f\"[{idx}] Dataset load time: {time.time() - start:.2f}s\")\n",
    "    \n",
    "    tid  = data[\"sample_name\"]\n",
    "    seq  = df.loc[df.target_id == tid, \"sequence\"].values[0]\n",
    "    \n",
    "    # —— NEW LENGTH‐CUTOFF —— \n",
    "    if len(seq) > MAX_LENGTH:\n",
    "        print(f\"  ▶ Skipping {tid}: length {len(seq)} > {MAX_LENGTH}\")\n",
    "        # pad with zeros so row‐count stays correct\n",
    "        for i, res in enumerate(seq, 1):\n",
    "            rows.append([f\"{tid}_{i}\", res, i] + [0.0]* (NUM_CONF*3))\n",
    "        continue\n",
    "    # ————————————————\n",
    "\n",
    "    if err:\n",
    "        print(\"error:\" + err)\n",
    "        # your existing error‐padding\n",
    "        for i, res in enumerate(seq, 1):\n",
    "            rows.append([f\"{tid}_{i}\", res, i] + [0.0]* (NUM_CONF*3))\n",
    "        continue\n",
    "\n",
    "    # now safe to run Protenix on a sequence ≤ MAX_LENGTH\n",
    "    start = time.time()\n",
    "    runner.update_model_configs(update_inference_configs(cfg, int(data[\"N_token\"])))\n",
    "    print(f\"[{idx}] Config update time: {time.time() - start:.2f}s\")\n",
    "    \n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        coord = runner.predict(data)[\"coordinate\"]\n",
    "    print(f\"[{idx}] Prediction time: {time.time() - start:.2f}s\")\n",
    "\n",
    "    c1_mask = data[\"input_feature_dict\"][\"atom_to_tokatom_idx\"] == 12\n",
    "    coord   = coord[:, c1_mask, :]                  # [N_sample, L, 3]\n",
    "\n",
    "    # ensure exactly NUM_CONF samples\n",
    "    while coord.shape[0] < NUM_CONF:\n",
    "        coord = torch.cat([coord, coord[-1:]], dim=0) \n",
    "\n",
    "    for i, res in enumerate(seq, 1):\n",
    "        triplets = coord[:, i-1, :].cpu().numpy().reshape(-1)\n",
    "        rows.append([f\"{tid}_{i}\", res, i] + triplets.tolist())\n",
    "\n",
    "\n",
    "cols = ([\"ID\", \"resname\", \"resid\"] +\n",
    "        [f\"{ax}_{k}\" for k in range(1,6) for ax in (\"x\",\"y\",\"z\")])\n",
    "sub  = pd.DataFrame(rows, columns=cols)\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "print(\"submission.csv written — shape:\", sub.shape)\n",
    "# sub.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aad4a2b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T22:36:58.484760Z",
     "iopub.status.busy": "2025-05-13T22:36:58.484210Z",
     "iopub.status.idle": "2025-05-13T22:36:58.495641Z",
     "shell.execute_reply": "2025-05-13T22:36:58.495045Z"
    },
    "papermill": {
     "duration": 0.017694,
     "end_time": "2025-05-13T22:36:58.496712",
     "exception": false,
     "start_time": "2025-05-13T22:36:58.479018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "if MODE == \"local\":\n",
    "    USALIGN = \"/home/max/Documents/Protenix-KaggleRNA3D/af3-dev/USalign/USalign\"\n",
    "    if not os.access(USALIGN, os.X_OK):\n",
    "        os.chmod(USALIGN, 0o755)\n",
    "\n",
    "    def write_c1_pdb(xyz, seq, fname):\n",
    "        lines = []\n",
    "        for i, (r, (x, y, z)) in enumerate(zip(seq, xyz), start=1):\n",
    "            lines.append(\n",
    "                f\"ATOM  {i:5d}  C1' {r:>3s} A{i:4d}\"\n",
    "                f\"{x:8.3f}{y:8.3f}{z:8.3f}  1.00  0.00           C\\n\"\n",
    "            )\n",
    "        open(fname, \"w\").write(\"\".join(lines))\n",
    "\n",
    "    def align_once(pred_pdb, truth_pdb, timeout=15):\n",
    "        cmd = [USALIGN, pred_pdb, truth_pdb, \"-atom\", \" C1'\", \"-m\", \"-\"]\n",
    "        try:\n",
    "            res = subprocess.run(cmd,\n",
    "                                 stdout=subprocess.PIPE,\n",
    "                                 stderr=subprocess.PIPE,\n",
    "                                 text=True,\n",
    "                                 timeout=timeout)\n",
    "            tm = float(re.findall(r\"TM-score=\\s+([\\d.]+)\", res.stdout)[1])\n",
    "            return tm\n",
    "        except subprocess.TimeoutExpired:\n",
    "            print(\"⏱  USalign timed out\")\n",
    "            return 0.0\n",
    "        except Exception as e:\n",
    "            print(\"‼️ alignment failed:\", e)\n",
    "            return 0.0\n",
    "\n",
    "    tm_scores = []\n",
    "    for i, row in df.iterrows():\n",
    "        tid, seq = row.target_id, row.sequence\n",
    "        print(f\"\\n[{i}] {tid} (len={len(seq)})\")\n",
    "\n",
    "        # 1) pull out only the x_1,y_1,z_1 columns and sort by resid\n",
    "        truth_df = (\n",
    "            label_df\n",
    "              .query(\"target_id == @tid\")\n",
    "              .sort_values(\"resid\")\n",
    "              .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "        # 2) build a boolean mask of “real” coords (i.e. not the -1e+18 sentinel)\n",
    "        coords = truth_df[[\"x_1\",\"y_1\",\"z_1\"]].to_numpy(dtype=np.float64)\n",
    "        valid = (np.abs(coords) < 1e17).all(axis=1)   # keep anything <1e17\n",
    "\n",
    "        # 3) pull out your filtered truth coords and matching sequence letters\n",
    "        truth_xyz   = coords[valid].astype(np.float32)\n",
    "        resid_keep  = truth_df.loc[valid, \"resid\"].to_numpy(dtype=int)\n",
    "        # for each kept resid, grab the correct base from seq:\n",
    "        truth_seq   = [ seq[r-1] for r in resid_keep ]\n",
    "\n",
    "        # write your filtered truth PDB\n",
    "        truth_pdb = tempfile.mktemp(suffix=\".pdb\")\n",
    "        write_c1_pdb(truth_xyz, truth_seq, truth_pdb)\n",
    "\n",
    "        # 4) align each of your NUM_CONF predictions\n",
    "        best = 0.0\n",
    "        for c in range(NUM_CONF):\n",
    "            all_pred_xyz = (\n",
    "                sub.loc[\n",
    "                  sub.ID.str.startswith(f\"{tid}_\"),\n",
    "                  [f\"{ax}_{c+1}\" for ax in (\"x\",\"y\",\"z\")]\n",
    "                ]\n",
    "                .to_numpy(dtype=np.float32)\n",
    "                .reshape(-1,3)\n",
    "            )\n",
    "            # apply the same mask to your predictions\n",
    "            pred_xyz = all_pred_xyz[valid]\n",
    "\n",
    "            # write it out\n",
    "            pred_pdb = tempfile.mktemp(suffix=\".pdb\")\n",
    "            write_c1_pdb(pred_xyz, truth_seq, pred_pdb)\n",
    "\n",
    "            tm = align_once(pred_pdb, truth_pdb)\n",
    "            # print(f\"  model {c}: TM={tm:.4f}\")\n",
    "            best = max(best, tm)\n",
    "\n",
    "        # print(f\"→ best for {tid}: {best:.4f}\")\n",
    "        tm_scores.append(best)\n",
    "\n",
    "    print(\"\\nALL TM:\", tm_scores)\n",
    "    print(\"MEAN TM:\", np.mean(tm_scores))\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12276181,
     "sourceId": 87793,
     "sourceType": "competition"
    },
    {
     "datasetId": 7359437,
     "sourceId": 11723611,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7365948,
     "sourceId": 11733497,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7366109,
     "sourceId": 11733759,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7411267,
     "sourceId": 11801488,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2164.10219,
   "end_time": "2025-05-13T22:37:01.720499",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-13T22:00:57.618309",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
