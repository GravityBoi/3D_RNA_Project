{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2025-06-21T22:31:43.471885Z","iopub.status.busy":"2025-06-21T22:31:43.471556Z","iopub.status.idle":"2025-06-21T22:31:45.999519Z","shell.execute_reply":"2025-06-21T22:31:45.998586Z","shell.execute_reply.started":"2025-06-21T22:31:43.471858Z"},"trusted":true},"outputs":[],"source":["import stat\n","import pandas as pd\n","import numpy as np\n","import subprocess, tempfile, os, re, shutil, warnings\n","from typing import Dict, List, Tuple\n","from tqdm.auto import tqdm\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2025-06-21T22:32:03.716300Z","iopub.status.busy":"2025-06-21T22:32:03.715956Z","iopub.status.idle":"2025-06-21T22:32:03.744065Z","shell.execute_reply":"2025-06-21T22:32:03.743040Z","shell.execute_reply.started":"2025-06-21T22:32:03.716275Z"},"trusted":true},"outputs":[],"source":["class RNAEnsemble:\n","    def __init__(self):\n","        self.models = {}\n","        self.labels = None\n","        print(\"✓ RNA Ensemble initialized\")\n","    \n","    def load_data(self, file_paths):\n","        for name, path in file_paths.items():\n","            df = pd.read_csv(path)\n","            if name == 'labels':\n","                self.labels = df\n","            else:\n","                self.models[name] = df\n","        print(f\"Loaded: {list(self.models.keys())} + labels\")\n","    \n","    def create_ensemble(self, method='best_confidence'):\n","        all_ids = set()\n","        for df in self.models.values():\n","            all_ids.update(df['ID'].values)\n","        \n","        ensemble_rows = []\n","        \n","        for nuc_id in sorted(all_ids):\n","            model_rows = {}\n","            for name, df in self.models.items():\n","                row = df[df['ID'] == nuc_id]\n","                if not row.empty:\n","                    model_rows[name] = row.iloc[0]\n","            \n","            if len(model_rows) < len(self.models):\n","                continue\n","            \n","            ensemble_row = {\n","                'ID': nuc_id,\n","                'resname': list(model_rows.values())[0]['resname'],\n","                'resid': list(model_rows.values())[0]['resid']\n","            }\n","            \n","            for i in range(1, 6):\n","                if method == 'best_confidence':\n","                    # Pick model with highest confidence\n","                    best_conf = -1\n","                    best_coords = None\n","                    \n","                    for name, row in model_rows.items():\n","                        if name == 'drfold2':\n","                            conf = row.get(f'drfold_confidence_{i}', 0.5)\n","                        elif name == 'ribonanzanet2':\n","                            conf = row.get(f'ribo_confidence_{i}', 0.5)\n","                        else:\n","                            conf = row.get(f'confidence_{i}', 0.5)\n","                        \n","                        if conf > best_conf:\n","                            best_conf = conf\n","                            best_coords = [row[f'x_{i}'], row[f'y_{i}'], row[f'z_{i}']]\n","                    \n","                    coords = best_coords\n","\n","                elif method == 'naive':\n","                    coords_dict = {}\n","                    for name, row in model_rows.items():\n","                        coords_dict[name] = [row[f'x_{i}'], row[f'y_{i}'], row[f'z_{i}']]\n","                    if i in [1, 2, 3]:\n","                        coords = [model_rows['protenix'][f'x_{i}'],\n","                                  model_rows['protenix'][f'y_{i}'],\n","                                  model_rows['protenix'][f'z_{i}']]\n","                    else:\n","                        coords = [model_rows['drfold2'][f'x_{i-3}'],\n","                                  model_rows['drfold2'][f'y_{i-3}'],\n","                                  model_rows['drfold2'][f'z_{i-3}']]\n","                \n","                elif method == 'weighted_avg':\n","                    # Confidence-weighted average\n","                    coords_list, weights = [], []\n","                    for name, row in model_rows.items():\n","                        coords_list.append([row[f'x_{i}'], row[f'y_{i}'], row[f'z_{i}']])\n","                        if name == 'drfold2':\n","                            conf = row.get(f'drfold_confidence_{i}', 0.5)\n","                        elif name == 'ribonanzanet2':\n","                            conf = row.get(f'ribo_confidence_{i}', 0.5)\n","                        else:\n","                            conf = row.get(f'confidence_{i}', 0.5)\n","                        weights.append(conf)\n","                    \n","                    coords_array = np.array(coords_list)\n","                    weights = np.array(weights)\n","                    weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones_like(weights) / len(weights)\n","                    coords = np.sum(coords_array * weights.reshape(-1, 1), axis=0)\n","                \n","                elif method == 'simple_avg':\n","                    # Simple average\n","                    coords_list = []\n","                    for name, row in model_rows.items():\n","                        coords_list.append([row[f'x_{i}'], row[f'y_{i}'], row[f'z_{i}']])\n","                    coords = np.mean(coords_list, axis=0)\n","                \n","                elif method == 'adaptive_weighted':\n","                    # Square confidence weights to emphasize differences\n","                    coords_list, weights = [], []\n","                    for name, row in model_rows.items():\n","                        coords_list.append([row[f'x_{i}'], row[f'y_{i}'], row[f'z_{i}']])\n","                        if name == 'drfold2':\n","                            conf = row.get(f'drfold_confidence_{i}', 0.5)\n","                        elif name == 'ribonanzanet2':\n","                            conf = row.get(f'ribo_confidence_{i}', 0.5)\n","                        else:\n","                            conf = row.get(f'confidence_{i}', 0.5)\n","                        weights.append(conf ** 2)  # Square to emphasize differences\n","                    \n","                    coords_array = np.array(coords_list)\n","                    weights = np.array(weights)\n","                    weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones_like(weights) / len(weights)\n","                    coords = np.sum(coords_array * weights.reshape(-1, 1), axis=0)\n","                \n","                elif method == 'confidence_threshold':\n","                    # Only use predictions above threshold\n","                    threshold = 0.6\n","                    coords_list, weights = [], []\n","                    \n","                    for name, row in model_rows.items():\n","                        if name == 'drfold2':\n","                            conf = row.get(f'drfold_confidence_{i}', 0.5)\n","                        elif name == 'ribonanzanet2':\n","                            conf = row.get(f'ribo_confidence_{i}', 0.5)\n","                        else:\n","                            conf = row.get(f'confidence_{i}', 0.5)\n","                        \n","                        if conf >= threshold:\n","                            coords_list.append([row[f'x_{i}'], row[f'y_{i}'], row[f'z_{i}']])\n","                            weights.append(conf)\n","                    \n","                    if coords_list:\n","                        coords_array = np.array(coords_list)\n","                        weights = np.array(weights)\n","                        weights = weights / np.sum(weights)\n","                        coords = np.sum(coords_array * weights.reshape(-1, 1), axis=0)\n","                    else:\n","                        # Fallback to drfold2 if no predictions meet threshold\n","                        coords = [model_rows['protenix'][f'x_{i}'], \n","                                model_rows['protenix'][f'y_{i}'], \n","                                model_rows['protenix'][f'z_{i}']]\n","                \n","                elif method == 'dynamic':\n","                    # Dynamically select strategy based on confidence patterns\n","                    confidences = {}\n","                    coords_dict = {}\n","                    \n","                    for name, row in model_rows.items():\n","                        if name == 'drfold2':\n","                            conf = row.get(f'drfold_confidence_{i}', 0.5)\n","                        elif name == 'ribonanzanet2':\n","                            conf = row.get(f'ribo_confidence_{i}', 0.5)\n","                        else:\n","                            conf = row.get(f'confidence_{i}', 0.5)\n","                        \n","                        confidences[name] = conf\n","                        coords_dict[name] = [row[f'x_{i}'], row[f'y_{i}'], row[f'z_{i}']]\n","                    \n","                    max_conf = max(confidences.values())\n","                    conf_std = np.std(list(confidences.values()))\n","                    \n","                    if max_conf > 0.7:\n","                        # High confidence: use best model\n","                        best_model = max(confidences.items(), key=lambda x: x[1])[0]\n","                        coords = coords_dict[best_model]\n","                    elif conf_std < 0.1:\n","                        # Similar confidences: use weighted average\n","                        weights = np.array(list(confidences.values()))\n","                        weights = weights / np.sum(weights)\n","                        coords_array = np.array(list(coords_dict.values()))\n","                        coords = np.sum(coords_array * weights.reshape(-1, 1), axis=0)\n","                    else:\n","                        # Default: use best overall model\n","                        coords = coords_dict['protenix']\n","                        \n","                \n","                ensemble_row[f'x_{i}'] = coords[0]\n","                ensemble_row[f'y_{i}'] = coords[1]\n","                ensemble_row[f'z_{i}'] = coords[2]\n","            \n","            ensemble_rows.append(ensemble_row)\n","        \n","        return pd.DataFrame(ensemble_rows)\n","    \n","    def evaluate_all(self):\n","        results = {}\n","\n","        print(\"\\nEvaluating ensemble methods...\")\n","        # Evaluate ensembles\n","        ensemble_methods = ['naive',\n","            'best_confidence', 'weighted_avg', 'simple_avg', \n","            'adaptive_weighted', 'confidence_threshold', 'dynamic'\n","        ]\n","        \n","        for method in ensemble_methods:\n","            print(f\"Creating ensemble_{method}...\")\n","            ensemble_df = self.create_ensemble(method)\n","            ensemble_df.to_csv(f'/kaggle/working/{method}.csv', index=False)\n","        return results\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2025-06-21T22:32:06.716880Z","iopub.status.busy":"2025-06-21T22:32:06.716561Z","iopub.status.idle":"2025-06-21T22:33:11.446229Z","shell.execute_reply":"2025-06-21T22:33:11.445273Z","shell.execute_reply.started":"2025-06-21T22:32:06.716857Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["✓ RNA Ensemble initialized\n","Loaded: ['drfold2', 'ribonanzanet2', 'protenix'] + labels\n","\n","Evaluating ensemble methods...\n","Creating ensemble_naive...\n"]},{"data":{"text/plain":["{}"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# === RNA Ensemble Analysis ===\n","ensemble_analyzer = RNAEnsemble()\n","file_paths = {\n","    'drfold2': '/kaggle/input/predictions/drfold2_submission_with_confidence.csv',\n","    'ribonanzanet2': '/kaggle/input/predictions/ribonanzanet2_submission_with_confidence.csv',\n","    'protenix': '/kaggle/input/predictions/protenix_submission_with_confidence.csv',\n","    'labels': '/kaggle/input/validation-labels-clean-csv/validation_labels_clean.csv'\n","}\n","\n","ensemble_analyzer.load_data(file_paths)\n","ensemble_analyzer.evaluate_all()"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":12276181,"sourceId":87793,"sourceType":"competition"},{"datasetId":6742586,"sourceId":10855324,"sourceType":"datasetVersion"},{"datasetId":7655201,"sourceId":12158058,"sourceType":"datasetVersion"},{"datasetId":7684811,"sourceId":12199811,"sourceType":"datasetVersion"},{"datasetId":7684816,"sourceId":12199817,"sourceType":"datasetVersion"},{"datasetId":7697141,"sourceId":12217657,"sourceType":"datasetVersion"},{"datasetId":7697562,"sourceId":12218300,"sourceType":"datasetVersion"},{"datasetId":7699504,"sourceId":12221035,"sourceType":"datasetVersion"},{"datasetId":7699571,"sourceId":12221131,"sourceType":"datasetVersion"}],"dockerImageVersionId":31040,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"}},"nbformat":4,"nbformat_minor":4}
