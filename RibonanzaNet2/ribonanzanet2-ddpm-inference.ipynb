{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":87793,"databundleVersionId":12276181,"sourceType":"competition"},{"sourceId":10855324,"sourceType":"datasetVersion","datasetId":6742586},{"sourceId":11278691,"sourceType":"datasetVersion","datasetId":7051341},{"sourceId":11279607,"sourceType":"datasetVersion","datasetId":7051942},{"sourceId":11469248,"sourceType":"datasetVersion","datasetId":7187409},{"sourceId":12199811,"sourceType":"datasetVersion","datasetId":7684811},{"sourceId":12199817,"sourceType":"datasetVersion","datasetId":7684816},{"sourceId":311741,"sourceType":"modelInstanceVersion","modelInstanceId":264400,"modelId":285488}],"dockerImageVersionId":30919,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport random\nimport pickle\nimport os\nimport sys","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-17T21:26:53.684289Z","iopub.execute_input":"2025-06-17T21:26:53.684659Z","iopub.status.idle":"2025-06-17T21:26:57.141788Z","shell.execute_reply.started":"2025-06-17T21:26:53.684629Z","shell.execute_reply":"2025-06-17T21:26:57.140834Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"config = {\n    \"seed\": 0,\n    \"cutoff_date\": \"2020-01-01\",\n    \"test_cutoff_date\": \"2022-05-01\",\n    \"max_len\": 384,\n    \"batch_size\": 1,\n    \"learning_rate\": 1e-4,\n    \"weight_decay\": 0.0,\n    \"mixed_precision\": \"bf16\",\n    \"model_config_path\": \"../working/configs/pairwise.yaml\",  # Adjust path as needed\n    \"epochs\": 10,\n    \"cos_epoch\": 5,\n    \"loss_power_scale\": 1.0,\n    \"max_cycles\": 1,\n    \"grad_clip\": 0.1,\n    \"gradient_accumulation_steps\": 1,\n    \"d_clamp\": 30,\n    \"max_len_filter\": 9999999,\n    \"structural_violation_epoch\": 50,\n    \"balance_weight\": False,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T21:27:12.089555Z","iopub.execute_input":"2025-06-17T21:27:12.089973Z","iopub.status.idle":"2025-06-17T21:27:12.094402Z","shell.execute_reply.started":"2025-06-17T21:27:12.089951Z","shell.execute_reply":"2025-06-17T21:27:12.093580Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"test_data=pd.read_csv(\"/kaggle/input/validation-sequences-clean-csv/validation_sequences_clean.csv\")\ntest_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T21:27:35.129903Z","iopub.execute_input":"2025-06-17T21:27:35.130219Z","iopub.status.idle":"2025-06-17T21:27:35.150437Z","shell.execute_reply.started":"2025-06-17T21:27:35.130194Z","shell.execute_reply":"2025-06-17T21:27:35.149814Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"  target_id                                           sequence  \\\n0    9L5R_2  AGCUCUCUUUGCCUUUUGGCUUAGAUCAAGUGUAGUAUCUGUUCUU...   \n1   9GFT_AU  GGGGCUAUAGCUCAGCUGGGAGAGCGCUUGCAUGGCAUGCAAGAGG...   \n2    9L0R_K  GCCGUCUCAAUAGUGGCUUAGCACAGAUAAUCCAUAGCGAUAUGGG...   \n3   9GFT_A3  GGCUACGUAGCUCAGUUGGUUAGAGCACAUCACUCAUAAUGAUGGG...   \n4    9B2K_B  AAACAGCAUAGCAAGUUAAAAUAAGGCUAGUCCGUUAUCAACUUGA...   \n\n  temporal_cutoff                                        description  \\\n0      2025-03-12  Cryo-EM structure of the thermophile spliceoso...   \n1      2025-02-12  Structure of the HrpA-bound E. coli disome, Cl...   \n2      2025-03-19       Streptococcus agalactiae GOLLD RNA dodecamer   \n3      2025-02-12  Structure of the HrpA-bound E. coli disome, Cl...   \n4      2025-03-26    SpCas9 with dual-guide RNA in open conformation   \n\n                                       all_sequences  \n0  >9L5R_1|Chain A[auth 2]|U2 snRNA|Chaetomium th...  \n1  >9GFT_1|Chains A[auth 0], N[auth AA]|16S ribos...  \n2  >9L0R_1|Chains A, B, C, D, E, F, G, H, I, J, K...  \n3  >9GFT_1|Chains A[auth 0], N[auth AA]|16S ribos...  \n4  >9B2K_1|Chain A|RNA (5'-R(P*GP*UP*UP*UP*UP*AP*...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target_id</th>\n      <th>sequence</th>\n      <th>temporal_cutoff</th>\n      <th>description</th>\n      <th>all_sequences</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9L5R_2</td>\n      <td>AGCUCUCUUUGCCUUUUGGCUUAGAUCAAGUGUAGUAUCUGUUCUU...</td>\n      <td>2025-03-12</td>\n      <td>Cryo-EM structure of the thermophile spliceoso...</td>\n      <td>&gt;9L5R_1|Chain A[auth 2]|U2 snRNA|Chaetomium th...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9GFT_AU</td>\n      <td>GGGGCUAUAGCUCAGCUGGGAGAGCGCUUGCAUGGCAUGCAAGAGG...</td>\n      <td>2025-02-12</td>\n      <td>Structure of the HrpA-bound E. coli disome, Cl...</td>\n      <td>&gt;9GFT_1|Chains A[auth 0], N[auth AA]|16S ribos...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9L0R_K</td>\n      <td>GCCGUCUCAAUAGUGGCUUAGCACAGAUAAUCCAUAGCGAUAUGGG...</td>\n      <td>2025-03-19</td>\n      <td>Streptococcus agalactiae GOLLD RNA dodecamer</td>\n      <td>&gt;9L0R_1|Chains A, B, C, D, E, F, G, H, I, J, K...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9GFT_A3</td>\n      <td>GGCUACGUAGCUCAGUUGGUUAGAGCACAUCACUCAUAAUGAUGGG...</td>\n      <td>2025-02-12</td>\n      <td>Structure of the HrpA-bound E. coli disome, Cl...</td>\n      <td>&gt;9GFT_1|Chains A[auth 0], N[auth AA]|16S ribos...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9B2K_B</td>\n      <td>AAACAGCAUAGCAAGUUAAAAUAAGGCUAGUCCGUUAUCAACUUGA...</td>\n      <td>2025-03-26</td>\n      <td>SpCas9 with dual-guide RNA in open conformation</td>\n      <td>&gt;9B2K_1|Chain A|RNA (5'-R(P*GP*UP*UP*UP*UP*AP*...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\nclass RNADataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n        # Add a mapping for unknown nucleotides (X, N, etc.)\n        self.tokens = {nt: i for i, nt in enumerate('ACGU')}\n        # Map unknown nucleotides to a default value (e.g., 'A' = 0)\n        self.unknown_token = 0  # Maps to 'A'\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        sequence_str = self.data.loc[idx, 'sequence']\n        sequence = []\n        \n        for nt in sequence_str:\n            if nt in self.tokens:\n                sequence.append(self.tokens[nt])\n            else:\n                # Handle unknown nucleotides (X, N, etc.)\n                sequence.append(self.unknown_token)\n        \n        sequence = np.array(sequence)\n        sequence = torch.tensor(sequence)\n        \n        return {'sequence': sequence}\n\ntest_dataset=RNADataset(test_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T21:48:34.803348Z","iopub.execute_input":"2025-06-17T21:48:34.803708Z","iopub.status.idle":"2025-06-17T21:48:34.809540Z","shell.execute_reply.started":"2025-06-17T21:48:34.803682Z","shell.execute_reply":"2025-06-17T21:48:34.808696Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"sys.path.append(\"/kaggle/input/ribonanzanet2/pytorch/alpha/1\")\n\nimport torch.nn as nn\nfrom Network import *\n\nclass SinusoidalPosEmb(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.dim = dim\n\n    def forward(self, x):\n        device = x.device\n        half_dim = self.dim // 2\n        emb = math.log(10000) / (half_dim - 1)\n        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n        emb = x[:, None] * emb[None, :]\n        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n        return emb\n\nclass finetuned_RibonanzaNet(RibonanzaNet):\n    def __init__(self, rnet_config, config, pretrained=False):\n        rnet_config.dropout=0.1\n        rnet_config.use_grad_checkpoint=True\n        super(finetuned_RibonanzaNet, self).__init__(rnet_config)\n        if pretrained:\n            self.load_state_dict(torch.load(config.pretrained_weight_path,map_location='cpu'))\n        # self.ct_predictor=nn.Sequential(nn.Linear(64,256),\n        #                                 nn.ReLU(),\n        #                                 nn.Linear(256,64),\n        #                                 nn.ReLU(),\n        #                                 nn.Linear(64,1)) \n        self.dropout=nn.Dropout(0.0)\n\n        decoder_dim=config.decoder_dim\n        self.structure_module=[SimpleStructureModule(d_model=decoder_dim, nhead=config.decoder_nhead, \n                 dim_feedforward=decoder_dim*4, pairwise_dimension=rnet_config.pairwise_dimension, dropout=0.0) for i in range(config.decoder_num_layers)]\n        self.structure_module=nn.ModuleList(self.structure_module)\n\n        self.xyz_embedder=nn.Linear(3,decoder_dim)\n        self.xyz_norm=nn.LayerNorm(decoder_dim)\n        self.xyz_predictor=nn.Linear(decoder_dim,3)\n        \n        self.adaptor=nn.Sequential(nn.Linear(rnet_config.ninp,decoder_dim),nn.LayerNorm(decoder_dim))\n\n        self.distogram_predictor=nn.Sequential(nn.LayerNorm(rnet_config.pairwise_dimension),\n                                                nn.Linear(rnet_config.pairwise_dimension,40))\n\n        self.time_embedder=SinusoidalPosEmb(decoder_dim)\n\n        self.time_mlp=nn.Sequential(nn.Linear(decoder_dim,decoder_dim),\n                                    nn.ReLU(),  \n                                    nn.Linear(decoder_dim,decoder_dim))\n        self.time_norm=nn.LayerNorm(decoder_dim)\n\n        self.distance2pairwise=nn.Linear(1,rnet_config.pairwise_dimension,bias=False)\n\n        self.pair_mlp=nn.Sequential(nn.Linear(rnet_config.pairwise_dimension,rnet_config.pairwise_dimension),\n                                    nn.ReLU(),\n                                    nn.Linear(rnet_config.pairwise_dimension,rnet_config.pairwise_dimension))\n\n\n        #hyperparameters for diffusion\n        self.n_times = config.n_times\n\n        #self.model = model\n        \n        # define linear variance schedule(betas)\n        beta_1, beta_T = config.beta_min, config.beta_max\n        betas = torch.linspace(start=beta_1, end=beta_T, steps=config.n_times)#.to(device) # follows DDPM paper\n        self.sqrt_betas = torch.sqrt(betas)\n                                     \n        # define alpha for forward diffusion kernel\n        self.alphas = 1 - betas\n        self.sqrt_alphas = torch.sqrt(self.alphas)\n        alpha_bars = torch.cumprod(self.alphas, dim=0)\n        self.sqrt_one_minus_alpha_bars = torch.sqrt(1-alpha_bars)\n        self.sqrt_alpha_bars = torch.sqrt(alpha_bars)\n\n        self.data_std=config.data_std\n\n\n    def custom(self, module):\n        def custom_forward(*inputs):\n            inputs = module(*inputs)\n            return inputs\n        return custom_forward\n    \n    def embed_pair_distance(self,inputs):\n        pairwise_features,xyz=inputs\n        distance_matrix=xyz[:,None,:,:]-xyz[:,:,None,:]\n        distance_matrix=(distance_matrix**2).sum(-1).clip(2,37**2).sqrt()\n        distance_matrix=distance_matrix[:,:,:,None]\n        pairwise_features=pairwise_features+self.distance2pairwise(distance_matrix)\n\n        return pairwise_features\n\n    def forward(self,src,xyz,t):\n        \n        #with torch.no_grad():\n        sequence_features, pairwise_features=self.get_embeddings(src, torch.ones_like(src).long().to(src.device))\n        \n        distogram=self.distogram_predictor(pairwise_features)\n\n        sequence_features=self.adaptor(sequence_features)\n\n        decoder_batch_size=xyz.shape[0]\n        sequence_features=sequence_features.repeat(decoder_batch_size,1,1)\n        \n\n        pairwise_features=pairwise_features.expand(decoder_batch_size,-1,-1,-1)\n\n        pairwise_features= checkpoint.checkpoint(self.custom(self.embed_pair_distance), [pairwise_features,xyz],use_reentrant=False)\n\n        time_embed=self.time_embedder(t).unsqueeze(1)\n        tgt=self.xyz_norm(sequence_features+self.xyz_embedder(xyz)+time_embed)\n\n        tgt=self.time_norm(tgt+self.time_mlp(tgt))\n\n        for layer in self.structure_module:\n            #tgt=layer([tgt, sequence_features,pairwise_features,xyz,None])\n            tgt=checkpoint.checkpoint(self.custom(layer),\n            [tgt, sequence_features,pairwise_features,xyz,None],\n            use_reentrant=False)\n            # xyz=xyz+self.xyz_predictor(sequence_features).squeeze(0)\n            # xyzs.append(xyz)\n            #print(sequence_features.shape)\n        \n        xyz=self.xyz_predictor(tgt).squeeze(0)\n        #.squeeze(0)\n\n        return xyz, distogram\n    \n\n    def denoise(self,sequence_features,pairwise_features,xyz,t):\n        decoder_batch_size=xyz.shape[0]\n        sequence_features=sequence_features.expand(decoder_batch_size,-1,-1)\n        pairwise_features=pairwise_features.expand(decoder_batch_size,-1,-1,-1)\n\n        pairwise_features=self.embed_pair_distance([pairwise_features,xyz])\n\n        sequence_features=self.adaptor(sequence_features)\n        time_embed=self.time_embedder(t).unsqueeze(1)\n        tgt=self.xyz_norm(sequence_features+self.xyz_embedder(xyz)+time_embed)\n        tgt=self.time_norm(tgt+self.time_mlp(tgt))\n        #xyz_batch_size=xyz.shape[0]\n        \n\n\n        for layer in self.structure_module:\n            tgt=layer([tgt, sequence_features,pairwise_features,xyz,None])\n            # xyz=xyz+self.xyz_predictor(sequence_features).squeeze(0)\n            # xyzs.append(xyz)\n            #print(sequence_features.shape)\n        xyz=self.xyz_predictor(tgt).squeeze(0)\n        # print(xyz.shape)\n        # exit()\n        return xyz\n\n\n    def extract(self, a, t, x_shape):\n        \"\"\"\n            from lucidrains' implementation\n                https://github.com/lucidrains/denoising-diffusion-pytorch/blob/beb2f2d8dd9b4f2bd5be4719f37082fe061ee450/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py#L376\n        \"\"\"\n        b, *_ = t.shape\n        out = a.gather(-1, t)\n        return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n    \n    def scale_to_minus_one_to_one(self, x):\n        # according to the DDPMs paper, normalization seems to be crucial to train reverse process network\n        return x * 2 - 1\n    \n    def reverse_scale_to_zero_to_one(self, x):\n        return (x + 1) * 0.5\n    \n    def make_noisy(self, x_zeros, t): \n        # assume we get raw data, so center and scale by 35\n        x_zeros = x_zeros - torch.nanmean(x_zeros,1,keepdim=True)\n        x_zeros = x_zeros/self.data_std\n        #rotate randomly\n        x_zeros = random_rotation_point_cloud_torch_batch(x_zeros)\n\n\n        # perturb x_0 into x_t (i.e., take x_0 samples into forward diffusion kernels)\n        epsilon = torch.randn_like(x_zeros).to(x_zeros.device)\n        \n        sqrt_alpha_bar = self.extract(self.sqrt_alpha_bars.to(x_zeros.device), t, x_zeros.shape)\n        sqrt_one_minus_alpha_bar = self.extract(self.sqrt_one_minus_alpha_bars.to(x_zeros.device), t, x_zeros.shape)\n        \n        # Let's make noisy sample!: i.e., Forward process with fixed variance schedule\n        #      i.e., sqrt(alpha_bar_t) * x_zero + sqrt(1-alpha_bar_t) * epsilon\n        noisy_sample = x_zeros * sqrt_alpha_bar + epsilon * sqrt_one_minus_alpha_bar\n    \n        return noisy_sample.detach(), epsilon\n    \n    \n    # def forward(self, x_zeros):\n    #     x_zeros = self.scale_to_minus_one_to_one(x_zeros)\n        \n    #     B, _, _, _ = x_zeros.shape\n        \n    #     # (1) randomly choose diffusion time-step\n    #     t = torch.randint(low=0, high=self.n_times, size=(B,)).long().to(x_zeros.device)\n        \n    #     # (2) forward diffusion process: perturb x_zeros with fixed variance schedule\n    #     perturbed_images, epsilon = self.make_noisy(x_zeros, t)\n        \n    #     # (3) predict epsilon(noise) given perturbed data at diffusion-timestep t.\n    #     pred_epsilon = self.model(perturbed_images, t)\n        \n    #     return perturbed_images, epsilon, pred_epsilon\n    \n    \n    def denoise_at_t(self, x_t, sequence_features, pairwise_features, timestep, t):\n        B, _, _ = x_t.shape\n        if t > 1:\n            z = torch.randn_like(x_t).to(sequence_features.device)\n        else:\n            z = torch.zeros_like(x_t).to(sequence_features.device)\n        \n        # at inference, we use predicted noise(epsilon) to restore perturbed data sample.\n        epsilon_pred = self.denoise(sequence_features, pairwise_features, x_t, timestep)\n        \n        alpha = self.extract(self.alphas.to(x_t.device), timestep, x_t.shape)\n        sqrt_alpha = self.extract(self.sqrt_alphas.to(x_t.device), timestep, x_t.shape)\n        sqrt_one_minus_alpha_bar = self.extract(self.sqrt_one_minus_alpha_bars.to(x_t.device), timestep, x_t.shape)\n        sqrt_beta = self.extract(self.sqrt_betas.to(x_t.device), timestep, x_t.shape)\n        \n        # denoise at time t, utilizing predicted noise\n        x_t_minus_1 = 1 / sqrt_alpha * (x_t - (1-alpha)/sqrt_one_minus_alpha_bar*epsilon_pred) + sqrt_beta*z\n        \n        return x_t_minus_1#.clamp(-1., 1)\n                \n    def sample(self, src, N):\n        # start from random noise vector, NxLx3\n        x_t = torch.randn((N, src.shape[1], 3)).to(src.device)\n        \n        # autoregressively denoise from x_T to x_0\n        #     i.e., generate image from noise, x_T\n\n        #first get conditioning\n        sequence_features, pairwise_features=self.get_embeddings(src, torch.ones_like(src).long().to(src.device))\n        # sequence_features=sequence_features.expand(N,-1,-1)\n        # pairwise_features=pairwise_features.expand(N,-1,-1,-1)\n        distogram=self.distogram_predictor(pairwise_features).squeeze()\n        distogram=distogram.squeeze()[:,:,2:40]*torch.arange(2,40).float().cuda() \n        distogram=distogram.sum(-1)  \n\n        for t in range(self.n_times-1, -1, -1):\n            timestep = torch.tensor([t]).repeat_interleave(N, dim=0).long().to(src.device)\n            x_t = self.denoise_at_t(x_t, sequence_features, pairwise_features, timestep, t)\n        \n        # denormalize x_0 into 0 ~ 1 ranged values.\n        #x_0 = self.reverse_scale_to_zero_to_one(x_t)\n        x_0 = x_t * self.data_std\n        return x_0, distogram\n\n\n\n\nclass SimpleStructureModule(nn.Module):\n\n    def __init__(self, d_model, nhead, \n                 dim_feedforward, pairwise_dimension, dropout=0.1,\n                 ):\n        super(SimpleStructureModule, self).__init__()\n        #self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n        self.self_attn = MultiHeadAttention(d_model, nhead, d_model//nhead, d_model//nhead, dropout=dropout)\n        #self.cross_attn = MultiHeadAttention(d_model, nhead, d_model//nhead, d_model//nhead, dropout=dropout)\n\n        self.linear1 = nn.Linear(d_model, dim_feedforward)\n        self.dropout = nn.Dropout(dropout)\n        self.linear2 = nn.Linear(dim_feedforward, d_model)\n\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.dropout1 = nn.Dropout(dropout)\n        self.dropout2 = nn.Dropout(dropout)\n\n        self.pairwise2heads=nn.Linear(pairwise_dimension,nhead,bias=False)\n        self.pairwise_norm=nn.LayerNorm(pairwise_dimension)\n\n        #self.distance2heads=nn.Linear(1,nhead,bias=False)\n        #self.pairwise_norm=nn.LayerNorm(pairwise_dimension)\n\n        self.activation = nn.GELU()\n\n        \n    def custom(self, module):\n        def custom_forward(*inputs):\n            inputs = module(*inputs)\n            return inputs\n        return custom_forward\n\n    def forward(self, input):\n        tgt , src,  pairwise_features, pred_t, src_mask = input\n        \n        #src = src*src_mask.float().unsqueeze(-1)\n\n        pairwise_bias=self.pairwise2heads(self.pairwise_norm(pairwise_features)).permute(0,3,1,2)\n\n        \n\n\n        #print(pairwise_bias.shape,distance_bias.shape)\n\n        #pairwise_bias=pairwise_bias+distance_bias\n\n\n        res=tgt\n        tgt,attention_weights = self.self_attn(tgt, tgt, tgt, mask=pairwise_bias, src_mask=src_mask)\n        tgt = res + self.dropout1(tgt)\n        tgt = self.norm1(tgt)\n\n        # print(tgt.shape,src.shape)\n        # exit()\n\n        res=tgt\n        tgt = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n        tgt = res + self.dropout2(tgt)\n        tgt = self.norm2(tgt)\n\n\n        return tgt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T21:48:38.000865Z","iopub.execute_input":"2025-06-17T21:48:38.001173Z","iopub.status.idle":"2025-06-17T21:48:38.029373Z","shell.execute_reply.started":"2025-06-17T21:48:38.001147Z","shell.execute_reply":"2025-06-17T21:48:38.028499Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import yaml\n\nclass Config:\n    def __init__(self, **entries):\n        self.__dict__.update(entries)\n        self.entries=entries\n\n    def print(self):\n        print(self.entries)\n\ndef load_config_from_yaml(file_path):\n    with open(file_path, 'r') as file:\n        config = yaml.safe_load(file)\n    return Config(**config)\n\n\ndiffusion_config=load_config_from_yaml(\"/kaggle/input/ribonanzanet2-ddpm-v2/diffusion_config.yaml\")\nrnet_config=load_config_from_yaml(\"/kaggle/input/ribonanzanet2/pytorch/alpha/1/pairwise.yaml\")\n\nmodel=finetuned_RibonanzaNet(rnet_config,diffusion_config).cuda()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T21:48:44.415280Z","iopub.execute_input":"2025-06-17T21:48:44.415621Z","iopub.status.idle":"2025-06-17T21:48:46.503713Z","shell.execute_reply.started":"2025-06-17T21:48:44.415593Z","shell.execute_reply":"2025-06-17T21:48:46.502770Z"}},"outputs":[{"name":"stdout","text":"constructing 48 ConvTransformerEncoderLayers\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"state_dict=torch.load(\"/kaggle/input/ribonanzanet2-ddpm-v2/RibonanzaNet-DDPM-v2.pt\",map_location='cpu')\n\n#get rid of module. from ddp state dict\nnew_state_dict={}\n\nfor key in state_dict:\n    new_state_dict[key[7:]]=state_dict[key]\n\nmodel.load_state_dict(new_state_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T21:48:53.042565Z","iopub.execute_input":"2025-06-17T21:48:53.042862Z","iopub.status.idle":"2025-06-17T21:48:53.803481Z","shell.execute_reply.started":"2025-06-17T21:48:53.042841Z","shell.execute_reply":"2025-06-17T21:48:53.802757Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-14-e7e9f88fe7ad>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict=torch.load(\"/kaggle/input/ribonanzanet2-ddpm-v2/RibonanzaNet-DDPM-v2.pt\",map_location='cpu')\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"from tqdm import tqdm\nmodel.eval()\npreds=[]\nfor i in tqdm(range(len(test_dataset))):\n    src=test_dataset[i]['sequence'].long()\n    src=src.unsqueeze(0).cuda()\n    target_id=test_data.loc[i,'target_id']\n\n    #tmp=[]\n    predicted_dm=[]\n    #for _ in range(5):\n    with torch.no_grad():\n        xyz,distogram=model.sample(src,5)\n\n    preds.append(xyz.cpu().numpy())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T21:48:59.148278Z","iopub.execute_input":"2025-06-17T21:48:59.148616Z","iopub.status.idle":"2025-06-17T22:38:39.983943Z","shell.execute_reply.started":"2025-06-17T21:48:59.148589Z","shell.execute_reply":"2025-06-17T22:38:39.983235Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 94/94 [49:40<00:00, 31.71s/it]  \n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"ID=[]\nresname=[]\nresid=[]\nx=[]\ny=[]\nz=[]\n\ndata=[]\n\nfor i in range(len(test_data)):\n    #print(test_data.loc[i])\n\n    \n    for j in range(len(test_data.loc[i,'sequence'])):\n        # ID.append(test_data.loc[i,'sequence_id']+f\"_{j+1}\")\n        # resname.append(test_data.loc[i,'sequence'][j])\n        # resid.append(j+1) # 1 indexed\n        row=[test_data.loc[i,'target_id']+f\"_{j+1}\",\n             test_data.loc[i,'sequence'][j],\n             j+1]\n\n        for k in range(5):\n            for kk in range(3):\n                row.append(preds[i][k][j][kk])\n        data.append(row)\n\ncolumns=['ID','resname','resid']\nfor i in range(1,6):\n    columns+=[f\"x_{i}\"]\n    columns+=[f\"y_{i}\"]\n    columns+=[f\"z_{i}\"]\n\n\nsubmission=pd.DataFrame(data,columns=columns)\n\n\nsubmission\nsubmission.to_csv('submission.csv',index=False)\nprint(submission)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T22:41:08.990767Z","iopub.execute_input":"2025-06-17T22:41:08.991048Z","iopub.status.idle":"2025-06-17T22:41:09.580591Z","shell.execute_reply.started":"2025-06-17T22:41:08.991030Z","shell.execute_reply":"2025-06-17T22:41:09.579612Z"}},"outputs":[{"name":"stdout","text":"               ID resname  resid         x_1        y_1        z_1        x_2  \\\n0        9L5R_2_1       A      1  115.680298  20.948994 -83.126831  13.701052   \n1        9L5R_2_2       G      2  115.680695  16.281565 -77.371597   9.450191   \n2        9L5R_2_3       C      3  109.755745  14.659638 -74.048309   8.290426   \n3        9L5R_2_4       U      4  105.739998  10.953444 -73.434540   9.190623   \n4        9L5R_2_5       C      5  101.480087   8.412958 -74.487503  12.683903   \n...           ...     ...    ...         ...        ...        ...        ...   \n13777  9GBZ_R_131       C    131  -20.945736  37.823826 -38.323193  -6.622515   \n13778  9GBZ_R_132       C    132  -19.921278  34.150997 -35.603973  -7.201981   \n13779  9GBZ_R_133       U    133  -13.199568  25.931143 -35.741051 -11.134209   \n13780  9GBZ_R_134       U    134  -12.689199  33.496429 -36.152927  -5.907422   \n13781  9GBZ_R_135       U    135  -13.360568  29.193382 -34.808327  -8.004910   \n\n             y_2        z_2        x_3        y_3        z_3        x_4  \\\n0     -89.104118 -93.640335  -3.347059 -99.753181  60.895599 -79.581467   \n1     -86.389053 -90.415779   0.415796 -97.760735  55.659519 -72.382675   \n2     -83.551003 -86.403168   1.527724 -93.269432  51.966419 -67.099998   \n3     -80.730743 -82.713440  -0.146233 -88.304207  49.910583 -63.602211   \n4     -79.029877 -79.924240  -2.933028 -83.531128  49.867897 -61.380791   \n...          ...        ...        ...        ...        ...        ...   \n13777  37.174503 -38.378632  45.921482 -43.404102  -3.035672 -18.732737   \n13778  32.945396 -36.990078  42.099644 -41.262276   0.225383 -20.681755   \n13779  26.075720 -37.367916  39.086479 -34.424965   1.592325 -21.672846   \n13780  26.958752 -30.374487  38.968590 -32.990086   5.807047 -29.525932   \n13781  28.182323 -30.309668  38.320232 -32.674812   9.393902 -31.479769   \n\n             y_4        z_4        x_5        y_5         z_5  \n0      83.066315  -0.208563 -43.116741 -69.377190  104.920990  \n1      89.212051  -0.656291 -36.845589 -66.578278   98.282951  \n2      89.110168  -1.857358 -34.880581 -63.084961   93.366821  \n3      85.728333  -3.510870 -34.862732 -57.961445   90.275757  \n4      79.609627  -3.471469 -37.167828 -53.264435   89.270409  \n...          ...        ...        ...        ...         ...  \n13777 -14.573851  60.034660  67.172241  10.310445    0.391319  \n13778 -16.712313  54.335163  62.210594   7.637969    2.420364  \n13779 -17.652800  47.755299  57.132629   7.133810    2.286278  \n13780 -16.059065  45.979321  42.868031  -2.684844    5.532588  \n13781 -14.788252  43.440693  45.393124  -1.367321   -1.006878  \n\n[13782 rows x 18 columns]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import shutil\nimport os\n\n# Copy USalign to working directory and make it executable\nshutil.copy2(\"/kaggle/input/usalign/USalign\", \"/kaggle/working/USalign\")\nos.chmod(\"/kaggle/working/USalign\", 0o755)\n\nprint(\"USalign copied to /kaggle/working/ and made executable\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T22:47:28.308902Z","iopub.execute_input":"2025-06-17T22:47:28.309200Z","iopub.status.idle":"2025-06-17T22:47:28.349296Z","shell.execute_reply.started":"2025-06-17T22:47:28.309178Z","shell.execute_reply":"2025-06-17T22:47:28.348560Z"}},"outputs":[{"name":"stdout","text":"USalign copied to /kaggle/working/ and made executable\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import os\nimport re\nimport numpy as np\nimport pandas as pd\n\ndef parse_tmscore_output(output):\n    \"\"\"Parse TM-score from USalign output with detailed debugging\"\"\"\n    print(f\"DEBUG: Raw USalign output:\")\n    print(f\"'{output}'\")\n    print(f\"DEBUG: Output length: {len(output)}\")\n    \n    if not output.strip():\n        print(\"Warning: Empty output from USalign\")\n        return 0.0\n    \n    # Look for all TM-score patterns\n    tm_score_matches = re.findall(r'TM-score=\\s*([\\d.]+)', output)\n    print(f\"DEBUG: Found TM-score matches: {tm_score_matches}\")\n    \n    if len(tm_score_matches) == 0:\n        print(\"Warning: No TM-score found in output\")\n        return 0.0\n    elif len(tm_score_matches) == 1:\n        print(\"Warning: Only one TM-score found, using it\")\n        return float(tm_score_matches[0])\n    else:\n        print(f\"Found {len(tm_score_matches)} TM-scores, using the second one\")\n        return float(tm_score_matches[1])\n\ndef write_target_line(\n    atom_name, atom_serial, residue_name, chain_id, residue_num,\n    x_coord, y_coord, z_coord, occupancy=1.0, b_factor=0.0, atom_type='P'\n) -> str:\n    return (\n        f'ATOM  {atom_serial:>5d}  {atom_name:<5s} {residue_name:<3s} '\n        f'{residue_num:>3d}    {x_coord:>8.3f}{y_coord:>8.3f}'\n        f'{z_coord:>8.3f}{occupancy:>6.2f}{b_factor:>6.2f}           {atom_type}\\n'\n    )\n\ndef write2pdb(df: pd.DataFrame, xyz_id: int, target_path: str) -> int:\n    resolved_cnt = 0\n    with open(target_path, 'w') as f:\n        for _, row in df.iterrows():\n            x = row[f'x_{xyz_id}']; y = row[f'y_{xyz_id}']; z = row[f'z_{xyz_id}']\n            if x > -1e17 and y > -1e17 and z > -1e17:\n                resolved_cnt += 1\n                f.write(write_target_line(\n                    atom_name=\"C1'\", atom_serial=int(row['resid']),\n                    residue_name=row['resname'], chain_id='0',\n                    residue_num=int(row['resid']),\n                    x_coord=x, y_coord=y, z_coord=z, atom_type='C'\n                ))\n    return resolved_cnt\n\ndef test_usalign():\n    \"\"\"Test if USalign is working properly\"\"\"\n    usalign_path = \"/kaggle/working/USalign\"\n    \n    # Check if file exists\n    if not os.path.exists(usalign_path):\n        print(f\"ERROR: USalign not found at {usalign_path}\")\n        return False\n    \n    # Check if it's executable\n    if not os.access(usalign_path, os.X_OK):\n        print(f\"ERROR: USalign at {usalign_path} is not executable\")\n        print(\"Trying to make it executable...\")\n        os.chmod(usalign_path, 0o755)\n    \n    # Test basic execution\n    try:\n        test_output = os.popen(f'{usalign_path} 2>&1').read()\n        print(f\"USalign test output: {test_output[:200]}...\")\n        return True\n    except Exception as e:\n        print(f\"ERROR testing USalign: {e}\")\n        return False\n\ndef score_and_report_debug(solution: pd.DataFrame, submission: pd.DataFrame):\n    \"\"\"Scoring function with extensive debugging\"\"\"\n    print(\"=== Starting scoring with debug output ===\")\n    \n    # Test USalign first\n    if not test_usalign():\n        print(\"USalign test failed, cannot proceed with scoring\")\n        return {}, 0.0\n    \n    # extract target_id\n    solution['target_id'] = solution['ID'].str.split('_').str[0]\n    submission['target_id'] = submission['ID'].str.split('_').str[0]\n\n    native_idxs = sorted(int(c.split('_')[1])\n                         for c in solution.columns if c.startswith('x_'))\n    print(f\"Native structure indices: {native_idxs}\")\n\n    usalign = \"/kaggle/working/USalign\"\n    per_target = {}\n\n    # Test with just the first target for debugging\n    target_ids = solution['target_id'].unique()\n    print(f\"Found {len(target_ids)} targets, testing first one for debugging...\")\n    \n    for target_idx, (tid, grp_nat) in enumerate(solution.groupby('target_id')):\n        print(f\"\\n=== Processing target {tid} ({target_idx+1}/{len(target_ids)}) ===\")\n        grp_pred = submission[submission['target_id'] == tid]\n        \n        print(f\"Native group shape: {grp_nat.shape}\")\n        print(f\"Predicted group shape: {grp_pred.shape}\")\n        \n        best_of_five = []\n\n        for pred_cnt in range(1, 6):\n            print(f\"\\n--- Testing prediction {pred_cnt} ---\")\n            best_for_this_pred = 0.0\n            \n            for nat_cnt in native_idxs:\n                print(f\"Comparing prediction {pred_cnt} vs native {nat_cnt}\")\n                \n                n_nat = write2pdb(grp_nat, nat_cnt, 'native.pdb')\n                n_pred = write2pdb(grp_pred, pred_cnt, 'predicted.pdb')\n                \n                print(f\"Native atoms written: {n_nat}, Predicted atoms written: {n_pred}\")\n                \n                if n_nat > 0 and n_pred > 0:\n                    cmd = f'{usalign} predicted.pdb native.pdb -atom \" C1\\'\"'\n                    print(f\"Running command: {cmd}\")\n                    \n                    try:\n                        out = os.popen(cmd).read()\n                        score = parse_tmscore_output(out)\n                        print(f\"TM-score: {score}\")\n                        best_for_this_pred = max(best_for_this_pred, score)\n                    except Exception as e:\n                        print(f\"Error running USalign: {e}\")\n                        continue\n                else:\n                    print(\"Skipping due to empty structures\")\n            \n            best_of_five.append(best_for_this_pred)\n            print(f\"Best score for prediction {pred_cnt}: {best_for_this_pred}\")\n\n        per_target[tid] = best_of_five\n        print(f\"{tid}: TM-scores per model = {best_of_five}, best = {max(best_of_five):.4f}\")\n        \n        # Only process first target for debugging, remove this break for full scoring\n        if target_idx == 0:\n            print(\"=== Debug mode: stopping after first target ===\")\n            break\n\n    overall = np.mean([max(v) for v in per_target.values()]) if per_target else 0.0\n    print(f\"\\n>>> mean best-of-5 TM-score = {overall:.4f}\")\n    return per_target, overall\n\n# Quick function to check PDB files\ndef check_pdb_files():\n    \"\"\"Check if PDB files are being created correctly\"\"\"\n    for filename in ['native.pdb', 'predicted.pdb']:\n        if os.path.exists(filename):\n            with open(filename, 'r') as f:\n                content = f.read()\n                print(f\"\\n=== {filename} content (first 500 chars) ===\")\n                print(content[:500])\n                print(f\"=== {filename} total lines: {len(content.splitlines())} ===\")\n        else:\n            print(f\"{filename} does not exist\")\n\n# Main execution\nif __name__ == \"__main__\":\n    solution = pd.read_csv(\n        \"/kaggle/input/validation-labels-clean-csv/validation_labels_clean.csv\"\n    )\n    submission = pd.read_csv(\"submission.csv\")\n\n    print(\"Solution columns:\", solution.columns.tolist())\n    print(\"Submission columns:\", submission.columns.tolist())\n    print(\"Solution shape:\", solution.shape)\n    print(\"Submission shape:\", submission.shape)\n\n    # Run debug scoring\n    per_target_scores, mean_tm = score_and_report_debug(solution, submission)\n    \n    # Check PDB files after scoring\n    check_pdb_files()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T22:48:29.012976Z","iopub.execute_input":"2025-06-17T22:48:29.013263Z","iopub.status.idle":"2025-06-17T22:48:29.373467Z","shell.execute_reply.started":"2025-06-17T22:48:29.013244Z","shell.execute_reply":"2025-06-17T22:48:29.372532Z"}},"outputs":[{"name":"stdout","text":"Solution columns: ['ID', 'resname', 'resid', 'x_1', 'y_1', 'z_1']\nSubmission columns: ['ID', 'resname', 'resid', 'x_1', 'y_1', 'z_1', 'x_2', 'y_2', 'z_2', 'x_3', 'y_3', 'z_3', 'x_4', 'y_4', 'z_4', 'x_5', 'y_5', 'z_5']\nSolution shape: (13782, 6)\nSubmission shape: (13782, 18)\n=== Starting scoring with debug output ===\nUSalign test output: \n ********************************************************************\n * US-align (Version 20241108)                                      *\n * Universal Structure Alignment of Proteins and Nucleic Ac...\nNative structure indices: [1]\nFound 83 targets, testing first one for debugging...\n\n=== Processing target 8K85 (1/83) ===\nNative group shape: (56, 7)\nPredicted group shape: (56, 19)\n\n--- Testing prediction 1 ---\nComparing prediction 1 vs native 1\nNative atoms written: 56, Predicted atoms written: 56\nRunning command: /kaggle/working/USalign predicted.pdb native.pdb -atom \" C1'\"\nDEBUG: Raw USalign output:\n'\n ********************************************************************\n * US-align (Version 20241108)                                      *\n * Universal Structure Alignment of Proteins and Nucleic Acids      *\n * Reference: C Zhang, M Shine, AM Pyle, Y Zhang. (2022) Nat Methods*\n *            C Zhang, AM Pyle (2022) iScience.                     *\n * Please email comments and suggestions to zhang@zhanggroup.org    *\n ********************************************************************\n\nName of Structure_1: predicted.pdb:_ (to be superimposed onto Structure_2)\nName of Structure_2: native.pdb:_\nLength of Structure_1: 56 residues\nLength of Structure_2: 56 residues\n\nAligned length= 13, RMSD=   3.11, Seq_ID=n_identical/n_aligned= 1.000\nTM-score= 0.11458 (normalized by length of Structure_1: L=56, d0=1.97)\nTM-score= 0.11458 (normalized by length of Structure_2: L=56, d0=1.97)\n(You should use TM-score normalized by length of the reference structure)\n\n(\":\" denotes residue pairs of d < 5.0 Angstrom, \".\" denotes other aligned residues)\nggagacggucggguccagucgcaacgauguu-------------------------------ggcuguugagu-agugugugggcucc-----------\n                                                              :::::::..:  ::.                      \n-------------------------------ggagacggucggguccagucgcaacgauguuggcuguugag-uagu-----------gugugggcucc\n\n#Total CPU time is  0.00 seconds\n'\nDEBUG: Output length: 1377\nDEBUG: Found TM-score matches: ['0.11458', '0.11458']\nFound 2 TM-scores, using the second one\nTM-score: 0.11458\nBest score for prediction 1: 0.11458\n\n--- Testing prediction 2 ---\nComparing prediction 2 vs native 1\nNative atoms written: 56, Predicted atoms written: 56\nRunning command: /kaggle/working/USalign predicted.pdb native.pdb -atom \" C1'\"\nDEBUG: Raw USalign output:\n'\n ********************************************************************\n * US-align (Version 20241108)                                      *\n * Universal Structure Alignment of Proteins and Nucleic Acids      *\n * Reference: C Zhang, M Shine, AM Pyle, Y Zhang. (2022) Nat Methods*\n *            C Zhang, AM Pyle (2022) iScience.                     *\n * Please email comments and suggestions to zhang@zhanggroup.org    *\n ********************************************************************\n\nName of Structure_1: predicted.pdb:_ (to be superimposed onto Structure_2)\nName of Structure_2: native.pdb:_\nLength of Structure_1: 56 residues\nLength of Structure_2: 56 residues\n\nAligned length= 10, RMSD=   3.21, Seq_ID=n_identical/n_aligned= 0.900\nTM-score= 0.10062 (normalized by length of Structure_1: L=56, d0=1.97)\nTM-score= 0.10062 (normalized by length of Structure_2: L=56, d0=1.97)\n(You should use TM-score normalized by length of the reference structure)\n\n(\":\" denotes residue pairs of d < 5.0 Angstrom, \".\" denotes other aligned residues)\nggagacgg-ucggguccagucgcaacgauguuggcuguugaguagugugugggcucc---------------------------------------------\n.:::::.  :                                         ..                                                 \nggagacg-gu-----------------------------------------cg----gguccagucgcaacgauguuggcuguugaguagugugugggcucc\n\n#Total CPU time is  0.00 seconds\n'\nDEBUG: Output length: 1386\nDEBUG: Found TM-score matches: ['0.10062', '0.10062']\nFound 2 TM-scores, using the second one\nTM-score: 0.10062\nBest score for prediction 2: 0.10062\n\n--- Testing prediction 3 ---\nComparing prediction 3 vs native 1\nNative atoms written: 56, Predicted atoms written: 56\nRunning command: /kaggle/working/USalign predicted.pdb native.pdb -atom \" C1'\"\nDEBUG: Raw USalign output:\n'\n ********************************************************************\n * US-align (Version 20241108)                                      *\n * Universal Structure Alignment of Proteins and Nucleic Acids      *\n * Reference: C Zhang, M Shine, AM Pyle, Y Zhang. (2022) Nat Methods*\n *            C Zhang, AM Pyle (2022) iScience.                     *\n * Please email comments and suggestions to zhang@zhanggroup.org    *\n ********************************************************************\n\nName of Structure_1: predicted.pdb:_ (to be superimposed onto Structure_2)\nName of Structure_2: native.pdb:_\nLength of Structure_1: 56 residues\nLength of Structure_2: 56 residues\n\nAligned length= 29, RMSD=   3.09, Seq_ID=n_identical/n_aligned= 1.000\nTM-score= 0.26501 (normalized by length of Structure_1: L=56, d0=1.97)\nTM-score= 0.26501 (normalized by length of Structure_2: L=56, d0=1.97)\n(You should use TM-score normalized by length of the reference structure)\n\n(\":\" denotes residue pairs of d < 5.0 Angstrom, \".\" denotes other aligned residues)\nggagacggucggguccagucgcaacg--------------------------auguuggcuguugaguagugugu-gggcucc\n                                                    .:::::::::::::::::..::  :::::::\n--------------------------ggagacggucggguccagucgcaacgauguuggcuguugaguagugug-ugggcucc\n\n#Total CPU time is  0.00 seconds\n'\nDEBUG: Output length: 1329\nDEBUG: Found TM-score matches: ['0.26501', '0.26501']\nFound 2 TM-scores, using the second one\nTM-score: 0.26501\nBest score for prediction 3: 0.26501\n\n--- Testing prediction 4 ---\nComparing prediction 4 vs native 1\nNative atoms written: 56, Predicted atoms written: 56\nRunning command: /kaggle/working/USalign predicted.pdb native.pdb -atom \" C1'\"\nDEBUG: Raw USalign output:\n'\n ********************************************************************\n * US-align (Version 20241108)                                      *\n * Universal Structure Alignment of Proteins and Nucleic Acids      *\n * Reference: C Zhang, M Shine, AM Pyle, Y Zhang. (2022) Nat Methods*\n *            C Zhang, AM Pyle (2022) iScience.                     *\n * Please email comments and suggestions to zhang@zhanggroup.org    *\n ********************************************************************\n\nName of Structure_1: predicted.pdb:_ (to be superimposed onto Structure_2)\nName of Structure_2: native.pdb:_\nLength of Structure_1: 56 residues\nLength of Structure_2: 56 residues\n\nAligned length= 28, RMSD=   2.62, Seq_ID=n_identical/n_aligned= 1.000\nTM-score= 0.27572 (normalized by length of Structure_1: L=56, d0=1.97)\nTM-score= 0.27572 (normalized by length of Structure_2: L=56, d0=1.97)\n(You should use TM-score normalized by length of the reference structure)\n\n(\":\" denotes residue pairs of d < 5.0 Angstrom, \".\" denotes other aligned residues)\nggagacggucggguccagucgcaacga---------------------------uguuggcuguugaguagugugu-gggcucc\n                                                      ::::::::::::::::::.::  :::::::\n---------------------------ggagacggucggguccagucgcaacgauguuggcuguugaguagugug-ugggcucc\n\n#Total CPU time is  0.00 seconds\n'\nDEBUG: Output length: 1332\nDEBUG: Found TM-score matches: ['0.27572', '0.27572']\nFound 2 TM-scores, using the second one\nTM-score: 0.27572\nBest score for prediction 4: 0.27572\n\n--- Testing prediction 5 ---\nComparing prediction 5 vs native 1\nNative atoms written: 56, Predicted atoms written: 56\nRunning command: /kaggle/working/USalign predicted.pdb native.pdb -atom \" C1'\"\nDEBUG: Raw USalign output:\n'\n ********************************************************************\n * US-align (Version 20241108)                                      *\n * Universal Structure Alignment of Proteins and Nucleic Acids      *\n * Reference: C Zhang, M Shine, AM Pyle, Y Zhang. (2022) Nat Methods*\n *            C Zhang, AM Pyle (2022) iScience.                     *\n * Please email comments and suggestions to zhang@zhanggroup.org    *\n ********************************************************************\n\nName of Structure_1: predicted.pdb:_ (to be superimposed onto Structure_2)\nName of Structure_2: native.pdb:_\nLength of Structure_1: 56 residues\nLength of Structure_2: 56 residues\n\nAligned length= 28, RMSD=   2.63, Seq_ID=n_identical/n_aligned= 1.000\nTM-score= 0.27020 (normalized by length of Structure_1: L=56, d0=1.97)\nTM-score= 0.27020 (normalized by length of Structure_2: L=56, d0=1.97)\n(You should use TM-score normalized by length of the reference structure)\n\n(\":\" denotes residue pairs of d < 5.0 Angstrom, \".\" denotes other aligned residues)\nggagacggucggguccagucgcaacga---------------------------uguuggcuguugaguagugugu-gggcucc\n                                                      ::::::::::::::::::.::  :::::::\n---------------------------ggagacggucggguccagucgcaacgauguuggcuguugaguagugug-ugggcucc\n\n#Total CPU time is  0.00 seconds\n'\nDEBUG: Output length: 1332\nDEBUG: Found TM-score matches: ['0.27020', '0.27020']\nFound 2 TM-scores, using the second one\nTM-score: 0.2702\nBest score for prediction 5: 0.2702\n8K85: TM-scores per model = [0.11458, 0.10062, 0.26501, 0.27572, 0.2702], best = 0.2757\n=== Debug mode: stopping after first target ===\n\n>>> mean best-of-5 TM-score = 0.2757\n\n=== native.pdb content (first 500 chars) ===\nATOM      1  C1'   G     1      12.203  19.486-101.136  1.00  0.00           C\nATOM      2  C1'   G     2       6.845  18.058-100.242  1.00  0.00           C\nATOM      3  C1'   A     3       3.327  14.528 -98.580  1.00  0.00           C\nATOM      4  C1'   G     4       2.209   9.647 -95.383  1.00  0.00           C\nATOM      5  C1'   A     5       2.288   5.752 -91.493  1.00  0.00           C\nATOM      6  C1'   C     6       5.032   3.833 -87.377  1.00  0.00           C\nATOM      7  C1'   G     7\n=== native.pdb total lines: 56 ===\n\n=== predicted.pdb content (first 500 chars) ===\nATOM      1  C1'   G     1     -24.718  21.755   5.925  1.00  0.00           C\nATOM      2  C1'   G     2     -20.714  21.439   1.872  1.00  0.00           C\nATOM      3  C1'   A     3     -15.878  21.987   0.586  1.00  0.00           C\nATOM      4  C1'   G     4     -10.694  21.989   1.233  1.00  0.00           C\nATOM      5  C1'   A     5      -5.483  21.339   2.942  1.00  0.00           C\nATOM      6  C1'   C     6      -2.233  18.064   5.753  1.00  0.00           C\nATOM      7  C1'   G     7\n=== predicted.pdb total lines: 56 ===\n","output_type":"stream"}],"execution_count":24}]}