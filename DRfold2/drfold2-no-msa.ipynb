{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42cd3ca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T22:31:10.393068Z",
     "iopub.status.busy": "2025-05-12T22:31:10.392769Z",
     "iopub.status.idle": "2025-05-12T22:31:14.650548Z",
     "shell.execute_reply": "2025-05-12T22:31:14.649666Z"
    },
    "papermill": {
     "duration": 4.265035,
     "end_time": "2025-05-12T22:31:14.651822",
     "exception": false,
     "start_time": "2025-05-12T22:31:10.386787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 2.5.1+cu121\n",
      "torch.cuda 12.1\n",
      "IMPORT OK!!!\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from timeit import default_timer as timer\n",
    "import re\n",
    "import optuna\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# helper--\n",
    "class dotdict(dict):\n",
    "\t__setattr__ = dict.__setitem__\n",
    "\t__delattr__ = dict.__delitem__\n",
    "\n",
    "\tdef __getattr__(self, name):\n",
    "\t\ttry:\n",
    "\t\t\treturn self[name]\n",
    "\t\texcept KeyError:\n",
    "\t\t\traise AttributeError(name)\n",
    "\n",
    "def time_to_str(t, mode='min'):\n",
    "\tif mode=='min':\n",
    "\t\tt  = int(t)/60\n",
    "\t\thr = t//60\n",
    "\t\tmin = t%60\n",
    "\t\treturn '%2d hr %02d min'%(hr,min) \n",
    "\telif mode=='sec':\n",
    "\t\tt   = int(t)\n",
    "\t\tmin = t//60\n",
    "\t\tsec = t%60\n",
    "\t\treturn '%2d min %02d sec'%(min,sec)\n",
    "\n",
    "\telse:\n",
    "\t\traise NotImplementedError\n",
    "\n",
    "def gpu_memory_use():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(0)\n",
    "        free, total = torch.cuda.mem_get_info(device)\n",
    "        used= (total - free) / 1024 ** 3\n",
    "        return int(round(used))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def set_aspect_equal(ax):\n",
    "\tx_limits = ax.get_xlim()\n",
    "\ty_limits = ax.get_ylim()\n",
    "\tz_limits = ax.get_zlim()\n",
    "\n",
    "\t# Compute the mean of each axis\n",
    "\tx_middle = np.mean(x_limits)\n",
    "\ty_middle = np.mean(y_limits)\n",
    "\tz_middle = np.mean(z_limits)\n",
    "\n",
    "\t# Compute the max range across all axes\n",
    "\tmax_range = max(x_limits[1] - x_limits[0],\n",
    "\t\t\t\t\ty_limits[1] - y_limits[0],\n",
    "\t\t\t\t\tz_limits[1] - z_limits[0]) / 2.0\n",
    "\n",
    "\t# Set the new limits to ensure equal scaling\n",
    "\tax.set_xlim(x_middle - max_range, x_middle + max_range)\n",
    "\tax.set_ylim(y_middle - max_range, y_middle + max_range)\n",
    "\tax.set_zlim(z_middle - max_range, z_middle + max_range)\n",
    "\n",
    "\n",
    "print('torch',torch.__version__)\n",
    "print('torch.cuda',torch.version.cuda)\n",
    "\n",
    "print('IMPORT OK!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfc80252",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T22:31:14.662178Z",
     "iopub.status.busy": "2025-05-12T22:31:14.661815Z",
     "iopub.status.idle": "2025-05-12T22:31:15.033924Z",
     "shell.execute_reply": "2025-05-12T22:31:15.033222Z"
    },
    "papermill": {
     "duration": 0.378891,
     "end_time": "2025-05-12T22:31:15.035593",
     "exception": false,
     "start_time": "2025-05-12T22:31:14.656702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tuning\n",
    "class SequenceStructureDataset(Dataset):\n",
    "    def __init__(self, csv_file, data_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        features = np.load(self.data_dir / f\"{row['ID']}_features.npy\")\n",
    "        coords   = np.load(self.data_dir / f\"{row['ID']}_coords.npy\")\n",
    "        sample = {'features': torch.from_numpy(features).float(),\n",
    "                  'coords':   torch.from_numpy(coords).float()}\n",
    "        return self.transform(sample) if self.transform else sample\n",
    "\n",
    "\n",
    "DATA_KAGGLE_DIR = '/kaggle/input/stanford-rna-3d-folding'\n",
    "\n",
    "train_dataset = SequenceStructureDataset(\n",
    "    csv_file=f\"{DATA_KAGGLE_DIR}/train_labels.csv\",\n",
    "    data_dir=f\"{DATA_KAGGLE_DIR}/train_data\"\n",
    ")\n",
    "val_dataset = SequenceStructureDataset(\n",
    "    csv_file=f\"{DATA_KAGGLE_DIR}/validation_labels.csv\",\n",
    "    data_dir=f\"{DATA_KAGGLE_DIR}/validation_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1f2f570",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T22:31:15.045347Z",
     "iopub.status.busy": "2025-05-12T22:31:15.045117Z",
     "iopub.status.idle": "2025-05-12T22:31:15.048779Z",
     "shell.execute_reply": "2025-05-12T22:31:15.048211Z"
    },
    "papermill": {
     "duration": 0.009639,
     "end_time": "2025-05-12T22:31:15.049893",
     "exception": false,
     "start_time": "2025-05-12T22:31:15.040254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cfg = dict(\n",
    "#         seq_dim=6,\n",
    "#         msa_dim=7,\n",
    "#         N_ensemble=1,   # how many ensemble members\n",
    "#         N_cycle=8,      # how many recycling cycles\n",
    "#         m_dim=64,\n",
    "#     s_in_dim=5,\n",
    "#     z_in_dim=2,\n",
    "#     s_dim= 512,\n",
    "#     z_dim= 128,\n",
    "#     N_elayers=18,\n",
    "#     )\n",
    "# def train_and_evaluate(\n",
    "#     cfg: dict,\n",
    "#     lr: float = 1e-4,\n",
    "#     weight_decay: float = 1e-5,\n",
    "#     batch_size: int = 8,\n",
    "#     T_max: int = 10,\n",
    "#     num_epochs: int = 20,\n",
    "#     freeze_embed: bool = True,\n",
    "#     scheduler_type: str = 'cosine',\n",
    "#     optimizer_type: str = 'adamw',\n",
    "#     warmup_ratio: float = 0.0,\n",
    "#     device: torch.device = None\n",
    "# ) -> float:\n",
    "#     \"\"\"\n",
    "#     Fine-tunes DRfold2Model with the given configuration and returns average validation loss.\n",
    "#     Supports choosing optimizer, scheduler, and optional warmup.\n",
    "#     \"\"\"\n",
    "#     device = device or (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "\n",
    "#     # DataLoader for this run\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "#     val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "#     # Instantiate model\n",
    "#     model = DRfold2Model(cfg)\n",
    "#     model.load_state_dict(torch.load(\n",
    "#         '/kaggle/working/drfold/model_hub/drfold2_pretrained.pth'\n",
    "#     ))\n",
    "#     if freeze_embed:\n",
    "#         for name, param in model.named_parameters():\n",
    "#             if 'embed' in name:\n",
    "#                 param.requires_grad = False\n",
    "#     model.to(device)\n",
    "\n",
    "#     # Choose optimizer\n",
    "#     if optimizer_type == 'adamw':\n",
    "#         optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=weight_decay)\n",
    "#     else:\n",
    "#         optimizer = SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=weight_decay, momentum=0.9)\n",
    "\n",
    "#     # Choose scheduler\n",
    "#     if scheduler_type == 'cosine':\n",
    "#         scheduler = CosineAnnealingLR(optimizer, T_max=T_max)\n",
    "#     else:\n",
    "#         scheduler = StepLR(optimizer, step_size=max(1, T_max//2), gamma=0.1)\n",
    "\n",
    "#     # Optional warmup via LambdaLR\n",
    "#     if warmup_ratio > 0.0:\n",
    "#         warmup_steps = int(warmup_ratio * num_epochs)\n",
    "#         def lr_lambda(epoch):\n",
    "#             return min((epoch + 1) / warmup_steps, 1.0)\n",
    "#         scheduler = LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "#     criterion = nn.MSELoss()\n",
    "\n",
    "#     # Training loop\n",
    "#     for epoch in range(1, num_epochs + 1):\n",
    "#         model.train()\n",
    "#         total_loss = 0.0\n",
    "#         for batch in train_loader:\n",
    "#             feats  = batch['features'].to(device)\n",
    "#             target = batch['coords'].to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             pred   = model(feats)\n",
    "#             loss   = criterion(pred, target)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#         scheduler.step()\n",
    "\n",
    "#     # Validation\n",
    "#     model.eval()\n",
    "#     val_loss = 0.0\n",
    "#     with torch.no_grad():\n",
    "#         for batch in val_loader:\n",
    "#             feats  = batch['features'].to(device)\n",
    "#             target = batch['coords'].to(device)\n",
    "#             val_loss += criterion(model(feats), target).item()\n",
    "\n",
    "#     avg_val_loss = val_loss / len(val_loader)\n",
    "#     return avg_val_loss\n",
    "\n",
    "# smoke_loss = train_and_evaluate(\n",
    "#     cfg=cfg,\n",
    "#     lr=1e-4,\n",
    "#     weight_decay=1e-5,\n",
    "#     batch_size=4,\n",
    "#     T_max=5,\n",
    "#     num_epochs=1,\n",
    "#     freeze_embed=True\n",
    "# )\n",
    "# print(\"Validation loss after 1 epoch:\", smoke_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d6969ad",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-12T22:31:15.059490Z",
     "iopub.status.busy": "2025-05-12T22:31:15.059280Z",
     "iopub.status.idle": "2025-05-12T22:31:27.038854Z",
     "shell.execute_reply": "2025-05-12T22:31:27.037908Z"
    },
    "papermill": {
     "duration": 11.985775,
     "end_time": "2025-05-12T22:31:27.040183",
     "exception": false,
     "start_time": "2025-05-12T22:31:15.054408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGGING TIME OF START: 2025-05-13 06:31:15\n",
      "Processing /kaggle/input/biopython/biopython-1.85-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython==1.85) (1.26.4)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->biopython==1.85) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->biopython==1.85) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->biopython==1.85) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->biopython==1.85) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->biopython==1.85) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->biopython==1.85) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->biopython==1.85) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->biopython==1.85) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->biopython==1.85) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->biopython==1.85) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->biopython==1.85) (2024.2.0)\r\n",
      "Installing collected packages: biopython\r\n",
      "Successfully installed biopython-1.85\r\n",
      "Processing /kaggle/input/biopython/biopython-1.85-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython==1.85) (1.26.4)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->biopython==1.85) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->biopython==1.85) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->biopython==1.85) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->biopython==1.85) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->biopython==1.85) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->biopython==1.85) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->biopython==1.85) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->biopython==1.85) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->biopython==1.85) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->biopython==1.85) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->biopython==1.85) (2024.2.0)\r\n",
      "biopython is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\r\n",
      "Requirement already satisfied: biopython in /usr/local/lib/python3.10/dist-packages (1.85)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython) (1.26.4)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->biopython) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->biopython) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->biopython) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->biopython) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->biopython) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->biopython) (2024.2.0)\r\n",
      "PIP INSTALL OK !!!!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pytz\n",
    "print('LOGGING TIME OF START:',  datetime.strftime(datetime.now(pytz.timezone('Asia/Singapore')), \"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "\n",
    "try:\n",
    "    import Bio\n",
    "except:\n",
    "    #for drfold2 --------\n",
    "    #!pip install biopython\n",
    "    !pip install /kaggle/input/biopython/biopython-1.85-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!pip install /kaggle/input/biopython/biopython-1.85-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!pip install biopython\n",
    "print('PIP INSTALL OK !!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e349405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T22:31:27.051124Z",
     "iopub.status.busy": "2025-05-12T22:31:27.050824Z",
     "iopub.status.idle": "2025-05-12T22:31:27.064405Z",
     "shell.execute_reply": "2025-05-12T22:31:27.063634Z"
    },
    "papermill": {
     "duration": 0.020328,
     "end_time": "2025-05-12T22:31:27.065635",
     "exception": false,
     "start_time": "2025-05-12T22:31:27.045307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(valid_df) 12\n",
      "target_id                                                      R1107\n",
      "sequence           GGGGGCCACAGCAGAAGCGUUCACGUCGCAGCCCCUGUCAGCCAUU...\n",
      "temporal_cutoff                                           2022-05-28\n",
      "description        CPEB3 ribozyme\\nHuman\\nhuman CPEB3 HDV-like ri...\n",
      "all_sequences      >7QR4_1|Chain A|U1 small nuclear ribonucleopro...\n",
      "Name: 0, dtype: object\n",
      "\n",
      "MODE: submit\n",
      "SETTING OK!!!\n"
     ]
    }
   ],
   "source": [
    "# MODE = 'local' #'local' # submit\n",
    "MODE = 'submit'\n",
    "\n",
    "DATA_KAGGLE_DIR = '/kaggle/input/stanford-rna-3d-folding'\n",
    "if MODE == 'local':\n",
    "    valid_df = pd.read_csv(f'{DATA_KAGGLE_DIR}/validation_sequences.csv')\n",
    "    label_df = pd.read_csv(f'{DATA_KAGGLE_DIR}/validation_labels.csv')\n",
    "    label_df['target_id'] = label_df['ID'].apply(lambda x: '_'.join(x.split('_')[:-1]))\n",
    "\n",
    "if MODE == 'submit':\n",
    "\tvalid_df = pd.read_csv(f'{DATA_KAGGLE_DIR}/test_sequences.csv')\n",
    "\n",
    "print('len(valid_df)',len(valid_df))\n",
    "print(valid_df.iloc[0])\n",
    "print('')\n",
    "\n",
    "\n",
    "# cfg = dotdict(\n",
    "#     num_conf = 5,\n",
    "#     max_length=480,\n",
    "# )\n",
    "NUM_CONF=5\n",
    "MAX_LENGTH=480\n",
    "DEVICE='cuda' #'cpu'\n",
    "\n",
    "print('MODE:', MODE)\n",
    "print('SETTING OK!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cac28d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T22:31:27.076403Z",
     "iopub.status.busy": "2025-05-12T22:31:27.076168Z",
     "iopub.status.idle": "2025-05-12T22:31:39.824635Z",
     "shell.execute_reply": "2025-05-12T22:31:39.823681Z"
    },
    "papermill": {
     "duration": 12.755788,
     "end_time": "2025-05-12T22:31:39.826416",
     "exception": false,
     "start_time": "2025-05-12T22:31:27.070628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('/kaggle/working/drfold', exist_ok=True)\n",
    "!cp -r /kaggle/input/drfold/DRfold2/DRfold2/* /kaggle/working/drfold/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "734b0dc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T22:31:39.837484Z",
     "iopub.status.busy": "2025-05-12T22:31:39.837215Z",
     "iopub.status.idle": "2025-05-12T22:31:39.840510Z",
     "shell.execute_reply": "2025-05-12T22:31:39.839768Z"
    },
    "papermill": {
     "duration": 0.009935,
     "end_time": "2025-05-12T22:31:39.841694",
     "exception": false,
     "start_time": "2025-05-12T22:31:39.831759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import sys, os\n",
    "# CFG97 = os.path.join('/kaggle/input/drfold/DRfold2/DRfold2', 'cfg_97')\n",
    "# assert os.path.isdir(CFG97), f\"{CFG97} not found!\"\n",
    "# sys.path.insert(0, CFG97)\n",
    "\n",
    "# # now this should succeed:\n",
    "# from EvoMSA2XYZ import MSA2XYZ\n",
    "# from RNALM2.Model import RNA2nd\n",
    "# from data         import parse_seq, Get_base, BASE_COOR\n",
    "# from data         import write_frame_coor_to_pdb, parse_pdb_to_xyz\n",
    "\n",
    "# print(\"imported!\", MSA2XYZ, RNA2nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "febe2fd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T22:31:39.851947Z",
     "iopub.status.busy": "2025-05-12T22:31:39.851726Z",
     "iopub.status.idle": "2025-05-12T22:31:40.196311Z",
     "shell.execute_reply": "2025-05-12T22:31:40.195392Z"
    },
    "papermill": {
     "duration": 0.351555,
     "end_time": "2025-05-12T22:31:40.197956",
     "exception": false,
     "start_time": "2025-05-12T22:31:39.846401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 1) Point at the cfg_97 folder (adjust this to your actual path)\n",
    "CFG97 = '/kaggle/input/drfold/DRfold2/DRfold2/cfg_97'\n",
    "\n",
    "# 2) Load the base.npy file once into a Python variable\n",
    "BASE_COOR = np.load(os.path.join(CFG97, 'base.npy'))\n",
    "\n",
    "# 3) Now import your parsing and model code\n",
    "import sys\n",
    "sys.path.insert(0, CFG97)\n",
    "from data import parse_seq, Get_base\n",
    "# (no BASE_COOR to import from data.py)\n",
    "\n",
    "# 4) When you need the 3×3 base coordinates for a sequence, call:\n",
    "sequence = \"ACGUACGUA\"\n",
    "base_coords = Get_base(sequence, BASE_COOR)\n",
    "# base_coords.shape == (len(sequence), 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93e2a0a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T22:31:40.208853Z",
     "iopub.status.busy": "2025-05-12T22:31:40.208335Z",
     "iopub.status.idle": "2025-05-12T22:31:46.405459Z",
     "shell.execute_reply": "2025-05-12T22:31:46.404682Z"
    },
    "papermill": {
     "duration": 6.204034,
     "end_time": "2025-05-12T22:31:46.407076",
     "exception": false,
     "start_time": "2025-05-12T22:31:40.203042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/kaggle/working/drfold/cfg_97/EvoMSA2XYZ.py:35: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  RNAlm.load_state_dict(torch.load(saved_model,map_location=torch.device('cpu')),strict=False)\n"
     ]
    }
   ],
   "source": [
    "import os, sys, shutil\n",
    "\n",
    "# 1) make sure you have a writable copy\n",
    "shutil.copytree(\n",
    "  '/kaggle/input/drfold/DRfold2/DRfold2',\n",
    "  '/kaggle/working/drfold',\n",
    "  dirs_exist_ok=True\n",
    ")\n",
    "\n",
    "# 2) point Python at the cfg_97 folder under that copy\n",
    "BASE = '/kaggle/working/drfold'\n",
    "sys.path.insert(0, os.path.join(BASE, 'cfg_97'))\n",
    "from EvoMSA2XYZ import MSA2XYZ\n",
    "from RNALM2.Model import RNA2nd\n",
    "from data import parse_seq, Get_base\n",
    "from util import outpdb\n",
    "# parse_pdb_to_xyz write_frame_coor_to_pdb\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def parse_pdb_to_xyz(pdb_file, atom_name=\" P  \"):\n",
    "    coords, resid, resname = [], [], []\n",
    "    with open(pdb_file) as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"ATOM\") and line[12:16].strip() == atom_name.strip():\n",
    "                x = float(line[30:38]); y = float(line[38:46]); z = float(line[46:54])\n",
    "                coords.append((x,y,z))\n",
    "                resid.append(int(line[22:26]))\n",
    "                resname.append(line[17:20].strip())\n",
    "    return np.array(coords, dtype=np.float32), resname, resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8896230c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T22:31:46.418541Z",
     "iopub.status.busy": "2025-05-12T22:31:46.418149Z",
     "iopub.status.idle": "2025-05-12T22:31:46.511041Z",
     "shell.execute_reply": "2025-05-12T22:31:46.510153Z"
    },
    "papermill": {
     "duration": 0.099953,
     "end_time": "2025-05-12T22:31:46.512507",
     "exception": false,
     "start_time": "2025-05-12T22:31:46.412554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "###########################################################3\n",
    "KAGGLE_TRUTH_PDB_DIR ='/kaggle/working/drfold/kaggle-casp15-truth'\n",
    "USALIGN = '/kaggle/working/USalign' \n",
    "os.system('cp /kaggle/input/usalign/USalign /kaggle/working/')\n",
    "os.system('sudo chmod u+x /kaggle/working/USalign')\n",
    "\n",
    "# evaluate helper\n",
    "def get_truth_df(target_id, label_df):\n",
    "    truth_df = label_df[label_df['target_id'] == target_id]\n",
    "    truth_df = truth_df.reset_index(drop=True)\n",
    "    return truth_df\n",
    "\n",
    "def parse_usalign_for_tm_score(output):\n",
    "    # Extract TM-score based on length of reference structure (second)\n",
    "    tm_score_match = re.findall(r'TM-score=\\s+([\\d.]+)', output)[1]\n",
    "    if not tm_score_match:\n",
    "        raise ValueError('No TM score found')\n",
    "    return float(tm_score_match)\n",
    "\n",
    "def parse_usalign_for_transform(output):\n",
    "    # Locate the rotation matrix section\n",
    "    matrix_lines = []\n",
    "    found_matrix = False\n",
    "\n",
    "    for line in output.splitlines():\n",
    "        if \"The rotation matrix to rotate Structure_1 to Structure_2\" in line:\n",
    "            found_matrix = True\n",
    "        elif found_matrix and re.match(r'^\\d+\\s+[-\\d.]+\\s+[-\\d.]+\\s+[-\\d.]+\\s+[-\\d.]+$', line):\n",
    "            matrix_lines.append(line)\n",
    "        elif found_matrix and not line.strip():\n",
    "            break  # Stop parsing if an empty line is encountered after the matrix\n",
    "\n",
    "    # Parse the rotation matrix values\n",
    "    rotation_matrix = []\n",
    "    for line in matrix_lines:\n",
    "        parts = line.split()\n",
    "        row_values = list(map(float, parts[1:]))  # Skip the first column (index)\n",
    "        rotation_matrix.append(row_values)\n",
    "    return np.array(rotation_matrix)\n",
    "\n",
    "\n",
    "\n",
    "# data helper\n",
    "def make_data(seq):\n",
    "    aa_type = parse_seq(seq)\n",
    "    base = Get_base(seq, BASE_COOR)\n",
    "    seq_idx = np.arange(len(seq)) + 1\n",
    "\n",
    "    msa = aa_type[None, :]\n",
    "    msa = torch.from_numpy(msa)\n",
    "    msa = torch.cat([msa, msa], 0) #???\n",
    "    msa = F.one_hot(msa.long(), 6).float()\n",
    "\n",
    "    base_x  = torch.from_numpy(base).float()\n",
    "    seq_idx = torch.from_numpy(seq_idx).long()\n",
    "    return msa, base_x, seq_idx\n",
    "    \n",
    "def make_dummy_solution():\n",
    "    solution=dotdict()\n",
    "    for i, row in valid_df.iterrows():\n",
    "        target_id = row.target_id\n",
    "        sequence = row.sequence\n",
    "        solution[target_id]=dotdict(\n",
    "            target_id=target_id,\n",
    "            sequence=sequence,\n",
    "            coord=[],\n",
    "        )\n",
    "    return solution\n",
    "\n",
    "def solution_to_submit_df(solution):\n",
    "    submit_df = []\n",
    "    for k,s in solution.items():\n",
    "        df = coord_to_df(s.sequence, s.coord, s.target_id)\n",
    "        submit_df.append(df)\n",
    "    \n",
    "    submit_df = pd.concat(submit_df)\n",
    "    return submit_df\n",
    " \n",
    "\n",
    "def coord_to_df(sequence, coord, target_id):\n",
    "    L = len(sequence)\n",
    "    df = pd.DataFrame()\n",
    "    df['ID'] = [f'{target_id}_{i + 1}' for i in range(L)]\n",
    "    df['resname'] = [s for s in sequence]\n",
    "    df['resid'] = [i + 1 for i in range(L)]\n",
    "\n",
    "    num_coord = len(coord)\n",
    "    for j in range(num_coord):\n",
    "        df[f'x_{j+1}'] = coord[j][:, 0]\n",
    "        df[f'y_{j+1}'] = coord[j][:, 1]\n",
    "        df[f'z_{j+1}'] = coord[j][:, 2]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4da2d391",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T22:31:46.523731Z",
     "iopub.status.busy": "2025-05-12T22:31:46.523487Z",
     "iopub.status.idle": "2025-05-12T22:31:47.505545Z",
     "shell.execute_reply": "2025-05-12T22:31:47.504589Z"
    },
    "papermill": {
     "duration": 0.989194,
     "end_time": "2025-05-12T22:31:47.507051",
     "exception": false,
     "start_time": "2025-05-12T22:31:46.517857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "/kaggle/working/drfold/model_hub/RCLM/epoch_67000\n",
      "_IncompatibleKeys(missing_keys=[], unexpected_keys=['ss_head.linear.weight', 'ss_head.linear.bias'])\n"
     ]
    }
   ],
   "source": [
    "################### start here !!! #######################################################3\n",
    "out_dir = '/kaggle/working/model-output'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "solution = make_dummy_solution()\n",
    "\n",
    "\n",
    "#load model (these are moified versions, not the same from their github repo)\n",
    "rnalm = RNA2nd(dict(\n",
    "    s_in_dim=5,\n",
    "    z_in_dim=2,\n",
    "    s_dim= 512,\n",
    "    z_dim= 128,\n",
    "    N_elayers=18,\n",
    "))\n",
    "rnalm_file = '/kaggle/working/drfold/model_hub/RCLM/epoch_67000'\n",
    "print(rnalm_file)\n",
    "print(\n",
    "    rnalm.load_state_dict(torch.load(rnalm_file, map_location='cpu', weights_only=True), strict=False)\n",
    "    #Unexpected key(s) in state_dict: \"ss_head.linear.weight\", \"ss_head.linear.bias\".\n",
    ")\n",
    "rnalm = rnalm.to(DEVICE)\n",
    "rnalm = rnalm.eval()\n",
    "total_time_taken = 0\n",
    "max_gpu_mem_used = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4207422",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T22:31:47.518645Z",
     "iopub.status.busy": "2025-05-12T22:31:47.518388Z",
     "iopub.status.idle": "2025-05-12T22:31:47.522913Z",
     "shell.execute_reply": "2025-05-12T22:31:47.522277Z"
    },
    "papermill": {
     "duration": 0.011536,
     "end_time": "2025-05-12T22:31:47.524111",
     "exception": false,
     "start_time": "2025-05-12T22:31:47.512575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_frame_coor_to_pdb(coord, seq, savefile):\n",
    "    \"\"\"\n",
    "    coord: np.ndarray of shape (L,3,3) from your model (P, sugar, N)\n",
    "    seq:   string of length L\n",
    "    savefile: path to write PDB with only C1' atom per residue\n",
    "    \"\"\"\n",
    "    L = coord.shape[0]\n",
    "    with open(savefile, 'w') as f:\n",
    "        count = 1\n",
    "        for i, res in enumerate(seq):\n",
    "            x, y, z = coord[i, 1]   # channel=1 → sugar atom\n",
    "            # PDB ATOM line building:\n",
    "            # atom serial, atom name, residue name, chain A, residue seq, x,y,z, occup,temp, element\n",
    "            f.write(\n",
    "                f\"ATOM  {count:5d}  C1' {res:>3s} A{ i+1:4d}\"\n",
    "                f\"{x:8.3f}{y:8.3f}{z:8.3f}  1.00  0.00           C\\n\"\n",
    "            )\n",
    "            count += 1\n",
    "        f.write(\"TER\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "709cbd46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T22:31:47.535660Z",
     "iopub.status.busy": "2025-05-12T22:31:47.535441Z",
     "iopub.status.idle": "2025-05-13T00:17:09.619291Z",
     "shell.execute_reply": "2025-05-13T00:17:09.618527Z"
    },
    "papermill": {
     "duration": 6322.100389,
     "end_time": "2025-05-13T00:17:09.629553",
     "exception": false,
     "start_time": "2025-05-12T22:31:47.529164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "/kaggle/working/drfold/model_hub/cfg_97/model_0\n",
      "<All keys matched successfully>\n",
      "0 0 R1107 69 GGGGGCCACAGCAGAAGCGUUCACGUCGCAGCCCCUGUCAGCCAUUGCACUCCGGCUGCGAAUUCUGCU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: (69, 3, 3)\n",
      "time_taken:  0 min 12 sec\n",
      "gpu_mem_used: 2 GB\n",
      "0 1 R1108 69 GGGGGCCACAGCAGAAGCGUUCACGUCGCGGCCCCUGUCAGCCAUUGCACUCCGGCUGCGAAUUCUGCU...\n",
      "out: (69, 3, 3)\n",
      "time_taken:  0 min 10 sec\n",
      "gpu_mem_used: 2 GB\n",
      "0 2 R1116 157 CGCCCGGAUAGCUCAGUCGGUAGAGCAGCGGCUAAAACAGCUCUGGGGUUGUACCCACCCCAGAGGCCCACGUGG...\n",
      "out: (157, 3, 3)\n",
      "time_taken:  0 min 31 sec\n",
      "gpu_mem_used: 3 GB\n",
      "0 3 R1117v2 30 UUGGGUUCCCUCACCCCAAUCAUAAAAAGG...\n",
      "out: (30, 3, 3)\n",
      "time_taken:  0 min 10 sec\n",
      "gpu_mem_used: 2 GB\n",
      "0 4 R1126 363 GGAAUCUCGCCCGAUGUUCGCAUCGGGAUUUGCAGGUCCAUGGAUUACACCAUGCAACGCAGACCUGUAGAUGCC...\n",
      "out: (363, 3, 3)\n",
      "time_taken:  4 min 10 sec\n",
      "gpu_mem_used: 8 GB\n",
      "0 5 R1128 238 GGAAUAUCGUCAUGGUGAUUCGUCACCAUGAGGCUAGAUCUCAUAUCUAGCGCUUUCGAGCGCUAGAGUCCUUAU...\n",
      "out: (238, 3, 3)\n",
      "time_taken:  1 min 20 sec\n",
      "gpu_mem_used: 4 GB\n",
      "0 6 R1136 374 GGAUACGUCUACGCUCAGUGACGGACUCUCUUCGGAGAGUCUGACAUCCGAACCAUACACGGAUGUGCCUCGCCG...\n",
      "out: (374, 3, 3)\n",
      "time_taken:  4 min 24 sec\n",
      "gpu_mem_used: 8 GB\n",
      "0 7 R1138 720 GCGGGCGUAUAGGUUCGUCUAUACGUCCGCGUUUUCCGAGAAGAGGUAACUCGGGAAACCGGUCCACGUGACAAA...\n",
      "out: (720, 3, 3)\n",
      "time_taken:  8 min 53 sec\n",
      "gpu_mem_used: 14 GB\n",
      "0 8 R1149 124 GGACACGAGUAACUCGUCUAUCUUCUGCAGGCUGCUUACGGUUUCGUCCGUGUUGCAGCCGAUCAUCAGCACAUC...\n",
      "out: (124, 3, 3)\n",
      "time_taken:  0 min 17 sec\n",
      "gpu_mem_used: 2 GB\n",
      "0 9 R1156 135 GGAGCAUCGUGUCUCAAGUGCUUCACGGUCACAAUAUACCGUUUCGUCGGGUGCGUGGCAAUUCGGUGCACAUCA...\n",
      "out: (135, 3, 3)\n",
      "time_taken:  0 min 22 sec\n",
      "gpu_mem_used: 2 GB\n",
      "0 10 R1189 118 GCGUACAGGGAACACGCAACCCCGAAGGAUCGGGGAAGGGACGUCGCCAGGGAGGCGAUUCCAUCAGGAUGAUGA...\n",
      "out: (118, 3, 3)\n",
      "time_taken:  0 min 15 sec\n",
      "gpu_mem_used: 2 GB\n",
      "0 11 R1190 118 GCGUACAGGGAACACGCAACCCCGAAGGAUCGGGGAAGGGACGUCGCCAGGGAGGCGAUUCCAUCAGGAUGAUGA...\n",
      "out: (118, 3, 3)\n",
      "time_taken:  0 min 15 sec\n",
      "gpu_mem_used: 2 GB\n",
      "\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "/kaggle/working/drfold/model_hub/cfg_97/model_1\n",
      "<All keys matched successfully>\n",
      "1 0 R1107 69 GGGGGCCACAGCAGAAGCGUUCACGUCGCAGCCCCUGUCAGCCAUUGCACUCCGGCUGCGAAUUCUGCU...\n",
      "out: (69, 3, 3)\n",
      "time_taken:  0 min 10 sec\n",
      "gpu_mem_used: 2 GB\n",
      "1 1 R1108 69 GGGGGCCACAGCAGAAGCGUUCACGUCGCGGCCCCUGUCAGCCAUUGCACUCCGGCUGCGAAUUCUGCU...\n",
      "out: (69, 3, 3)\n",
      "time_taken:  0 min 10 sec\n",
      "gpu_mem_used: 2 GB\n",
      "1 2 R1116 157 CGCCCGGAUAGCUCAGUCGGUAGAGCAGCGGCUAAAACAGCUCUGGGGUUGUACCCACCCCAGAGGCCCACGUGG...\n",
      "out: (157, 3, 3)\n",
      "time_taken:  0 min 30 sec\n",
      "gpu_mem_used: 3 GB\n",
      "1 3 R1117v2 30 UUGGGUUCCCUCACCCCAAUCAUAAAAAGG...\n",
      "out: (30, 3, 3)\n",
      "time_taken:  0 min 09 sec\n",
      "gpu_mem_used: 2 GB\n",
      "1 4 R1126 363 GGAAUCUCGCCCGAUGUUCGCAUCGGGAUUUGCAGGUCCAUGGAUUACACCAUGCAACGCAGACCUGUAGAUGCC...\n",
      "out: (363, 3, 3)\n",
      "time_taken:  4 min 08 sec\n",
      "gpu_mem_used: 8 GB\n",
      "1 5 R1128 238 GGAAUAUCGUCAUGGUGAUUCGUCACCAUGAGGCUAGAUCUCAUAUCUAGCGCUUUCGAGCGCUAGAGUCCUUAU...\n",
      "out: (238, 3, 3)\n",
      "time_taken:  1 min 20 sec\n",
      "gpu_mem_used: 4 GB\n",
      "1 6 R1136 374 GGAUACGUCUACGCUCAGUGACGGACUCUCUUCGGAGAGUCUGACAUCCGAACCAUACACGGAUGUGCCUCGCCG...\n",
      "out: (374, 3, 3)\n",
      "time_taken:  4 min 24 sec\n",
      "gpu_mem_used: 8 GB\n",
      "1 7 R1138 720 UCCUCCGACUAAGUGUAUUCGUAUACUUAGUGCCUUGUGCCUGCUUCGGCAGGCAUGACCCAAAUGUGCCUUUCG...\n",
      "out: (720, 3, 3)\n",
      "time_taken:  8 min 53 sec\n",
      "gpu_mem_used: 14 GB\n",
      "1 8 R1149 124 GGACACGAGUAACUCGUCUAUCUUCUGCAGGCUGCUUACGGUUUCGUCCGUGUUGCAGCCGAUCAUCAGCACAUC...\n",
      "out: (124, 3, 3)\n",
      "time_taken:  0 min 17 sec\n",
      "gpu_mem_used: 2 GB\n",
      "1 9 R1156 135 GGAGCAUCGUGUCUCAAGUGCUUCACGGUCACAAUAUACCGUUUCGUCGGGUGCGUGGCAAUUCGGUGCACAUCA...\n",
      "out: (135, 3, 3)\n",
      "time_taken:  0 min 22 sec\n",
      "gpu_mem_used: 2 GB\n",
      "1 10 R1189 118 GCGUACAGGGAACACGCAACCCCGAAGGAUCGGGGAAGGGACGUCGCCAGGGAGGCGAUUCCAUCAGGAUGAUGA...\n",
      "out: (118, 3, 3)\n",
      "time_taken:  0 min 15 sec\n",
      "gpu_mem_used: 2 GB\n",
      "1 11 R1190 118 GCGUACAGGGAACACGCAACCCCGAAGGAUCGGGGAAGGGACGUCGCCAGGGAGGCGAUUCCAUCAGGAUGAUGA...\n",
      "out: (118, 3, 3)\n",
      "time_taken:  0 min 15 sec\n",
      "gpu_mem_used: 2 GB\n",
      "\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "/kaggle/working/drfold/model_hub/cfg_97/model_2\n",
      "<All keys matched successfully>\n",
      "2 0 R1107 69 GGGGGCCACAGCAGAAGCGUUCACGUCGCAGCCCCUGUCAGCCAUUGCACUCCGGCUGCGAAUUCUGCU...\n",
      "out: (69, 3, 3)\n",
      "time_taken:  0 min 10 sec\n",
      "gpu_mem_used: 2 GB\n",
      "2 1 R1108 69 GGGGGCCACAGCAGAAGCGUUCACGUCGCGGCCCCUGUCAGCCAUUGCACUCCGGCUGCGAAUUCUGCU...\n",
      "out: (69, 3, 3)\n",
      "time_taken:  0 min 09 sec\n",
      "gpu_mem_used: 2 GB\n",
      "2 2 R1116 157 CGCCCGGAUAGCUCAGUCGGUAGAGCAGCGGCUAAAACAGCUCUGGGGUUGUACCCACCCCAGAGGCCCACGUGG...\n",
      "out: (157, 3, 3)\n",
      "time_taken:  0 min 31 sec\n",
      "gpu_mem_used: 3 GB\n",
      "2 3 R1117v2 30 UUGGGUUCCCUCACCCCAAUCAUAAAAAGG...\n",
      "out: (30, 3, 3)\n",
      "time_taken:  0 min 09 sec\n",
      "gpu_mem_used: 2 GB\n",
      "2 4 R1126 363 GGAAUCUCGCCCGAUGUUCGCAUCGGGAUUUGCAGGUCCAUGGAUUACACCAUGCAACGCAGACCUGUAGAUGCC...\n",
      "out: (363, 3, 3)\n",
      "time_taken:  4 min 10 sec\n",
      "gpu_mem_used: 8 GB\n",
      "2 5 R1128 238 GGAAUAUCGUCAUGGUGAUUCGUCACCAUGAGGCUAGAUCUCAUAUCUAGCGCUUUCGAGCGCUAGAGUCCUUAU...\n",
      "out: (238, 3, 3)\n",
      "time_taken:  1 min 20 sec\n",
      "gpu_mem_used: 4 GB\n",
      "2 6 R1136 374 GGAUACGUCUACGCUCAGUGACGGACUCUCUUCGGAGAGUCUGACAUCCGAACCAUACACGGAUGUGCCUCGCCG...\n",
      "out: (374, 3, 3)\n",
      "time_taken:  4 min 26 sec\n",
      "gpu_mem_used: 8 GB\n",
      "2 7 R1138 720 UAUACGUCCGCGUUUUCCGAGAAGAGGUAACUCGGGAAACCGGUCCACGUGACAAAGGUAGAGUUACGUGGAGGG...\n",
      "out: (720, 3, 3)\n",
      "time_taken:  8 min 55 sec\n",
      "gpu_mem_used: 14 GB\n",
      "2 8 R1149 124 GGACACGAGUAACUCGUCUAUCUUCUGCAGGCUGCUUACGGUUUCGUCCGUGUUGCAGCCGAUCAUCAGCACAUC...\n",
      "out: (124, 3, 3)\n",
      "time_taken:  0 min 17 sec\n",
      "gpu_mem_used: 2 GB\n",
      "2 9 R1156 135 GGAGCAUCGUGUCUCAAGUGCUUCACGGUCACAAUAUACCGUUUCGUCGGGUGCGUGGCAAUUCGGUGCACAUCA...\n",
      "out: (135, 3, 3)\n",
      "time_taken:  0 min 22 sec\n",
      "gpu_mem_used: 2 GB\n",
      "2 10 R1189 118 GCGUACAGGGAACACGCAACCCCGAAGGAUCGGGGAAGGGACGUCGCCAGGGAGGCGAUUCCAUCAGGAUGAUGA...\n",
      "out: (118, 3, 3)\n",
      "time_taken:  0 min 15 sec\n",
      "gpu_mem_used: 2 GB\n",
      "2 11 R1190 118 GCGUACAGGGAACACGCAACCCCGAAGGAUCGGGGAAGGGACGUCGCCAGGGAGGCGAUUCCAUCAGGAUGAUGA...\n",
      "out: (118, 3, 3)\n",
      "time_taken:  0 min 15 sec\n",
      "gpu_mem_used: 2 GB\n",
      "\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "/kaggle/working/drfold/model_hub/cfg_97/model_8\n",
      "<All keys matched successfully>\n",
      "3 0 R1107 69 GGGGGCCACAGCAGAAGCGUUCACGUCGCAGCCCCUGUCAGCCAUUGCACUCCGGCUGCGAAUUCUGCU...\n",
      "out: (69, 3, 3)\n",
      "time_taken:  0 min 10 sec\n",
      "gpu_mem_used: 2 GB\n",
      "3 1 R1108 69 GGGGGCCACAGCAGAAGCGUUCACGUCGCGGCCCCUGUCAGCCAUUGCACUCCGGCUGCGAAUUCUGCU...\n",
      "out: (69, 3, 3)\n",
      "time_taken:  0 min 09 sec\n",
      "gpu_mem_used: 2 GB\n",
      "3 2 R1116 157 CGCCCGGAUAGCUCAGUCGGUAGAGCAGCGGCUAAAACAGCUCUGGGGUUGUACCCACCCCAGAGGCCCACGUGG...\n",
      "out: (157, 3, 3)\n",
      "time_taken:  0 min 31 sec\n",
      "gpu_mem_used: 3 GB\n",
      "3 3 R1117v2 30 UUGGGUUCCCUCACCCCAAUCAUAAAAAGG...\n",
      "out: (30, 3, 3)\n",
      "time_taken:  0 min 09 sec\n",
      "gpu_mem_used: 2 GB\n",
      "3 4 R1126 363 GGAAUCUCGCCCGAUGUUCGCAUCGGGAUUUGCAGGUCCAUGGAUUACACCAUGCAACGCAGACCUGUAGAUGCC...\n",
      "out: (363, 3, 3)\n",
      "time_taken:  4 min 09 sec\n",
      "gpu_mem_used: 8 GB\n",
      "3 5 R1128 238 GGAAUAUCGUCAUGGUGAUUCGUCACCAUGAGGCUAGAUCUCAUAUCUAGCGCUUUCGAGCGCUAGAGUCCUUAU...\n",
      "out: (238, 3, 3)\n",
      "time_taken:  1 min 20 sec\n",
      "gpu_mem_used: 4 GB\n",
      "3 6 R1136 374 GGAUACGUCUACGCUCAGUGACGGACUCUCUUCGGAGAGUCUGACAUCCGAACCAUACACGGAUGUGCCUCGCCG...\n",
      "out: (374, 3, 3)\n",
      "time_taken:  4 min 24 sec\n",
      "gpu_mem_used: 8 GB\n",
      "3 7 R1138 720 UCCGGUCAUCCAAGUUCGCUUGGGUGAUGCGGGCGUAUAGGUUCGUCUAUACGUCCGCGUUUUCCGAGAAGAGGU...\n",
      "out: (720, 3, 3)\n",
      "time_taken:  8 min 52 sec\n",
      "gpu_mem_used: 14 GB\n",
      "3 8 R1149 124 GGACACGAGUAACUCGUCUAUCUUCUGCAGGCUGCUUACGGUUUCGUCCGUGUUGCAGCCGAUCAUCAGCACAUC...\n",
      "out: (124, 3, 3)\n",
      "time_taken:  0 min 17 sec\n",
      "gpu_mem_used: 2 GB\n",
      "3 9 R1156 135 GGAGCAUCGUGUCUCAAGUGCUUCACGGUCACAAUAUACCGUUUCGUCGGGUGCGUGGCAAUUCGGUGCACAUCA...\n",
      "out: (135, 3, 3)\n",
      "time_taken:  0 min 22 sec\n",
      "gpu_mem_used: 2 GB\n",
      "3 10 R1189 118 GCGUACAGGGAACACGCAACCCCGAAGGAUCGGGGAAGGGACGUCGCCAGGGAGGCGAUUCCAUCAGGAUGAUGA...\n",
      "out: (118, 3, 3)\n",
      "time_taken:  0 min 15 sec\n",
      "gpu_mem_used: 2 GB\n",
      "3 11 R1190 118 GCGUACAGGGAACACGCAACCCCGAAGGAUCGGGGAAGGGACGUCGCCAGGGAGGCGAUUCCAUCAGGAUGAUGA...\n",
      "out: (118, 3, 3)\n",
      "time_taken:  0 min 15 sec\n",
      "gpu_mem_used: 2 GB\n",
      "\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "will do checkpoint\n",
      "/kaggle/working/drfold/model_hub/cfg_97/model_9\n",
      "<All keys matched successfully>\n",
      "4 0 R1107 69 GGGGGCCACAGCAGAAGCGUUCACGUCGCAGCCCCUGUCAGCCAUUGCACUCCGGCUGCGAAUUCUGCU...\n",
      "out: (69, 3, 3)\n",
      "time_taken:  0 min 10 sec\n",
      "gpu_mem_used: 2 GB\n",
      "4 1 R1108 69 GGGGGCCACAGCAGAAGCGUUCACGUCGCGGCCCCUGUCAGCCAUUGCACUCCGGCUGCGAAUUCUGCU...\n",
      "out: (69, 3, 3)\n",
      "time_taken:  0 min 09 sec\n",
      "gpu_mem_used: 2 GB\n",
      "4 2 R1116 157 CGCCCGGAUAGCUCAGUCGGUAGAGCAGCGGCUAAAACAGCUCUGGGGUUGUACCCACCCCAGAGGCCCACGUGG...\n",
      "out: (157, 3, 3)\n",
      "time_taken:  0 min 30 sec\n",
      "gpu_mem_used: 3 GB\n",
      "4 3 R1117v2 30 UUGGGUUCCCUCACCCCAAUCAUAAAAAGG...\n",
      "out: (30, 3, 3)\n",
      "time_taken:  0 min 09 sec\n",
      "gpu_mem_used: 2 GB\n",
      "4 4 R1126 363 GGAAUCUCGCCCGAUGUUCGCAUCGGGAUUUGCAGGUCCAUGGAUUACACCAUGCAACGCAGACCUGUAGAUGCC...\n",
      "out: (363, 3, 3)\n",
      "time_taken:  4 min 10 sec\n",
      "gpu_mem_used: 8 GB\n",
      "4 5 R1128 238 GGAAUAUCGUCAUGGUGAUUCGUCACCAUGAGGCUAGAUCUCAUAUCUAGCGCUUUCGAGCGCUAGAGUCCUUAU...\n",
      "out: (238, 3, 3)\n",
      "time_taken:  1 min 20 sec\n",
      "gpu_mem_used: 4 GB\n",
      "4 6 R1136 374 GGAUACGUCUACGCUCAGUGACGGACUCUCUUCGGAGAGUCUGACAUCCGAACCAUACACGGAUGUGCCUCGCCG...\n",
      "out: (374, 3, 3)\n",
      "time_taken:  4 min 24 sec\n",
      "gpu_mem_used: 8 GB\n",
      "4 7 R1138 720 UGCAUCUAGGGUACGUUUUCGAACGUAUCCUCCGACUAAGUGUAUUCGUAUACUUAGUGCCUUGUGCCUGCUUCG...\n",
      "out: (720, 3, 3)\n",
      "time_taken:  8 min 53 sec\n",
      "gpu_mem_used: 14 GB\n",
      "4 8 R1149 124 GGACACGAGUAACUCGUCUAUCUUCUGCAGGCUGCUUACGGUUUCGUCCGUGUUGCAGCCGAUCAUCAGCACAUC...\n",
      "out: (124, 3, 3)\n",
      "time_taken:  0 min 17 sec\n",
      "gpu_mem_used: 2 GB\n",
      "4 9 R1156 135 GGAGCAUCGUGUCUCAAGUGCUUCACGGUCACAAUAUACCGUUUCGUCGGGUGCGUGGCAAUUCGGUGCACAUCA...\n",
      "out: (135, 3, 3)\n",
      "time_taken:  0 min 22 sec\n",
      "gpu_mem_used: 2 GB\n",
      "4 10 R1189 118 GCGUACAGGGAACACGCAACCCCGAAGGAUCGGGGAAGGGACGUCGCCAGGGAGGCGAUUCCAUCAGGAUGAUGA...\n",
      "out: (118, 3, 3)\n",
      "time_taken:  0 min 15 sec\n",
      "gpu_mem_used: 2 GB\n",
      "4 11 R1190 118 GCGUACAGGGAACACGCAACCCCGAAGGAUCGGGGAAGGGACGUCGCCAGGGAGGCGAUUCCAUCAGGAUGAUGA...\n",
      "out: (118, 3, 3)\n",
      "time_taken:  0 min 15 sec\n",
      "gpu_mem_used: 2 GB\n",
      "\n",
      "MAX_LENGTH 480\n",
      "### total_time_taken:  1 hr 45 min\n",
      "### max_gpu_mem_used: 14 GB\n",
      "\n",
      "            ID resname  resid        x_1        y_1        z_1        x_2        y_2        z_2        x_3        y_3        z_3        x_4        y_4        z_4        x_5        y_5       z_5\n",
      "0      R1107_1       G      1   2.905267   9.048628  -3.282411  -7.015918   8.532943   4.970207  -0.031350   8.395054  -9.734588   1.462059  -1.383294   4.998859  -2.708893   2.232720 -1.934017\n",
      "1      R1107_2       G      2   6.057236  12.926416  -0.379654  -8.077373   9.264426  10.573361   2.114906  12.400799  -9.890106  -0.719784  -2.968459   0.928596  -6.980391   0.893952 -4.024602\n",
      "2      R1107_3       G      3   9.028996  14.280936   4.500532 -10.581871   7.324004  15.353767   2.510819  18.012100  -8.438994  -5.177915  -3.207253  -2.163895 -12.186717   0.791450 -4.414519\n",
      "3      R1107_4       G      4  11.440684  12.405815   9.389330 -12.854498   2.791572  18.680662   0.575659  22.589180  -5.405528 -10.183083  -1.089534  -3.836257 -17.234041   2.204441 -2.606580\n",
      "4      R1107_5       G      5  13.022847   8.801436  13.396454 -13.723700  -3.033416  19.300079  -3.260521  24.759499  -1.301328 -14.501650   2.489855  -3.892360 -20.979321   5.056321  0.697954\n",
      "..         ...     ...    ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...       ...\n",
      "113  R1190_114       U    114  37.431461  29.191401 -23.236778  25.699198  13.256453   1.729606 -19.714554  23.329748 -25.334530 -14.302045   5.630352 -38.118252  13.410790  18.505308 -0.301396\n",
      "114  R1190_115       U    115  39.509476  30.352846 -27.411892  25.358614  12.014378  -3.406775 -20.675510  22.789078 -31.465862 -10.201819   8.242227 -41.550781  13.997248  24.096087  1.629771\n",
      "115  R1190_116       U    116  39.291718  28.581354 -31.448900  23.059139  10.930712  -8.056493 -24.455994  22.114527 -35.920990  -6.644732  12.584609 -43.184269  11.690513  29.257166  3.376415\n",
      "116  R1190_117       U    117  37.334759  26.751799 -34.572781  18.574976  10.367143 -10.891772 -30.128588  22.477226 -37.759769  -3.424911  17.473389 -41.998726   6.794422  31.804995  5.750101\n",
      "117  R1190_118       U    118  33.142796  25.009861 -37.321827  13.075107  11.367743 -11.401947 -35.670151  24.485725 -36.954601  -1.414341  21.280870 -38.099602   1.437041  31.150944  7.912365\n",
      "\n",
      "[2515 rows x 18 columns]\n",
      "SUBMIT OK!!!!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = dict(\n",
    "    seq_dim=6,\n",
    "    msa_dim=7,\n",
    "    N_ensemble=10,   # how many ensemble members\n",
    "    N_cycle=8,      # how many recycling cycles\n",
    "    m_dim=64,\n",
    "    s_dim=64,\n",
    "    z_dim=64,\n",
    ")\n",
    "for c in range(NUM_CONF): \n",
    "    msa2xyz = MSA2XYZ(**cfg)\n",
    "    msa2xyz_file = [\n",
    "        f'/kaggle/working/drfold/model_hub/cfg_97/model_{k}' for k in [0,1,2,8,9]\n",
    "    ][c]\n",
    "    print(msa2xyz_file)\n",
    "    print(\n",
    "        msa2xyz.load_state_dict(torch.load(msa2xyz_file, map_location='cpu', weights_only=True), strict=True)\n",
    "    )\n",
    "    msa2xyz.msaxyzone.premsa.rnalm = rnalm\n",
    "    msa2xyz = msa2xyz.to(DEVICE)\n",
    "    msa2xyz = msa2xyz.eval()\n",
    " \n",
    "    for i,row in valid_df.iterrows():\n",
    "        start_timer = timer()\n",
    "        \n",
    "        target_id = row.target_id\n",
    "        sequence = row.sequence\n",
    "        seq = row.sequence    \n",
    "        \n",
    "        L = len(sequence)\n",
    "        if L>MAX_LENGTH:\n",
    "            i0 = np.random.choice(L-MAX_LENGTH+1)\n",
    "            i1 = i0 + MAX_LENGTH\n",
    "        else:\n",
    "            i0 = 0\n",
    "            i1 = L\n",
    "        \n",
    "        seq = sequence[i0:i1]\n",
    "        print(c,i,target_id, L, seq[:75]+'...')\n",
    "        \n",
    "        msa, base_x, seq_idx = make_data(seq)\n",
    "        msa, base_x, seq_idx = msa.to(DEVICE), base_x.to(DEVICE), seq_idx.to(DEVICE)\n",
    "        secondary = None #secondary structure\n",
    "    \n",
    "        with torch.no_grad(): \n",
    "            out = msa2xyz.pred(msa, seq_idx, secondary, base_x, np.array(list(seq)))\n",
    "\n",
    "        # key = list(out.keys()) # plddt(L,L), coor(L,3,3), dist_p(L,L,38), dist_c, dist_n,\n",
    "        # for k in key:\n",
    "        #     print(k, type(out[k]), out[k].shape)\n",
    " \n",
    "        \n",
    "        if L!=len(seq):\n",
    "             out['coor'] = np.pad(out['coor'] ,((i0, L - i1), (0, 0), (0, 0)), 'constant', constant_values=0)\n",
    "\n",
    "\n",
    "        print('out:',  out['coor'].shape)\n",
    "        time_taken = timer()-start_timer\n",
    "        total_time_taken += time_taken\n",
    "        print('time_taken:', time_to_str(time_taken, mode='sec')) \n",
    "        \n",
    "        gpu_mem_used = gpu_memory_use()\n",
    "        max_gpu_mem_used = max(max_gpu_mem_used,gpu_mem_used)\n",
    "        print('gpu_mem_used:', gpu_mem_used, 'GB')\n",
    "\n",
    "        torch.cuda.empty_cache() \n",
    "        sugar_xyz = out['coor'][:, 1, :]   # shape (L,3)\n",
    "        solution[target_id].coord.append(sugar_xyz)\n",
    "    print('')\n",
    "    \n",
    "#-----end of conformation generation ----\n",
    "print('MAX_LENGTH', MAX_LENGTH)\n",
    "print('### total_time_taken:', time_to_str(total_time_taken, mode='min'))\n",
    "print('### max_gpu_mem_used:', max_gpu_mem_used, 'GB')\n",
    "print('')\n",
    "\n",
    "submit_df = solution_to_submit_df(solution)\n",
    "submit_df.to_csv(f'submission.csv', index=False)\n",
    "print(submit_df)\n",
    "print('SUBMIT OK!!!!!!')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd5677c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T00:17:09.648344Z",
     "iopub.status.busy": "2025-05-13T00:17:09.648071Z",
     "iopub.status.idle": "2025-05-13T00:17:09.651665Z",
     "shell.execute_reply": "2025-05-13T00:17:09.651028Z"
    },
    "papermill": {
     "duration": 0.014279,
     "end_time": "2025-05-13T00:17:09.652730",
     "exception": false,
     "start_time": "2025-05-13T00:17:09.638451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_dataset = SequenceStructureDataset(\n",
    "#     csv_file=f\"{DATA_KAGGLE_DIR}/train_labels.csv\",\n",
    "#     data_dir=f\"{DATA_KAGGLE_DIR}/train_data\"\n",
    "# )\n",
    "# val_dataset = SequenceStructureDataset(\n",
    "#     csv_file=f\"{DATA_KAGGLE_DIR}/validation_labels.csv\",\n",
    "#     data_dir=f\"{DATA_KAGGLE_DIR}/validation_data\"\n",
    "# )\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
    "\n",
    "# # from cfg_97.RNALM2.Model import RNA2nd as DRfold2Model  # adjust import as needed\n",
    "\n",
    "# # model = DRfold2Model(rnacfg)\n",
    "# # # Load pre-trained weights\n",
    "# # msa2xyz_file = [f'/kaggle/working/drfold/model_hub/cfg_97/model_0' for k in [0,1,2,8,9]][0]\n",
    "# model = rnalm\n",
    "# model.load_state_dict(torch.load(msa2xyz_file, map_location='cpu', weights_only=True), strict=True)\n",
    "# model.train()\n",
    "\n",
    "# # Freeze embedding layers if desired\n",
    "# for name, param in model.named_parameters():\n",
    "#     if 'embed' in name:\n",
    "#         param.requires_grad = False\n",
    "\n",
    "# optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4, weight_decay=1e-5)\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# num_epochs = 20\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model.to(device)\n",
    "\n",
    "# for epoch in range(1, num_epochs + 1):\n",
    "#     # Training\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     for batch in train_loader:\n",
    "#         features = batch['features'].to(device)\n",
    "#         coords_target = batch['coords'].to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         coords_pred = model(features)\n",
    "#         loss = criterion(coords_pred, coords_target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#     avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "#     # Validation\n",
    "#     model.eval()\n",
    "#     val_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for batch in val_loader:\n",
    "#             features = batch['features'].to(device)\n",
    "#             coords_target = batch['coords'].to(device)\n",
    "#             coords_pred = model(features)\n",
    "#             val_loss += criterion(coords_pred, coords_target).item()\n",
    "#     avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "#     scheduler.step()\n",
    "\n",
    "#     print(f\"Epoch {epoch}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
    "\n",
    "#     # Save checkpoint\n",
    "#     if epoch % 5 == 0:\n",
    "#         torch.save(model.state_dict(), f\"drfold2_finetuned_epoch{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "791d62f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T00:17:09.670352Z",
     "iopub.status.busy": "2025-05-13T00:17:09.670129Z",
     "iopub.status.idle": "2025-05-13T00:17:09.764088Z",
     "shell.execute_reply": "2025-05-13T00:17:09.763270Z"
    },
    "papermill": {
     "duration": 0.104085,
     "end_time": "2025-05-13T00:17:09.765328",
     "exception": false,
     "start_time": "2025-05-13T00:17:09.661243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID resname  resid        x_1        y_1        z_1        x_2        y_2        z_2        x_3        y_3        z_3        x_4        y_4        z_4        x_5        y_5       z_5\n",
      "0      R1107_1       G      1   2.905267   9.048628  -3.282411  -7.015918   8.532943   4.970207  -0.031350   8.395054  -9.734588   1.462059  -1.383294   4.998859  -2.708893   2.232720 -1.934017\n",
      "1      R1107_2       G      2   6.057236  12.926416  -0.379654  -8.077373   9.264426  10.573361   2.114906  12.400799  -9.890106  -0.719784  -2.968459   0.928596  -6.980391   0.893952 -4.024602\n",
      "2      R1107_3       G      3   9.028996  14.280936   4.500532 -10.581871   7.324004  15.353767   2.510819  18.012100  -8.438994  -5.177915  -3.207253  -2.163895 -12.186717   0.791450 -4.414519\n",
      "3      R1107_4       G      4  11.440684  12.405815   9.389330 -12.854498   2.791572  18.680662   0.575659  22.589180  -5.405528 -10.183083  -1.089534  -3.836257 -17.234041   2.204441 -2.606580\n",
      "4      R1107_5       G      5  13.022847   8.801436  13.396454 -13.723700  -3.033416  19.300079  -3.260521  24.759499  -1.301328 -14.501650   2.489855  -3.892360 -20.979321   5.056321  0.697954\n",
      "..         ...     ...    ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...        ...       ...\n",
      "113  R1190_114       U    114  37.431461  29.191401 -23.236778  25.699198  13.256453   1.729606 -19.714554  23.329748 -25.334530 -14.302045   5.630352 -38.118252  13.410790  18.505308 -0.301396\n",
      "114  R1190_115       U    115  39.509476  30.352846 -27.411892  25.358614  12.014378  -3.406775 -20.675510  22.789078 -31.465862 -10.201819   8.242227 -41.550781  13.997248  24.096087  1.629771\n",
      "115  R1190_116       U    116  39.291718  28.581354 -31.448900  23.059139  10.930712  -8.056493 -24.455994  22.114527 -35.920990  -6.644732  12.584609 -43.184269  11.690513  29.257166  3.376415\n",
      "116  R1190_117       U    117  37.334759  26.751799 -34.572781  18.574976  10.367143 -10.891772 -30.128588  22.477226 -37.759769  -3.424911  17.473389 -41.998726   6.794422  31.804995  5.750101\n",
      "117  R1190_118       U    118  33.142796  25.009861 -37.321827  13.075107  11.367743 -11.401947 -35.670151  24.485725 -36.954601  -1.414341  21.280870 -38.099602   1.437041  31.150944  7.912365\n",
      "\n",
      "[2515 rows x 18 columns]\n",
      "SUBMIT OK!!!!!!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "submit_df = solution_to_submit_df(solution)\n",
    "submit_df.to_csv(f'submission.csv', index=False)\n",
    "print(submit_df)\n",
    "print('SUBMIT OK!!!!!!')\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f19cc49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T00:17:09.782893Z",
     "iopub.status.busy": "2025-05-13T00:17:09.782683Z",
     "iopub.status.idle": "2025-05-13T00:17:09.785310Z",
     "shell.execute_reply": "2025-05-13T00:17:09.784716Z"
    },
    "papermill": {
     "duration": 0.012656,
     "end_time": "2025-05-13T00:17:09.786543",
     "exception": false,
     "start_time": "2025-05-13T00:17:09.773887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !rm -rf /kaggle/working/drfold\n",
    "# !rm -rf /kaggle/working/model-output\n",
    "# !rm -rf /kaggle/working/USalign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08101254",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T00:17:09.804220Z",
     "iopub.status.busy": "2025-05-13T00:17:09.803969Z",
     "iopub.status.idle": "2025-05-13T00:17:09.806845Z",
     "shell.execute_reply": "2025-05-13T00:17:09.806306Z"
    },
    "papermill": {
     "duration": 0.012901,
     "end_time": "2025-05-13T00:17:09.808025",
     "exception": false,
     "start_time": "2025-05-13T00:17:09.795124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if 0: \n",
    "#     print('debug: show first perdict')\n",
    "#     solution = list(solution.values())\n",
    "#     s = solution[0]\n",
    "#     target_id = s.target_id\n",
    "    \n",
    "#     fig = plt.figure(figsize=(10, 10))\n",
    "#     ax = fig.add_subplot(111, projection='3d')\n",
    " \n",
    "#     truth_df  = get_truth_df(target_id, label_df)\n",
    "#     truth_pdb = f'{KAGGLE_TRUTH_PDB_DIR}/kaggle_truth_{target_id}_C1.pdb' \n",
    "#     # print(os.path.isfile(truth_pdb))\n",
    "\n",
    "#     for c in range(5):\n",
    "#         predict_pdb = f'{out_dir}/{target_id}-coor.{c}.pdb'\n",
    "#         # print(os.path.isfile(predict_pdb))\n",
    "        \n",
    "#         if MODE=='local':\n",
    "#             command = f'{USALIGN} {predict_pdb} {truth_pdb} -atom \" C1\\'\" -m -'\n",
    "#             output = os.popen(command).read()\n",
    "#             tm_score = parse_usalign_for_tm_score(output)\n",
    "#             transform = parse_usalign_for_transform(output)\n",
    "#             aligned = s.coord[c]@transform[:,1:].T + transform[:,[0]].T\n",
    "\n",
    "#             #---\n",
    "#             if c==0:\n",
    "#                 truth = truth_df[['x_1', 'y_1', 'z_1']].to_numpy().astype('float32')\n",
    "#                 x, y, z = truth[:, 0], truth[:, 1], truth[:, 2]\n",
    "#                 ax.scatter(x, y, z, c='black', s=30, alpha=1)\n",
    "#                 ax.plot(x, y, z, color='black', linewidth=1, alpha=1, label=f'truth')\n",
    "#         else:\n",
    "#             aligned = s.coord[c]\n",
    "#             tm_score ='?'\n",
    "\n",
    "#         x, y, z = aligned[:, 0], aligned[:, 1], aligned[:, 2]\n",
    "#         alpha =1 if c==0 else 0.2\n",
    "#         ax.scatter(x, y, z, c='RED', s=30, alpha=alpha)\n",
    "#         ax.plot(x, y, z, color='RED', linewidth=1, alpha=alpha, label=f'{c}: tm {tm_score}')\n",
    "        \n",
    "#     set_aspect_equal(ax)\n",
    "#     plt.legend()\n",
    "#     plt.show() \n",
    "#     plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d478d1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T00:17:09.825624Z",
     "iopub.status.busy": "2025-05-13T00:17:09.825429Z",
     "iopub.status.idle": "2025-05-13T00:17:09.828236Z",
     "shell.execute_reply": "2025-05-13T00:17:09.827621Z"
    },
    "papermill": {
     "duration": 0.012893,
     "end_time": "2025-05-13T00:17:09.829419",
     "exception": false,
     "start_time": "2025-05-13T00:17:09.816526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if MODE=='local':\n",
    "#     # local validation\n",
    " \n",
    "#     tm_score=[]\n",
    "#     for i,row in valid_df.iterrows(): \n",
    "#         target_id = row.target_id#'R1116' #casp15 R1116: len(157)\n",
    "#         seq = row.sequence \n",
    "#         #-----------------------------------------------\n",
    "#         print(i,target_id, len(seq), seq[:75]+'...')\n",
    "    \n",
    "#         truth_pdb = f'{KAGGLE_TRUTH_PDB_DIR}/kaggle_truth_{target_id}_C1.pdb'\n",
    "#         # print(os.path.isfile(truth_pdb))\n",
    "        \n",
    "#         tm = []\n",
    "#         for c in range(NUM_CONF):\n",
    "#             predict_pdb = f'{out_dir}/{target_id}-coor.{c}.pdb'\n",
    "#             # print(os.path.isfile(predict_pdb))\n",
    "        \n",
    "#             command = f'{USALIGN} {predict_pdb} {truth_pdb} -atom \" C1\\'\" -m -'\n",
    "#             output = os.popen(command).read()\n",
    "#             # print(output)\n",
    "#             try:\n",
    "#                 tm_c = parse_usalign_for_tm_score(output)\n",
    "#             except:\n",
    "#                 tm_c = 0\n",
    "#             tm.append(tm_c)\n",
    "#         print('### tm:', tm)\n",
    "#         tm_score.append(max(tm))\n",
    "    \n",
    "#     print('ALL\\n',tm_score)\n",
    "#     print('MEAN', np.array(tm_score).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06801247",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T00:17:09.846640Z",
     "iopub.status.busy": "2025-05-13T00:17:09.846446Z",
     "iopub.status.idle": "2025-05-13T00:17:09.849890Z",
     "shell.execute_reply": "2025-05-13T00:17:09.849350Z"
    },
    "papermill": {
     "duration": 0.013385,
     "end_time": "2025-05-13T00:17:09.851070",
     "exception": false,
     "start_time": "2025-05-13T00:17:09.837685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# from torch.optim import AdamW\n",
    "# from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "# from pathlib import Path\n",
    "\n",
    "# # If the drfold package isn't installed, add its directory to PYTHONPATH\n",
    "# import sys\n",
    "# # Adjust the path below to where the drfold repo lives in your environment\n",
    "# sys.path.append('/kaggle/working/drfold')\n",
    "\n",
    "# # Import the DRfold2 model\n",
    "# from cfg_97.RNALM2.Model import RNA2nd as DRfold2Model\n",
    "\n",
    "\n",
    "# class SequenceStructureDataset(Dataset):\n",
    "#     def __init__(self, csv_file, data_dir, transform=None):\n",
    "#         self.df = pd.read_csv(csv_file)\n",
    "#         self.data_dir = Path(data_dir)\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.df)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         row = self.df.iloc[idx]\n",
    "#         seq_id = row['ID']\n",
    "#         # Load input features (e.g., 1-hot encoding of sequence)\n",
    "#         features = np.load(self.data_dir / f\"{seq_id}_features.npy\")\n",
    "#         # Load target coordinates\n",
    "#         coords = np.load(self.data_dir / f\"{seq_id}_coords.npy\")\n",
    "#         sample = {\n",
    "#             'features': torch.from_numpy(features).float(),\n",
    "#             'coords': torch.from_numpy(coords).float()\n",
    "#         }\n",
    "#         if self.transform:\n",
    "#             sample = self.transform(sample)\n",
    "#         return sample\n",
    "\n",
    "# train_dataset = SequenceStructureDataset(\n",
    "#     csv_file=f\"{DATA_KAGGLE_DIR}/train_labels.csv\",\n",
    "#     data_dir=f\"{DATA_KAGGLE_DIR}/train_data\"\n",
    "# )\n",
    "# val_dataset = SequenceStructureDataset(\n",
    "#     csv_file=f\"{DATA_KAGGLE_DIR}/validation_labels.csv\",\n",
    "#     data_dir=f\"{DATA_KAGGLE_DIR}/validation_data\"\n",
    "# )\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4)\n",
    "\n",
    "# # from drfold.model import DRfold2Model  # adjust import as needed\n",
    "\n",
    "# model = DRfold2Model(dict(\n",
    "#     s_in_dim=5,\n",
    "#     z_in_dim=2,\n",
    "#     s_dim= 512,\n",
    "#     z_dim= 128,\n",
    "#     N_elayers=18,\n",
    "# ))\n",
    "# # Load pre-trained weights\n",
    "# msa2xyz_file = [f'/kaggle/working/drfold/model_hub/cfg_97/model_{k}' for k in [0,1,2,8,9]][c]\n",
    "# model.load_state_dict(torch.load(msa2xyz_file, map_location='cpu', weights_only=True), strict=True)\n",
    "# model.train()\n",
    "\n",
    "# # Freeze embedding layers if desired\n",
    "# for name, param in model.named_parameters():\n",
    "#     if 'embed' in name:\n",
    "#         param.requires_grad = False\n",
    "\n",
    "# optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4, weight_decay=1e-5)\n",
    "# scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# num_epochs = 20\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model.to(device)\n",
    "\n",
    "# for epoch in range(1, num_epochs + 1):\n",
    "#     # Training\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     for batch in train_loader:\n",
    "#         features = batch['features'].to(device)\n",
    "#         coords_target = batch['coords'].to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         coords_pred = model(features)\n",
    "#         loss = criterion(coords_pred, coords_target)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         total_loss += loss.item()\n",
    "\n",
    "#     avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "#     # Validation\n",
    "#     model.eval()\n",
    "#     val_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for batch in val_loader:\n",
    "#             features = batch['features'].to(device)\n",
    "#             coords_target = batch['coords'].to(device)\n",
    "#             coords_pred = model(features)\n",
    "#             val_loss += criterion(coords_pred, coords_target).item()\n",
    "#     avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "#     scheduler.step()\n",
    "\n",
    "#     print(f\"Epoch {epoch}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}\")\n",
    "\n",
    "#     # Save checkpoint\n",
    "#     if epoch % 5 == 0:\n",
    "#         torch.save(model.state_dict(), f\"drfold2_finetuned_epoch{epoch}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "056d777f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T00:17:09.868837Z",
     "iopub.status.busy": "2025-05-13T00:17:09.868640Z",
     "iopub.status.idle": "2025-05-13T00:17:09.871626Z",
     "shell.execute_reply": "2025-05-13T00:17:09.871087Z"
    },
    "papermill": {
     "duration": 0.013075,
     "end_time": "2025-05-13T00:17:09.872842",
     "exception": false,
     "start_time": "2025-05-13T00:17:09.859767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Install Optuna if not already installed\n",
    "# !pip install optuna\n",
    "\n",
    "# import optuna  # Using pure Optuna without PyTorchLightningPruningCallback\n",
    "\n",
    "# def objective(trial):\n",
    "#     # Suggest hyperparameters\n",
    "#     lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)\n",
    "#     wd = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
    "#     batch_size = trial.suggest_categorical('batch_size', [4, 8, 16])\n",
    "#     T_max = trial.suggest_int('T_max', 5, 20)\n",
    "\n",
    "#     # Update DataLoaders\n",
    "#     train_loader = DataLoader(\n",
    "#         train_dataset, batch_size=batch_size, shuffle=True, num_workers=4\n",
    "#     )\n",
    "#     val_loader = DataLoader(\n",
    "#         val_dataset, batch_size=batch_size, shuffle=False, num_workers=4\n",
    "#     )\n",
    "\n",
    "#     # Reset model, optimizer, scheduler\n",
    "#     model = DRfold2Model()\n",
    "#     model.load_state_dict(torch.load(\n",
    "#         \"/kaggle/working/drfold/model_hub/drfold2_pretrained.pth\"\n",
    "#     ))\n",
    "#     model.to(device)\n",
    "#     optimizer = AdamW(\n",
    "#         filter(lambda p: p.requires_grad, model.parameters()),\n",
    "#         lr=lr, weight_decay=wd\n",
    "#     )\n",
    "#     scheduler = CosineAnnealingLR(optimizer, T_max=T_max)\n",
    "#     criterion = nn.MSELoss()\n",
    "\n",
    "#     # Training for a few epochs\n",
    "#     for epoch in range(1, 6):  # short run for tuning\n",
    "#         model.train()\n",
    "#         for batch in train_loader:\n",
    "#             features = batch['features'].to(device)\n",
    "#             coords_target = batch['coords'].to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             coords_pred = model(features)\n",
    "#             loss = criterion(coords_pred, coords_target)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#         scheduler.step()\n",
    "\n",
    "#     # Validation\n",
    "#     model.eval()\n",
    "#     val_loss = 0\n",
    "#     with torch.no_grad():\n",
    "#         for batch in val_loader:\n",
    "#             features = batch['features'].to(device)\n",
    "#             coords_target = batch['coords'].to(device)\n",
    "#             coords_pred = model(features)\n",
    "#             val_loss += criterion(coords_pred, coords_target).item()\n",
    "#     avg_val_loss = val_loss / len(val_loader)\n",
    "#     return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3dbfa614",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T00:17:09.890325Z",
     "iopub.status.busy": "2025-05-13T00:17:09.890118Z",
     "iopub.status.idle": "2025-05-13T00:17:09.892636Z",
     "shell.execute_reply": "2025-05-13T00:17:09.892083Z"
    },
    "papermill": {
     "duration": 0.012655,
     "end_time": "2025-05-13T00:17:09.893821",
     "exception": false,
     "start_time": "2025-05-13T00:17:09.881166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=20)\n",
    "\n",
    "# print(\"Best trial:\")\n",
    "# print(study.best_trial.params)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12255112,
     "sourceId": 87793,
     "sourceType": "competition"
    },
    {
     "datasetId": 6742586,
     "sourceId": 10855324,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6760509,
     "sourceId": 10880419,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6889817,
     "sourceId": 11065669,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7356947,
     "sourceId": 11752460,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6364.64701,
   "end_time": "2025-05-13T00:17:12.414970",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-12T22:31:07.767960",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
